#!/usr/bin/env python3

import datetime
import os
import json
import pickle
import random
import re
import sys
import time
import threading
import tiktoken

import enchant
from fuzzywuzzy import fuzz
import openai
import requests

import cfg
import utils
import my_dic
import my_google
import my_log
import my_trans


# clientside timeout
# openai.api_requestor.TIMEOUT_SECS = 150


CUSTOM_MODELS = my_dic.PersistentDict('db/custom_models.pkl')

# –ø–∞–º—è—Ç—å –¥–∏–∞–ª–æ–≥–æ–≤ {id:messages: list}
CHATS = my_dic.PersistentDict('db/dialogs.pkl')
# —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º—Ç—ã –¥–ª—è —á–∞—Ç–æ–≤, —Ä–æ–ª–∏ –∏–ª–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —á—Ç–æ –∏ –∫–∞–∫ –¥–µ–ª–∞—Ç—å –≤ —ç—Ç–æ–º —á–∞—Ç–µ
# {id:prompt}
# PROMPTS = my_dic.PersistentDict('db/prompts.pkl')
# —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ chatGPT {id:float(0-2)}
TEMPERATURE = {}
# –∑–∞–º–∫–∏ –¥–∏–∞–ª–æ–≥–æ–≤ {id:lock}
CHAT_LOCKS = {}


def ai(prompt: str = '', temp: float = 0.1, max_tok: int = 2000, timeou: int = 120, messages = None,
       chat_id = None, model_to_use: str = '') -> str:
    """–°—ã—Ä–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ GPT —á–∞—Ç—É, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç
    """
    global CUSTOM_MODELS

    if messages == None:
        assert prompt != '', 'prompt –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º'
        messages = [{"role": "system", "content": """–¢—ã –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç –æ—Ç–≤–µ—á–∞—é—â–∏–π –Ω–∞ –∑–∞–ø—Ä–æ—Å—ã —é–∑–µ—Ä–∞."""},
                    {"role": "user", "content": prompt}]

    current_model = cfg.model
    if chat_id and chat_id in CUSTOM_MODELS:
        current_model = CUSTOM_MODELS[chat_id]

    # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–∫–∞–∑–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –µ—Å—Ç—å
    current_model = current_model if not model_to_use else model_to_use

    response = ''

    # –∫–æ–ø–∏—Ä—É–µ–º –∏ –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å–µ—Ä–≤–µ—Ä–æ–≤
    shuffled_servers = cfg.openai_servers[:]
    random.shuffle(shuffled_servers)

    # –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞–≥—É –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    shuffled_servers = [x for x in shuffled_servers if 'api.naga.ac' not in x[0]]

    for server in shuffled_servers:
        openai.base_url = server[0]

        try:
            client = openai.OpenAI(api_key = server[1])
            # —Ç—É—Ç –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å —Å—Ç–µ–ø–µ–Ω—å —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–∞(–±—Ä–µ–¥–∞) –æ—Ç 0 –¥–æ 2 –¥–µ—Ñ–æ–ª—Ç - temperature = 1
            completion = client.chat.completions.create(
                model = current_model,
                messages=messages,
                max_tokens=max_tok,
                temperature=temp,
                timeout=timeou
            )
            response = completion.choices[0].message.content
            if response:
                break
        except Exception as unknown_error1:
            if 'You exceeded your current quota, please check your plan and billing details.' in str(unknown_error1) \
                or 'The OpenAI account associated with this API key has been deactivated.' in str(unknown_error1):
                my_log.log2(f'gpt_basic.ai: {unknown_error1}\n\nServer: {openai.base_url}\n\n{server[1]}')
                cfg.openai_servers = [x for x in cfg.openai_servers if x[1] != server[1]]
                continue
            # if str(unknown_error1).startswith('HTTP code 200 from API'):
            #         # –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞ json?
            #         text = str(unknown_error1)[24:]
            #         lines = [x[6:] for x in text.split('\n') if x.startswith('data:') and ':{"content":"' in x]
            #         content = ''
            #         for line in lines:
            #             parsed_data = json.loads(line)
            #             content += parsed_data["choices"][0]["delta"]["content"]
            #         if content:
            #             response = content
            #             break
            if 'Request timed out.' in str(unknown_error1) or 'cf_service_unavailable' in str(unknown_error1):
                my_log.log2(f'gpt_basic.ai: {unknown_error1}\n\nServer: {openai.base_url}\n\n{server[1]}\n\nsleep 10sec')
                time.sleep(10)
                continue
            # print(unknown_error1)
            my_log.log2(f'gpt_basic.ai: {unknown_error1}\n\nServer: {openai.base_url}')

    return check_and_fix_text(response)


def ai_instruct(prompt: str = '', temp: float = 0.1, max_tok: int = 2000, timeou: int = 120,
       model_to_use: str = 'gpt-3.5-turbo-instruct') -> str:
    """–°—ã—Ä–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∫ GPT —á–∞—Ç—É, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—ã—Ä–æ–π –æ—Ç–≤–µ—Ç, –¥–ª—è –º–æ–¥–µ–ª–µ–π instruct
    """

    assert prompt != '', 'prompt –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º'

    current_model = model_to_use

    response = ''
    
    # –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º —Å–µ—Ä–≤–µ—Ä–∞
    shuffled_servers = cfg.openai_servers[:]
    random.shuffle(shuffled_servers)

    # –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞–≥—É –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    shuffled_servers = [x for x in shuffled_servers if 'api.naga.ac' not in x[0]]

    for server in shuffled_servers:
        openai.base_url = server[0]

        try:
            client = openai.OpenAI(api_key = server[1])

            completion = client.completions.create(
                model=current_model,
                prompt=prompt,
                max_tokens=max_tok,
                # temperature=temp,
                timeout=timeou
            )
            response = completion.choices[0].text
            if response:
                break
        except Exception as unknown_error1:
            if str(unknown_error1).startswith('HTTP code 200 from API'):
                    # –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–µ—Ä–∞ json?
                    text = str(unknown_error1)[24:]
                    lines = [x[6:] for x in text.split('\n') if x.startswith('data:') and ':{"content":"' in x]
                    content = ''
                    for line in lines:
                        parsed_data = json.loads(line)
                        content += parsed_data["choices"][0]["delta"]["content"]
                    if content:
                        response = content
                        break
            print(unknown_error1)
            my_log.log2(f'gpt_basic.ai: {unknown_error1}\n\nServer: {openai.base_url}')

    return check_and_fix_text(response)


def ai_compress(prompt: str, max_prompt: int  = 300, origin: str = 'user', force: bool = False) -> str:
    """—Å–∂–∏–º–∞–µ—Ç –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç–µ –¥–ª—è —Ç–æ–≥–æ —á—Ç–æ –±—ã —ç–∫–æ–Ω–æ–º–∏—Ç—å –ø–∞–º—è—Ç—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
    origin - —á—å–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, —é–∑–µ—Ä–∞ –∏–ª–∏ —ç—Ç–æ –æ—Ç–≤–µ—Ç –ø–æ–º–æ—â–Ω–∏–∫–∞. 'user' –∏–ª–∏ 'assistant'
    force - –Ω–∞–¥–æ –ª–∏ —Å–∂–∏–º–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è –∫–æ—Ç–æ—Ä—ã–µ –∫–æ—Ä–æ—á–µ —á–µ–º –∑–∞–¥–∞–Ω–Ω–∞—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–Ω–∞. —ç—Ç–æ –Ω–∞–¥–æ —á—Ç–æ –±—ã –Ω–µ —Å–∂–∞—Ç—å –∞ –ø—Ä–æ—Å—Ç–æ —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞—Ç—å,
            –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –¥–∏–∞–ª–æ–≥ –≤ —Ç–∞–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —á—Ç–æ –±—ã –±–∏–Ω–≥ –µ–≥–æ –ø—Ä–∏–Ω—è–ª –≤–º–µ—Å—Ç–æ –¥–∏–∞–ª–æ–≥–∞
    """
    assert origin in ('user', 'assistant', 'dialog')
    if len(prompt) > max_prompt or force:
        try:
            if origin == 'user':
                compressed_prompt = ai(f'–°–æ–∫—Ä–∞—Ç–∏ —Ç–µ–∫—Å—Ç –¥–æ {max_prompt} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–∞–∫ —á—Ç–æ –±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–º—ã—Å–ª –∏ –≤–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏. \
–≠—Ç–æ—Ç —Ç–µ–∫—Å—Ç —è–≤–ª—è–µ—Ç—Å—è –∑–∞–ø—Ä–æ—Å–æ–º —é–∑–µ—Ä–∞ –≤ –ø–µ—Ä–µ–ø–∏—Å–∫–µ –º–µ–∂–¥—É —é–∑–µ—Ä–æ–º –∏ –ò–ò. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞. –¢–µ–∫—Å—Ç:\n{prompt}', max_tok = max_prompt)
            elif origin == 'assistant':
                compressed_prompt = ai(f'–°–æ–∫—Ä–∞—Ç–∏ —Ç–µ–∫—Å—Ç –¥–æ {max_prompt} —Å–∏–º–≤–æ–ª–æ–≤ —Ç–∞–∫ —á—Ç–æ –±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–º—ã—Å–ª –∏ –≤–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏. \
–≠—Ç–æ—Ç —Ç–µ–∫—Å—Ç —è–≤–ª—è–µ—Ç—Å—è –æ—Ç–≤–µ—Ç–æ–º –ò–ò –≤ –ø–µ—Ä–µ–ø–∏—Å–∫–µ –º–µ–∂–¥—É —é–∑–µ—Ä–æ–º –∏ –ò–ò. –ò—Å–ø–æ–ª—å–∑—É–π –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞. –¢–µ–∫—Å—Ç:\n{prompt}', max_tok = max_prompt)
            elif origin == 'dialog':
                compressed_prompt = ai(f'–†–µ–∑—é–º–∏—Ä—É–π –ø–µ—Ä–µ–ø–∏—Å–∫—É –º–µ–∂–¥—É —é–∑–µ—Ä–æ–º –∏ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–æ–º –¥–æ {max_prompt} —Å–∏–º–≤–æ–ª–æ–≤, –≤–µ—Å—å –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏—Å–ø—Ä–∞–≤—å –Ω–∞ –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π:\n{prompt}', max_tok = max_prompt)
            if len(compressed_prompt) < len(prompt) or force:
                return compressed_prompt
        except Exception as error:
            print(error)

        if len(prompt) > max_prompt:
            ziped = zip_text(prompt)
            if len(ziped) <= max_prompt:
                prompt = ziped
            else:
                prompt = prompt[:max_prompt]

    return prompt


def get_mem_as_string(chat_id_full: str) ->str:
    # –æ–±—Ä–µ–∑–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
    try:
        CHATS[chat_id_full] = CHATS[chat_id_full][-cfg.max_hist_lines:]
    except:
        pass

    if chat_id_full in CHATS:
        messages = CHATS[chat_id_full]
        messages2 = []
        for x in messages:
            if x['content'].startswith('[Info to help you answer'):
                end = x['content'].find(']') + 1
                x['content'] = x['content'][end:]
            messages2.append(x)
    prompt = '\n'.join(f'{"ùêîùêíùêÑùêë" if i["role"] == "user" else "ùêÅùêéùêì" if i["role"] == "assistant" else "ùêíùêòùêíùêìùêÑùêå"} - {i["content"]}\n' for i in messages2) or ''
    prompt = prompt.replace('\nùêÅùêéùêì','ùêÅùêéùêì')
    return prompt


def translate_text(text, fr = 'autodetect', to = 'ru'):
    """–ø–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é GPT-—á–∞—Ç–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –ø—Ä–∏ –æ—à–∏–±–∫–µ"""

    # –µ—Å–ª–∏ –Ω–µ—Ç –∫–ª—é—á–∞ —Ç–æ —Å—Ä–∞–∑—É –æ—Ç–±–æ–π
    # if not openai.api_key: return None
    
    prompt = f'–ò—Å–ø—Ä–∞–≤—å —è–≤–Ω—ã–µ –æ–ø–µ—á–∞—Ç–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ –∏ —Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ —Ç–∞–º –º–æ–≥–ª–∏ –ø–æ—è–≤–∏—Ç—å—Å—è –ø–æ—Å–ª–µ –ø–ª–æ—Ö–æ–≥–æ OCR, –ø–µ—Ä–µ–≤–µ–¥–∏ —Ç–µ–∫—Å—Ç —Å —è–∑—ã–∫–∞ ({fr}) –Ω–∞ —è–∑—ã–∫ ({to}), \
—Ä–∞–∑–±–µ–π –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ –∞–±–∑–∞—Ü—ã –¥–ª—è —É–¥–æ–±–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è –ø–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–∏–≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –∏ –∞–±–∑–∞—Ü—ã. \
–°—Å—ã–ª–∫–∏ –∏ –¥—Ä—É–≥–∏–µ –Ω–µ–ø–µ—Ä–µ–≤–æ–¥–∏–º—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞ –Ω–∞–¥–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –ø–µ—Ä–µ–≤–æ–¥–µ. –¢–µ–∫—Å—Ç —ç—Ç–æ –≤—Å—ë (–¥–æ –∫–æ–Ω—Ü–∞) —á—Ç–æ –∏–¥–µ—Ç –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è. \
–ü–æ–∫–∞–∂–∏ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥ –±–µ–∑ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∏ –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –¢–µ–∫—Å—Ç:'
    prompt += text

    try:
        r = ai(prompt)
    except Exception as e:
        print(e)
        return None
    return r


def clear_after_ocr(text: str) -> str:
    """
	Clears the text after performing OCR to fix obvious errors and typos that may have occurred during the OCR process. 
	Removes completely misrecognized characters and meaningless symbols. 
	Accuracy is important, so it is better to leave an error uncorrected if there is uncertainty about whether it is an error and how to fix it. 
	Preserves the original line and paragraph breaks. 
	Displays the result without formatting and debug information. 

	:param text: The text to be cleared after OCR.
	:type text: str
	:return: The cleared text.
	:rtype: str
    """
    
    return text
    
    prompt = '–ò—Å–ø—Ä–∞–≤—å —è–≤–Ω—ã–µ –æ—à–∏–±–∫–∏ –∏ –æ–ø–µ—á–∞—Ç–∫–∏ –≤ —Ç–µ–∫—Å—Ç–µ –∫–æ—Ç–æ—Ä—ã–µ —Ç–∞–º –º–æ–≥–ª–∏ –ø–æ—è–≤–∏—Ç—å—Å—è –ø–æ—Å–ª–µ –ø–ª–æ—Ö–æ–≥–æ OCR. \
–¢–æ —á—Ç–æ —Å–æ–≤—Å–µ–º –ø–ª–æ—Ö–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª–æ—Å—å, –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, –Ω–∞–¥–æ —É–±—Ä–∞—Ç—å. \
–í–∞–∂–Ω–∞ —Ç–æ—á–Ω–æ—Å—Ç—å, –ª—É—á—à–µ –æ—Å—Ç–∞–≤–∏—Ç—å –æ—à–∏–±–∫—É –Ω–µ–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –µ—Å–ª–∏ –Ω–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –≤ —Ç–æ–º —á—Ç–æ —ç—Ç–æ –æ—à–∏–±–∫–∞ –∏ –µ—ë –Ω–∞–¥–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –∏–º–µ–Ω–Ω–æ —Ç–∞–∫. \
–í–∞–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ —Å—Ç—Ä–æ–∫–∏ –∏ –∞–±–∑–∞—Ü—ã. \
–ù–µ –ø–µ—Ä–µ–≤–æ–¥–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫. \
–ü–æ–∫–∞–∂–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è –∏ –æ—Ç–ª–∞–¥–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –¢–µ–∫—Å—Ç:'
    prompt += text
    try:
        r = ai(prompt)
    except Exception as error:
        print(f'gpt_basic.ai:clear_after_ocr: {error}')
        my_log.log2(f'gpt_basic.ai:clear_after_ocr: {error}')
        return text
    my_log.log2(f'gpt_basic.ai:clear_after_ocr:ok: {text}\n\n{r}')
    return r


def detect_ocr_command(text):
    """–ø—ã—Ç–∞–µ—Ç—Å—è –ø–æ–Ω—è—Ç—å —è–≤–ª—è–µ—Ç—Å—è –ª–∏ text –∫–æ–º–∞–Ω–¥–æ–π —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç —Å –∫–∞—Ä—Ç–∏–Ω–∫–∏
    –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, False
    """
    keywords = (
    '–ø—Ä–æ—á–∏—Ç–∞–π', '—á–∏—Ç–∞–π', '—Ä–∞—Å–ø–æ–∑–Ω–∞–π', '–æ—Ç—Å–∫–∞–Ω–∏—Ä—É–π', '—Ä–æ–∑–ø—ñ–∑–Ω–∞–π', '—Å–∫–∞–Ω—É–π', 'extract', 'identify', 'detect', 'ocr',
     'read', 'recognize', 'scan'
    )

    # —Å–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–Ω—è—Ç—å –ø–æ –Ω–µ—á–µ—Ç–∫–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é —Å–ª–æ–≤
    if any(fuzz.ratio(text, keyword) > 70 for keyword in keywords): return True
    
    # –ø–æ–∫–∞ —á—Ç–æ –±–µ–∑ GPT - –ª–æ–∂–Ω—ã–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è –Ω–∏ –∫ —á–µ–º—É
    return False

    # if not openai.api_key: return False
    
    k = ', '.join(keywords)
    p = f'–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–∏—Å–ª–∞–ª –≤ —Ç–µ–ª–µ–≥—Ä–∞–º —á–∞—Ç –∫–∞—Ä—Ç–∏–Ω–∫—É —Å –ø–æ–¥–ø–∏—Å—å—é ({text}). –í —á–∞—Ç–µ –µ—Å—Ç—å –±–æ—Ç –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Ç–µ–∫—Å—Ç —Å –∫–∞—Ä—Ç–∏–Ω–æ–∫ –ø–æ –ø—Ä–æ—Å—å–±–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π. \
–¢–µ–±–µ –Ω–∞–¥–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ –ø–æ–¥–ø–∏—Å–∏ —Ö–æ—á–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —á—Ç–æ –±—ã —Å —ç—Ç–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏ –±—ã–ª —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é OCR –∏–ª–∏ –ø–æ–¥–ø–∏—Å—å –Ω–∞ —ç—Ç–æ —Å–æ–≤—Å–µ–º –Ω–µ —É–∫–∞–∑—ã–≤–∞–µ—Ç. \
–û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º –±–µ–∑ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è - –¥–∞ –∏–ª–∏ –Ω–µ—Ç –∏–ª–∏ –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ.'
    r = ai(p).lower().strip(' .')
    print(r)
    if r == '–¥–∞': return True
    #elif r == '–Ω–µ—Ç': return False
    return False


def check_and_fix_text(text):
    """–ø—ã—Ç–∞–µ–º—Å—è –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Å—Ç—Ä–∞–Ω–Ω—É—é –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å –ø–∏—Ä–∞—Ç—Å–∫–æ–≥–æ GPT —Å–µ—Ä–≤–µ—Ä–∞ (—Ç–æ–ª—å–∫–æ pawan?),
    –æ–Ω —á–∞—Å—Ç–æ –¥–µ–ª–∞–µ—Ç –æ—à–∏–±–∫—É –≤ —Å–ª–æ–≤–µ, –≤—Å—Ç–∞–≤–ª—è–µ—Ç 2 –≤–æ–ø—Ä–æ—Å–∏–∫–∞ –≤–º–µ—Å—Ç–æ –±—É–∫–≤—ã"""

    # –¥–ª—è –≤–∏–Ω–¥—ã –Ω–µ—Ç enchant?
    if 'Windows' in utils.platform():
        return text

    ru = enchant.Dict("ru_RU")

    # —É–±–∏—Ä–∞–µ–º –∏–∑ —Ç–µ–∫—Å—Ç–∞ –≤—Å—ë –∫—Ä–æ–º–µ —Ä—É—Å—Å–∫–∏—Ö –±—É–∫–≤, 2 —Å—Ç—Ä–∞–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–∞ –º–µ–Ω—è–µ–º –Ω–∞ 1 —á—Ç–æ –±—ã —É–ø—Ä–æ—Å—Ç–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∫—É
    text = text.replace('ÔøΩÔøΩ', '‚ÅÇ')
    russian_letters = re.compile('[^‚ÅÇ–∞-—è–ê-–Ø—ë–Å\s]')
    text2 = russian_letters.sub(' ', text)
    
    words = text2.split()
    for word in words:
        if '‚ÅÇ' in word:
            suggestions = ru.suggest(word)
            if len(suggestions) > 0:
                text = text.replace(word, suggestions[0])

    # –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–æ–±—Ä–∞—Ç—å —Å–ª–æ–≤–æ –∏–∑ —Å–ª–æ–≤–∞—Ä—è —Ç–æ –ø—Ä–æ—Å—Ç–æ —É–±–∏—Ä–∞–µ–º —ç—Ç–æ—Ç —Å–∏–º–≤–æ–ª, –ø—É—Å—Ç—å –ª—É—á—à–µ –±—É–¥–µ—Ç –æ–æ–ø–µ—á–∞—Ç–∫–∞ —á–µ–º –º—É—Å–æ—Ä
    return text.replace('‚ÅÇ', '')


def zip_text(text: str) -> str:
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Ä—É—Å—Å–∫–∏—Ö –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏—Ö –≥–ª–∞—Å–Ω—ã—Ö –±—É–∫–≤ —Ç–∏–ø–∞ "–∞", "–æ", "e" –∏ "a".
    –¢–∞–∫ –∂–µ —É–¥–∞–ª—è—é—Ç—Å—è –∏–¥—É—â–∏–µ –ø–æ–¥—Ä—è–¥ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã
    """
    vowels = [  '–æ', '–û',        # —Ä—É—Å—Å–∫–∏–µ
                'o', 'O']        # –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ. –Ω–µ —Å—Ç–æ–∏—Ç –Ω–∞–≤–µ—Ä–Ω–æ–µ —É–¥–∞–ª—è—Ç—å —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ

    # –∑–∞–º–µ–Ω—è–µ–º –≥–ª–∞—Å–Ω—ã–µ –±—É–∫–≤—ã –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É, –∏—Å–ø–æ–ª—å–∑—É—è –º–µ—Ç–æ–¥ translate –∏ —Ñ—É–Ω–∫—Ü–∏—é maketrans
    text = text.translate(str.maketrans('', '', ''.join(vowels)))

    # —É–±–∏—Ä–∞–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å–∏–º–≤–æ–ª—ã
    # –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–ø–∏—Å–∫–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –ø–æ–≤—Ç–æ—Ä–æ–≤
    # —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Å–∏–º–≤–æ–ª —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –∏ –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ, –µ—Å–ª–∏ –æ–Ω–∏ —Ä–∞–∑–Ω—ã–µ 
    new_text = "".join([text[i] for i in range(len(text)) if i == 0 or text[i] != text[i-1]])
    
    return new_text


def query_file(query: str, file_name: str, file_size: int, file_text: str) -> str:
    """
    Query a file using the chatGPT model and return the response.

    Args:
        query (str): The query to ask the chatGPT model.
        file_name (str): The name of the file.
        file_size (int): The size of the file in bytes.
        file_text (str): The content of the file.

    Returns:
        str: The response from the chatGPT model.
    """

    msg = f"""–û—Ç–≤–µ—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å —é–∑–µ—Ä–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é —Ñ–∞–π–ª–∞
–ó–∞–ø—Ä–æ—Å: {query}
–ò–º—è —Ñ–∞–π–ª–∞: {file_name}
–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size}
–¢–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞:


{file_text}
"""
    msg_size = len(msg)
    if msg_size > 99000:
        msg = msg[:99000]
        msg_size = 99000

    result = ''

    if msg_size < 15000:
        try:
            result = ai(msg, model_to_use = 'gpt-3.5-turbo-16k')
        except Exception as error:
            print(error)
            my_log.log2(f'gpt_basic:query_file: {error}')

    if not result and msg_size < 30000:
        try:
            result = ai(msg, model_to_use = 'claude-2-100k')
        except Exception as error:
            print(error)
            my_log.log2(f'gpt_basic:query_file: {error}')

    if not result and msg_size <= 99000:
        try:
            result = ai(msg, model_to_use = 'claude-instant-100k')
        except Exception as error:
            print(error)
            my_log.log2(f'gpt_basic:query_file: {error}')

    if not result:
        try:
            result = ai(msg[:15000], model_to_use = 'gpt-3.5-turbo-16k')
        except Exception as error:
            print(error)
            my_log.log2(f'gpt_basic:query_file: {error}')

    return result


def stt_after_repair(text: str) -> str:
    query = f"""–ò—Å–ø—Ä–∞–≤—å —Ç–µ–∫—Å—Ç, —ç—Ç–æ –∞—É–¥–∏–æ–∑–∞–ø–∏—Å—å, –≤ –Ω–µ–π –º–æ–≥—É—Ç –±—ã—Ç—å –æ—à–∏–±–∫–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏.
–ù–∞–¥–æ –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å —Ç–∞–∫ —á—Ç–æ –±—ã –±—ã–ª–æ –ø–æ–Ω—è—Ç–Ω–æ —á—Ç–æ —Ö–æ—Ç–µ–ª —Å–∫–∞–∑–∞—Ç—å —á–µ–ª–æ–≤–µ–∫ –∏ –æ—Ñ–æ—Ä–º–∏—Ç—å —É–¥–æ–±–Ω–æ –¥–ª—è —á—Ç–µ–Ω–∏—è, —Ä–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ –∞–±–∑–∞—Ü—ã,
–¥–æ–±–∞–≤–∏—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –≤ –Ω–µ–æ–¥–Ω–æ–∑–Ω–∞—á–Ω—ã–µ –º–µ—Å—Ç–∞.


{text}
"""
    result = ai(query, model_to_use = 'gpt-3.5-turbo-16k')
    return result


def stt(audio_file: str) -> str:
    """
    Transcribes an audio file to text using OpenAI API.

    Args:
        audio_file (str): The path to the audio file.

    Returns:
        str: The transcribed text.

    Raises:
        FileNotFoundError: If the audio file does not exist.
    """

    #—Å–ø–∏—Å–æ–∫ —Å–µ—Ä–≤–µ—Ä–æ–≤ –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –¥–æ—Å—Ç—É–ø–µ–Ω whisper
    servers = [x for x in cfg.openai_servers if x[2]]

    assert len(servers) > 0, 'No openai whisper servers configured'

    audio_file_fh = open(audio_file, "rb")

    # –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º —Å–µ—Ä–≤–µ—Ä–∞
    shuffled_servers = servers[:]
    random.shuffle(shuffled_servers)

    for server in shuffled_servers:
        openai.base_url = server[0]
        # openai.api_key = server[1]
        try:
            client = openai.OpenAI(api_key=server[1])
            translation = client.audio.transcriptions.create(
               model="whisper-1",
               file=audio_file_fh
            )
            if translation.text:
                break
        except Exception as error:
            print(error)
            my_log.log2(f'gpt_basic:stt: {error}\n\nServer: {server[0]}')

    return translation.text


def translate_image_prompt(prompt: str) -> str:
    """
    Translates the given image prompt into English if it is not already in English, otherwise leaves it as it is.

    Args:
        prompt (str): The image prompt to be translated.

    Returns:
        str: The translated image prompt in English.
    """
    prompt_tr = ''
    try:
        prompt_tr = ai_instruct(f'Translate into english if it is not english, else leave it as it is: {prompt}')
    except Exception as image_prompt_translate:
        my_log.log2(f'gpt_basic:image_gen:translate_prompt: {str(image_prompt_translate)}\n\n{prompt}')
    prompt_tr = prompt_tr.strip()
    if not prompt_tr:
        try:
            prompt_tr = my_trans.translate_text2(prompt, 'en')
        except Exception as google_translate_error:
            my_log.log2(f'gpt_basic:image_gen:translate_prompt:google_translate: {str(google_translate_error)}\n\n{prompt}')
        if not prompt_tr:
            prompt_tr = prompt
    return prompt_tr


def image_gen(prompt: str, amount: int = 10, size: str ='1024x1024'):
    """
    Generates a specified number of images based on a given prompt.

    Parameters:
        - prompt (str): The text prompt used to generate the images.
        - amount (int, optional): The number of images to generate. Defaults to 10.
        - size (str, optional): The size of the generated images. Must be one of '1024x1024', '512x512', or '256x256'. Defaults to '1024x1024'.

    Returns:
        - list: A list of URLs pointing to the generated images.
    """

    #—Å–ø–∏—Å–æ–∫ —Å–µ—Ä–≤–µ—Ä–æ–≤ –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –¥–æ—Å—Ç—É–ø–Ω–æ —Ä–∏—Å–æ–≤–∞–Ω–∏–µ
    servers = [x for x in cfg.openai_servers if x[3]]

    # –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º —Å–µ—Ä–≤–µ—Ä–∞
    shuffled_servers = servers[:]
    random.shuffle(shuffled_servers)

    if len(servers) == 0:
        return []

    # prompt_tr = translate_image_prompt(prompt)
    prompt_tr = prompt

    assert amount <= 10, 'Too many images to gen'
    assert size in ('1024x1024','512x512','256x256'), 'Wrong image size'

    my_log.log2(f'gpt_basic:image_gen: {prompt}\n{prompt_tr}')
    results = []
    for server in shuffled_servers:
        if len(results) >= amount:
            break
        openai.base_url = server[0]
        try:
            client = openai.OpenAI(api_key=server[1])
            response = client.images.generate(
                model="dall-e-3",
                prompt = prompt_tr,
                n = amount,
                size=size,
                quality = 'standard',
            )
            if response:
                results += [x.url for x in response.data]
        except AttributeError:
            pass
        except Exception as error:
            print(error)
            my_log.log2(f'gpt_basic:image_gen: {error}\n\nServer: {server[0]}')
    return results


def get_list_of_models():
    """
    Retrieves a list of models from the OpenAI servers.

    Returns:
        list: A list of model IDs.
    """
    result = []
    for server in cfg.openai_servers:
        openai.base_url = server[0]
        try:
            client = openai.OpenAI(api_key=server[1])
            model_lst = client.models.list()
            for i in model_lst.data:
                result += [i.id,]
        except Exception as error:
            print(error)
            my_log.log2(f'gpt_basic:get_list_of_models: {error}\n\nServer: {server[0]}')
    return sorted(list(set(result)))


def tr(text: str, lang: str = 'ru') -> str:
    """
    Translates text from one language to another.
    """
    return my_trans.translate_text2(text, lang)


def chat(chat_id: str, query: str, user_name: str = 'noname', lang: str = 'ru',
         is_private: bool = True, chat_name: str = 'noname chat') -> str:
    """
    The chat function is responsible for handling user queries and generating responses
    using the ChatGPT model.

    Parameters:
    - chat_id: str, the ID of the chat
    - query: str, the user's query
    - user_name: str, the user's name (default: 'noname')
    - lang: str, the language of the chat (default: 'ru')
    - is_private: bool, indicates whether the chat is private or not (default: True)
    - chat_name: str, the name of the chat (default: 'noname chat')

    Returns:
    - str, the response generated by the ChatGPT model
    """
    if chat_id in CHAT_LOCKS:
        lock = CHAT_LOCKS[chat_id]
    else:
        lock = threading.Lock()
        CHAT_LOCKS[chat_id] = lock

    with lock:
        # –≤ –∫–∞–∂–¥–æ–º —á–∞—Ç–µ —Å–≤–æ—è –∏—Å–æ—Ç—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –±–æ—Ç–∞ —Å —é–∑–µ—Ä–æ–º
        if chat_id in CHATS:
            messages = CHATS[chat_id]
        else:
            messages = []
        # —Ç–µ–ø–µ—Ä—å –µ–µ –Ω–∞–¥–æ –ø–æ—á–∏—Å—Ç–∏—Ç—å —á—Ç–æ –±—ã –≤–ª–µ–∑–ª–∞ –≤ –∑–∞–ø—Ä–æ—Å –∫ GPT
        # –ø—Ä–æ—Å—Ç–æ —É–¥–∞–ª—è–µ–º –≤—Å–µ –∫—Ä–æ–º–µ max_hist_lines –ø–æ—Å–ª–µ–¥–Ω–∏—Ö
        if len(messages) > cfg.max_hist_lines:
            messages = messages[cfg.max_hist_lines:]
        # —É–¥–∞–ª—è–µ–º –ø–µ—Ä–≤—É—é –∑–∞–ø–∏—Å—å –≤ –∏—Å—Ç–æ—Ä–∏–∏ –¥–æ —Ç–µ—Ö –ø–æ—Ä –ø–æ–∫–∞ –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –Ω–µ
        # —Å—Ç–∞–Ω–µ—Ç –º–µ–Ω—å—à–µ cfg.max_hist_bytes
        # —É–¥–∞–ª—è–µ–º –ø–æ 2 —Å—Ä–∞–∑—É —Ç–∞–∫ –∫–∞–∫ –ø–µ—Ä–≤–∞—è - –ø—Ä–æ–º–ø—Ç –¥–ª—è –±–æ—Ç–∞
        while utils.count_tokens(messages) > cfg.max_hist_bytes:
            messages = messages[2:]
        # –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º
        messages = messages + [{"role":    "user",
                                "content": query}]

        formatted_date = datetime.datetime.now().strftime("%d %B %Y %H:%M")

        # –≤ –∫–∞–∂–¥–æ–º —á–∞—Ç–µ —Å–≤–æ—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞
        if chat_id in TEMPERATURE:
            temp = TEMPERATURE[chat_id]
        else:
            temp = 0

#         # –≤ –∫–∞–∂–¥–æ–º —á–∞—Ç–µ —Å–≤–æ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–æ–º—Ç
#         curr_place = tr('–ø—Ä–∏–≤–∞—Ç–Ω—ã–π —Ç–µ–ª–µ–≥—Ä–∞–º —á–∞—Ç', lang) if is_private else \
# tr('–ø—É–±–ª–∏—á–Ω—ã–π —Ç–µ–ª–µ–≥—Ä–∞–º —á–∞—Ç', lang)
#         if not is_private:
#             curr_place = f'{curr_place} "{chat_name}"'
#         sys_prompt = f'{tr("–°–µ–π—á–∞—Å ", lang)} {formatted_date} , \
# {tr("—Ç—ã –Ω–∞—Ö–æ–¥–∏—à—å—Å—è –≤ ", lang)} {curr_place} \
# {tr("–∏ –æ—Ç–≤–µ—á–∞–µ—à—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é —Å –Ω–∏–∫–æ–º", lang)} "{user_name}", \
# {tr("–ª–æ–∫–∞–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: ", lang)} "{lang}"'
#         if chat_id in PROMPTS:
#             current_prompt = PROMPTS[chat_id]
#         else:
#             # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å
#             PROMPTS[chat_id] = [{"role": "system",
#                                  "content": tr(utils.gpt_start_message1, lang)}]
#             current_prompt =   [{"role": "system",
#                                  "content": tr(utils.gpt_start_message1, lang)}]
#         current_prompt = [{"role": "system", "content": sys_prompt}] + current_prompt
        current_prompt = []

        # –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç
        resp = ''
        try:
            resp = ai(prompt = '', temp = temp, messages = current_prompt + messages,
                      chat_id=chat_id)
            if resp:
                messages = messages + [{"role":    "assistant",
                                        "content": resp}]
            else:
                # –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏–∞–ª–æ–≥, –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞
                # –µ—Å–ª–∏ –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–º —Å–æ–æ–±—â–µ–Ω–∏–∏ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ (–≥–ª—é–∫) —Ç–æ —É–±–∏—Ä–∞–µ–º –µ–≥–æ
                if messages[-1]['content'].strip() == '':
                    messages = messages[:-1]
                CHATS[chat_id] = messages or []
                return tr('ChatGPT –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª.', lang)
        # –±–æ—Ç –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª –∏–ª–∏ –æ–±–∏–¥–µ–ª—Å—è
        except AttributeError:
            # –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏–∞–ª–æ–≥, –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞
            return tr('–ù–µ —Ö–æ—á—É –≥–æ–≤–æ—Ä–∏—Ç—å –æ–± —ç—Ç–æ–º. –ò–ª–∏ –Ω–µ –º–æ–≥—É.', lang)
        # –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞
        except openai.BadRequestError as error2:
            if """This model's maximum context length is""" in str(error2):
                # —á–∏—Å—Ç–∏–º –∏—Å—Ç–æ—Ä–∏—é, –ø–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å
                p = '\n'.join(f'{i["role"]} - {i["content"]}\n' for i in messages) or \
                    tr('–ü—É—Å—Ç–æ', lang)
                # —Å–∂–∏–º–∞–µ–º –≤–µ—Å—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä –¥–æ cfg.max_hist_compressed —Å–∏–º–≤–æ–ª–æ–≤
                r = ai_compress(p, cfg.max_hist_compressed, 'dialog')
                messages = [{'role':'system','content':r}] + messages[-1:]
                # –∏ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π –µ—â–µ
                while utils.count_tokens(messages) > cfg.max_hist_compressed:
                    messages = messages[2:]

                try:
                    resp = ai(prompt = '', temp=temp,
                              messages = current_prompt + messages,
                              chat_id=chat_id)
                except Exception as error3:
                    print(error3)
                    return tr('ChatGPT –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª.', lang)

                # –¥–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ GPT, –µ—Å–ª–∏ –æ–Ω –Ω–µ
                # –ø—É—Å—Ç–æ–π, –∏–Ω–∞—á–µ —É–¥–∞–ª—è–µ–º –∑–∞–ø—Ä–æ—Å —é–∑–µ—Ä–∞ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
                if resp:
                    messages = messages + [{"role":    "assistant",
                                            "content": resp}]
                else:
                    return tr('ChatGPT –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª.', lang)
            else:
                print(error2)
                return tr('ChatGPT –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª.', lang)

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏–∞–ª–æ–≥, –Ω–∞ –¥–∞–Ω–Ω–æ–º —ç—Ç–∞–ø–µ –≤ –∏—Å—Ç–æ—Ä–∏–∏ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å 2 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 
        # –∑–∞–ø–∏—Å–∏ –Ω–µ—Å–∂–∞—Ç—ã–º–∏
        messages = messages[:-2]
        # –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —é–∑–µ—Ä–∞ –±—ã–ª –¥–ª–∏–Ω–Ω—ã–º —Ç–æ –≤ –∏—Å—Ç–æ—Ä–∏–∏ –Ω–∞–¥–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –µ–≥–æ –∫–æ—Ä–æ—Ç–∫–æ
        if len(query) > cfg.max_hist_mem:
            new_text = ai_compress(query, cfg.max_hist_mem, 'user')
            # –∑–∞–º–µ–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ —Å–æ–∫—Ä–∞—â–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é
            messages += [{"role":    "user",
                          "content": new_text}]
        else:
            messages += [{"role":    "user",
                          "content": query}]
        # –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –±–æ—Ç–∞ –±—ã–ª –¥–ª–∏–Ω–Ω—ã–º —Ç–æ –≤ –∏—Å—Ç–æ—Ä–∏–∏ –Ω–∞–¥–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –µ–≥–æ –∫–æ—Ä–æ—Ç–∫–æ
        if len(resp) > cfg.max_hist_mem:
            new_resp = ai_compress(resp, cfg.max_hist_mem, 'assistant')
            messages += [{"role":    "assistant",
                          "content": new_resp}]
        else:
            messages += [{"role":    "assistant",
                          "content": resp}]
        CHATS[chat_id] = messages or []

        return resp or tr('ChatGPT –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª.', lang)


def chat_reset(chat_id: str):
    """
    Reset the chat with the given chat_id.
    
    Parameters:
        chat_id (str): The ID of the chat to reset.
    
    Returns:
        None
    """
    if chat_id in CHATS:
        CHATS[chat_id] = []


def console_chat_test():
    """
    This function is a console chat test. It allows the user to interact with a chatbot
    by entering queries in the console. The function takes no parameters.

    Parameters:
        None

    Returns:
        None
    """
    chat_id = 'test'
    user = '–ú–∞—à–∞ –ë–æ—Ä–∑—É–Ω–æ–≤–∞'
    lang = 'ru'
    is_private = False
    chat_name = '–ü–æ–º–æ—â—å –≤—Å–µ–º –≤–æ –≤—Å—ë–º'

    while True:
        query = input('> ')
        if query == 'exit':
            break
        if query == 'clear':
            chat_reset(chat_id=chat_id)
            print('OK')
            continue
        if query == 'mem':
            print('')
            mem = [x for x in CHATS[chat_id]]
            for x in mem:
                print(x)
            print('')
            continue
        response = chat(chat_id='test', query=query, user_name=user, lang=lang,
                        is_private=is_private, chat_name=chat_name)
        print(response)


def check_phone_number(number: str) -> str:
    """–ø—Ä–æ–≤–µ—Ä—è–µ—Ç —á–µ–π –Ω–æ–º–µ—Ä, –æ—Ç–∫—É–¥–∞ –∑–≤–æ–Ω–∏–ª–∏"""
    urls = [f'https://zvonili.com/phone/{number}',
            f'https://abonentik.ru/7{number}',
            f'https://www.list-org.com/search?type=phone&val=%2B7{number}'
            ]
    text = my_google.download_text(urls, no_links=True)
    query = f'''
–û–ø—Ä–µ–¥–µ–ª–∏ –ø–æ —Ç–µ–∫—Å—Ç—É –∫–∞–∫–æ–π —Ä–µ–≥–∏–æ–Ω, –∫–∞–∫–æ–π –æ–ø–µ—Ä–∞—Ç–æ—Ä, –∏ –Ω–µ —Å–≤—è–∑–∞–Ω –ª–∏ –æ–Ω —Å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ–º,
–æ—Ç–≤–µ—Ç—å –≤ —É–¥–æ–±–Ω–æ–π –¥–ª—è —á—Ç–µ–Ω–∏—è —Ñ–æ—Ä–º–µ —Å —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ –∞–±–∑–∞—Ü—ã –∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
–∂–∏—Ä–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–∫—Ü–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–Ω–∏–º–∞–Ω–∏—è,
–æ—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ, –Ω–æ –µ—Å–ª–∏ —Å–≤—è–∑–∞–Ω–æ —Å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ–º —Ç–æ –Ω–∞–ø–∏—à–∏ –ø–æ—á–µ–º—É —Ç—ã —Ç–∞–∫ —Ä–µ—à–∏–ª –ø–æ–¥—Ä–æ–±–Ω–æ.

–ù–æ–º–µ—Ä +7{number}

–¢–µ–∫—Å—Ç:

{text}
'''
    response = ai(query)
    return response


def moderation(text: str) -> bool:
    """
    Checks if the given text violates any moderation rules.

    Parameters:
        text (str): The text to be checked for moderation.

    Returns:
        bool: True if the text is flagged for moderation, False otherwise.
    """
    # –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º —Å–µ—Ä–≤–µ—Ä–∞
    shuffled_servers = cfg.openai_servers[:]
    random.shuffle(shuffled_servers)

    result = False
    for server in shuffled_servers:
        openai.base_url = server[0]
        try:
            client = openai.OpenAI(api_key=server[1])
            response = client.moderations.create(input=text)
            if response:
                result = response.results[0].flagged
                break
        except Exception as error:
            print(error)
            my_log.log2(f'gpt_basic.moderation: {error}\n\nServer: {openai.base_url}')
    return result


def tts(text: str, voice: str = 'alloy', model: str = 'tts-1') -> bytes:
    """
    Generates an audio file from the given text using the TTS API.
    voice = [alloy, echo, fable, onyx, nova, shimmer]
    model = [tts-1, tts-1-hd]

    Parameters:
        text (str): The text to convert to audio.
    """
    # –ø–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º —Å–µ—Ä–≤–µ—Ä–∞
    shuffled_servers = cfg.openai_servers[:]
    random.shuffle(shuffled_servers)

    for server in shuffled_servers:
        openai.base_url = server[0]

        try:
            client = openai.OpenAI(api_key=server[1])
            response = client.audio.speech.create(
                model=model,
                voice=voice,
                input=text,
                response_format='opus',
                speed=1
            )

            if response.content:
                break
        except Exception as unknown_error1:
            my_log.log2(f'gpt_basic.tts: {unknown_error1}\n\nServer: {server[0]}')
    
    return response.content


def get_balances() -> str:
    """–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, —á—Ç–æ —Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å –≤ API"""
    result = ''
    for server in [x for x in cfg.openai_servers if 'api.openai.com' in x[0]]:
        secret_key = server[1]
        response = requests.get(
            "https://api.openai.com/dashboard/billing/credit_grants",
            headers={"Authorization": "Bearer {}".format(secret_key)},
        )
        if response.status_code == 200:
            credits = response.json()["credits"]
            result += f'{server[1][:6]}: {credits}\n'
        else:
            result += f'{server[1][:6]}: {response.status_code}\n'
    return result


def count_tokens(text: str, model: str = 'gpt-3.5-turbo') -> int:
    """
    Count the number of tokens in the given text using the specified model.

    Parameters:
        text (str): The input text.
        model (str, optional): The name of the model to use for tokenizing. Defaults to 'gpt-3.5-turbo'.

    Returns:
        int: The number of tokens in the text.
    """
    encoding = tiktoken.encoding_for_model(model)
    return len(encoding.encode(text))


def translate_instruct(text: str, lang: str):
    prompt = f"""
Translate the following text to language [{lang}], leave it as is if not sure:

==============
{text}
==============
"""
    result = ai_instruct(prompt)
    return result


if __name__ == '__main__':
    tts_text = """–ü–µ—Ä—Å–∏ —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º –ø—Ä–æ—á–∏—Å—Ç–∏–ª –≥–æ—Ä–ª–æ –∏ –ø–æ—Å–º–æ—Ç—Ä–µ–ª –Ω–∞ –¥—Ä—É–≥–æ–π –∫–æ–Ω–µ—Ü —Å—Ç–æ–ª–∞, –≥–¥–µ —Å–∏–¥–µ–ª–∏ –ì–∞—Ä—Ä–∏, –†–æ–Ω –∏ –ì–µ—Ä–º–∏–æ–Ω–∞:

‚Äì –¢—ã –∑–Ω–∞–µ—à—å, –æ —á–µ–º —è, –ø–∞–ø–∞. ‚Äì –ò —á—É—Ç–æ—á–∫—É –ø–æ–≤—ã—Å–∏–ª –≥–æ–ª–æ—Å: ‚Äì –°–≤–µ—Ä—Ö—Å–µ–∫—Ä–µ—Ç–Ω–æ–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ.

–†–æ–Ω –∑–∞–∫–∞—Ç–∏–ª –≥–ª–∞–∑–∞ –∏ –ø—Ä–æ–±–æ—Ä–º–æ—Ç–∞–ª —Ç–∏—Ö–æ–Ω—å–∫–æ:

‚Äì –û–Ω –ø—ã—Ç–∞–µ—Ç—Å—è –∑–∞—Å—Ç–∞–≤–∏—Ç—å –Ω–∞—Å —Å–ø—Ä–æ—Å–∏—Ç—å, —á—Ç–æ –∑–∞ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏–µ, —Å —Ç–µ—Ö –ø–æ—Ä –∫–∞–∫ –ø–æ—à–µ–ª –Ω–∞ —Ä–∞–±–æ—Ç—É. –ù–µ –∏–Ω–∞—á–µ –≤—ã—Å—Ç–∞–≤–∫–∞ —Ç–æ–ª—Å—Ç–æ–¥–æ–Ω–Ω—ã—Ö –∫–æ—Ç–ª–æ–≤.

–í —Ü–µ–Ω—Ç—Ä–µ —Å—Ç–æ–ª–∞ –º–∏—Å—Å–∏—Å –£–∏–∑–ª–∏ —Å–ø–æ—Ä–∏–ª–∞ —Å –ë–∏–ª–ª–æ–º –æ –µ–≥–æ —Å–µ—Ä—å–≥–µ ‚Äì –≤–∏–¥–∏–º–æ, —Å–æ–≤—Å–µ–º –Ω–µ–¥–∞–≤–Ω–µ–º –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–∏.
"""

    print(count_tokens('—Ä–∞–∑ –¥–≤–∞ —Ç—Ä–∏ —á–µ—Ç—ã—Ä–µ –ø—è—Ç—å'))
    print(count_tokens('One two three four five'))
    print(count_tokens('‰∏Ä‰∫å‰∏âÂõõ‰∫î'))
    print(count_tokens('◊ê◊ó◊ì ◊©◊™◊ô◊ô◊ù ◊©◊ú◊ï◊© ◊ê◊®◊ë◊¢ ◊ó◊û◊©'))
    
    # print(translate_instruct(tts_text, 'ar'))
    # open('1.mp3', 'wb').write(tts('–Ω–∞–ø–∏—à–∏ 10 –≥–ª–∞–≤–Ω—ã—Ö –≥–µ—Ä–æ–µ–≤ –∫–Ω–∏–≥–∏ –Ω–µ–∑–Ω–∞–π–∫–∞ –Ω–∞ –ª—É–Ω–µ'))

    # print(ai_instruct('–Ω–∞–ø–∏—à–∏ 5 –≥–ª–∞–≤–Ω—ã—Ö –≥–µ—Ä–æ–µ–≤ –∫–Ω–∏–≥–∏ –Ω–µ–∑–Ω–∞–π–∫–∞ –Ω–∞ –ª—É–Ω–µ'))
    # print(ai('–Ω–∞–ø–∏—à–∏ 5 –≥–ª–∞–≤–Ω—ã—Ö –≥–µ—Ä–æ–µ–≤ –∫–Ω–∏–≥–∏ –Ω–µ–∑–Ω–∞–π–∫–∞ –Ω–∞ –ª—É–Ω–µ'))
    # print(moderation(''))
    # print(stt('1.ogg'))
    # print(image_gen('–∫–æ–º–∞–Ω–¥–µ—Ä –°–ø–æ–∫, –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ', 1))
    # open('1.ogg', 'wb').write(tts(tts_text, voice='echo', model = 'tts-1-hd'))
    # print(get_balances())
    # print(get_list_of_models())
    # print(count_tokens('–†–∞–∑ –¥–≤–∞ —Ç—Ä–∏ —á–µ—Ç—ã—Ä–µ –ø—è—Ç—å.'))
    # print(count_tokens('One two three four five.'))

    # print(query_file('—Å–∫–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä –≤ —Ñ–∞–π–ª–µ –∏ –∫–∞–∫–∞—è –∏—Ö —Å—É–º–º–∞', 'test.txt', 100, '1\n2\n2\n1'))

    # for x in range(5, 15):
    #     print(ai(f'1+{x}='))

    # for i in get_list_of_models():
        # print(i)

    #print(ai(open('1.txt', 'r', encoding='utf-8').read()[:15000], max_tok = 2000))

    # print(check_phone_number('9284655834'))
    # console_chat_test()

    sys.exit()

    if len(sys.argv) != 2:
        print("Usage: gptbasic.py filename|'request to qpt'")
        sys.exit(1)
    t = sys.argv[1]
    if os.path.exists(t):
        print(ai(open(t).read(), max_tok = 2000))
    else:
        print(ai(t, max_tok = 2000))
