# my_cmd_img2txt.py

# Standard library imports
import time
import traceback
from typing import Callable, Dict, List, Optional, Union

# Local application/library specific imports
import cfg
import my_db
import my_gemini_genimg
import my_init
import my_log
import my_qrcode
import my_transcribe
import utils
# import utils_llm

# AI/LLM specific imports
import my_cohere
import my_gemini3
import my_github
import my_groq
import my_mistral
import my_openrouter
import my_openrouter_free


def img2img(
    text: Union[bytes, List[bytes]],
    lang: str,
    chat_id_full: str,
    query: str = '',
    model: str = '',
    temperature: float = 1.0,
    system_message: str = '',
    timeout: int = 120,
) -> Optional[bytes]:
    """
    Regenerate the image using a query.
    Tries OpenRouter first, then falls back to the old method.

    Args:
        text (bytes): The source image data.
        lang (str): The language code (unused, for compatibility).
        chat_id_full (str): The full chat ID for logging.
        query (str): The user's prompt for the edit.
        model (str): The model to use (for OpenRouter).
        temperature (float): Generation temperature.
        system_message (str): System message for the model.
        timeout (int): Request timeout in seconds.

    Returns:
        Optional[bytes]: The new image as bytes, or None on failure.
    """
    edited_image = None

    # Attempt to edit the image using the new OpenRouter method
    # if not model or model == 'google/gemini-2.5-flash-image-preview:free':
    #     edited_image: Optional[bytes] = my_openrouter_free.edit_image(
    #         prompt=query,
    #         source_image=text,
    #         user_id=chat_id_full,
    #         # model = model,
    #         timeout=timeout,
    #         system_prompt=system_message,
    #         temperature=temperature
    #     )

    # If the new method succeeds, return the result
    if edited_image:
        return edited_image

    # If the new method fails, fall back to the original method
    if isinstance(text, bytes):
        images: list[bytes] = [text,]
    elif isinstance(text, list):
        images: list[bytes] = text
    else:
        my_log.log2(f'my_cmd_img2txt:img2img:2: unknown type: {type(text)}')
        return None
    return my_gemini_genimg.regenerate_image(query, sources_images=images, user_id=chat_id_full)


def img2txt(
    text: Union[bytes, str],
    lang: str,
    chat_id_full: str,
    query: str,
    model: str,
    temperature: float,
    system_message: str,
    timeout: int,
    images: List[Union[bytes, str]],
    WHO_ANSWERED: Dict[str, str],
    UNCAPTIONED_IMAGES: Dict[str, tuple],
    add_to_bots_mem: Callable,
    tr: Callable,
) -> Optional[Union[str, bytes]]:
    """
    Generate the text description of an image.

    Args:
        text (str): The image file URL or downloaded data(bytes).
        lang (str): The language code for the image description.
        chat_id_full (str): The full chat ID.
        query (str): The user's query text.
        model (str): gemini model
        temperature (float): temperature
        system_message (str): system message (role/style)
        timeout (int): timeout
        images (List[bytes|str]): List of image data or URLs.
        WHO_ANSWERED (Dict[str, str]): Dictionary to store which model answered.
        UNCAPTIONED_IMAGES (Dict[str, tuple]): Storage for user images without captions.
        add_to_bots_mem (Callable): Function to add entries to the bot's memory.
        tr (Callable): Translation function.

    Returns:
        str: The text description of the image.
    """
    try:
        query = query.strip()
        query__ = query
        time_to_answer_start = time.time()

        # –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –Ω–∞ ! —Ç–æ –Ω–∞–¥–æ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫—É –∞ –Ω–µ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å
        if query.startswith('!'):
            imgs = images if images else text
            r = img2img(
                imgs,
                lang,
                chat_id_full,
                query[1:],
                model,
                temperature,
                system_message,
                timeout,
            )
            if r:
                add_to_bots_mem(tr('User asked to edit image', lang) + f' <prompt>{query[1:]}</prompt>', tr('Changed image successfully.', lang), chat_id_full)
            else:
                add_to_bots_mem(tr('User asked to edit image', lang) + f' <prompt>{query[1:]}</prompt>', tr('Failed to edit image.', lang), chat_id_full)
            return r

        if temperature is None:
            temperature = my_db.get_user_property(chat_id_full, 'temperature') or 1
        if system_message is None:
            system_message = my_db.get_user_property(chat_id_full, 'role') or ''

        if isinstance(text, bytes):
            data = text
        else:
            data = utils.download_image_as_bytes(text)

        original_query = query or tr('Describe in detail what you see in the picture. If there is text, write it out in a separate block. If there is very little text, then write a prompt to generate this image.', lang)

        if not query:
            query = tr('Describe the image, what do you see here? Extract all text and show it preserving text formatting. Write a prompt to generate the same image - use markdown code with syntax highlighting ```prompt\n/img your prompt in english```', lang)
        if 'markdown' not in query.lower() and 'latex' not in query.lower():
            query = query + '\n\n' + my_init.get_img2txt_prompt(tr, lang)

        text = ''
        qr_code = my_qrcode.get_text(data)
        if qr_code:
            query = f"{query}\n\n{tr('QR Code was automatically detected on the image, it`s text:', lang)} {qr_code}"

        try:
            chat_mode = my_db.get_user_property(chat_id_full, 'chat_mode') or ''

            system_message_gemini = system_message
            if 'gemini' in chat_mode:
                system_message_gemini = system_message + '\n\n' + tr("–ï—Å–ª–∏ —Ç—ã –Ω–µ –º–æ–∂–µ—à—å –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç–æ –æ—Ç–≤–µ—Ç—å —Å–ª–æ–≤–æ–º 'STOP', –Ω–∏–∫–∞–∫–∏—Ö –¥—Ä—É–≥–∏—Ö —Å–ª–æ–≤ –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å, –Ω–µ –æ—Ç–≤–µ—á–∞–π —á—Ç–æ —Ç—ã –Ω–µ –º–æ–∂–µ—à—å —á—Ç–æ —Ç–æ —Å–¥–µ–ª–∞—Ç—å.", lang)


            # –∑–∞–ø—Ä–æ—Å –Ω–∞ OCR?
            if query__ == 'OCR':
                if not text:
                    text = my_mistral.ocr_image(data, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_mistral_ocr'
            # –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å - gpt —Ç–æ —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ gpt
            if query__ == 'gpt':
                if not text:
                    text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.BIG_GPT_41_MODEL, system=system_message, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.BIG_GPT_41_MODEL
                    else:
                        text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.DEFAULT_41_MINI_MODEL, system=system_message, timeout=timeout)
                        if text:
                            WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.DEFAULT_41_MINI_MODEL

                if not text:
                    text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.BIG_GPT_MODEL, system=system_message, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.BIG_GPT_MODEL
                    else:
                        text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.DEFAULT_MODEL, system=system_message, timeout=timeout)
                        if text:
                            WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.DEFAULT_MODEL


            # –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å –ø–æ–º–æ—â—å—é openrouter
            # –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞ —è–≤–Ω–æ —Ç–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ —Ä–µ–∂–∏–º—É —á–∞—Ç–∞
            if not model and not text:
                if not text and chat_mode == 'openrouter':
                    text = my_openrouter.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, system=system_message, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + 'openrouter'

                # if not text and chat_mode == 'qwen3':
                #     text = my_openrouter_free.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, system=system_message, timeout=timeout)
                #     if text:
                #         WHO_ANSWERED[chat_id_full] = 'img2txt_' + 'qwen3'

                elif not text and chat_mode == 'gpt-4o':
                    text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.BIG_GPT_MODEL, system=system_message, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.BIG_GPT_MODEL
                    else:
                        text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.DEFAULT_MODEL, system=system_message, timeout=timeout)
                        if text:
                            WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.DEFAULT_MODEL

                elif not text and chat_mode == 'gpt_41':
                    text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.BIG_GPT_41_MODEL, system=system_message, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.BIG_GPT_41_MODEL
                    else:
                        text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.DEFAULT_41_MINI_MODEL, system=system_message, timeout=timeout)
                        if text:
                            WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.DEFAULT_41_MINI_MODEL

                elif not text and chat_mode == 'gpt_41_mini':
                    text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.DEFAULT_41_MINI_MODEL, system=system_message, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.DEFAULT_41_MINI_MODEL
                    else:
                        text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.DEFAULT_MODEL, system=system_message, timeout=timeout)
                        if text:
                            WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.DEFAULT_MODEL

                elif not text and chat_mode == 'gemini15':
                    text = my_gemini3.img2txt(data, query, model=cfg.gemini_pro_model, temp=temperature, chat_id=chat_id_full, system=system_message_gemini, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + cfg.gemini_pro_model
                elif not text and chat_mode == 'gemini25_flash':
                    text = my_gemini3.img2txt(data, query, model=cfg.gemini25_flash_model, temp=temperature, chat_id=chat_id_full, system=system_message_gemini, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + cfg.gemini25_flash_model
                elif not text and chat_mode == 'gemini-exp':
                    text = my_gemini3.img2txt(data, query, model=cfg.gemini_exp_model, temp=temperature, chat_id=chat_id_full, system=system_message_gemini, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + cfg.gemini_exp_model
                elif not text and chat_mode == 'gemini-learn':
                    text = my_gemini3.img2txt(data, query, model=cfg.gemini_learn_model, temp=temperature, chat_id=chat_id_full, system=system_message_gemini, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + cfg.gemini_learn_model
                elif not text and chat_mode == 'gemma3_27b':
                    text = my_gemini3.img2txt(data, query, model=cfg.gemma3_27b_model, temp=temperature, chat_id=chat_id_full, system=system_message, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + cfg.gemma3_27b_model
                elif not text and chat_mode == 'gemini-lite':
                    text = my_gemini3.img2txt(data, query, model=cfg.gemini_flash_light_model, temp=temperature, chat_id=chat_id_full, system=system_message_gemini, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + cfg.gemini_flash_light_model
                elif not text and chat_mode == 'gemini':
                    text = my_gemini3.img2txt(data, query, model=cfg.gemini_flash_model, temp=temperature, chat_id=chat_id_full, system=system_message_gemini, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + cfg.gemini_flash_model
                elif not text and chat_mode == 'cohere':
                    text = my_cohere.img2txt(
                        image_data=data,
                        prompt=query,
                        temperature=temperature,
                        chat_id=chat_id_full,
                        system=system_message,
                        timeout=timeout
                    )
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_cohere'

            # –µ—Å–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞ —è–≤–Ω–æ –∏ –Ω–µ –±—ã–ª –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º –±–ª–æ–∫–µ —Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º
            # —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –º–æ–¥–µ–ª—å (–≤–æ–∑–º–æ–∂–Ω–æ —á—Ç–æ –µ—â–µ —Ä–∞–∑)
            if not model and not text:
                model = cfg.img2_txt_model

            # —Å–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å –ø–æ–º–æ—â—å—é –¥–µ—Ñ–æ–ª—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏
            if not text:
                if 'gpt' in model:
                    text = my_github.img2txt(data, query, chat_id=chat_id_full, model=model, temperature=temperature, system=system_message, timeout=timeout)
                    if not text:
                        text = my_gemini3.img2txt(data, query, model=model, temp=temperature, chat_id=chat_id_full, system=system_message_gemini, timeout=timeout)
                else:
                    text = my_gemini3.img2txt(data, query, model=model, temp=temperature, chat_id=chat_id_full, system=system_message_gemini, timeout=timeout)
                if text:
                    WHO_ANSWERED[chat_id_full] = 'img2txt_' + model


            # –µ—Å–ª–∏ —ç—Ç–æ –±—ã–ª–∞ –¥–∂–µ–º–∏–Ω–∏ –ø—Ä–æ —Ç–æ –ø—Ä–æ–±—É–µ–º –µ–µ —Ñ–æ–ª–±–µ–∫
            if not text and model == cfg.gemini_pro_model:
                text = my_gemini3.img2txt(data, query, model=cfg.gemini_pro_model_fallback, temp=temperature, chat_id=chat_id_full, system=system_message_gemini, timeout=timeout)
                if text:
                    WHO_ANSWERED[chat_id_full] = 'img2txt_' + cfg.gemini_pro_model_fallback

            # –µ—Å–ª–∏ —ç—Ç–æ –±—ã–ª–∞ –Ω–µ –¥–∂–µ–º–∏–Ω–∏ –ª–∞–π—Ç —Ç–æ –ø—Ä–æ–±—É–µ–º –µ–µ
            if not text and model != cfg.gemini_flash_light_model:
                text = my_gemini3.img2txt(data, query, model=cfg.gemini_flash_light_model, temp=temperature, chat_id=chat_id_full, system=system_message_gemini, timeout=timeout)
                if text:
                    WHO_ANSWERED[chat_id_full] = 'img2txt_' + cfg.gemini_flash_light_model


            # —Ñ–ª–µ—à25 —Ñ–æ–ª–±–µ–∫
            if not text and model == cfg.gemini25_flash_model:
                text = my_gemini3.img2txt(data, query, model=cfg.gemini25_flash_model_fallback, temp=temperature, chat_id=chat_id_full, system=system_message_gemini, timeout=timeout)
                if text:
                    WHO_ANSWERED[chat_id_full] = 'img2txt_' + cfg.gemini25_flash_model_fallback

            # —Ñ–ª–µ—à —Ñ–æ–ª–±–µ–∫
            if not text and model == cfg.gemini_flash_model:
                text = my_gemini3.img2txt(data, query, model=cfg.gemini_flash_model_fallback, temp=temperature, chat_id=chat_id_full, system=system_message_gemini, timeout=timeout)
                if text:
                    WHO_ANSWERED[chat_id_full] = 'img2txt_' + cfg.gemini_flash_model_fallback

            # –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–Ω—ã–π –∏ –≤ –Ω–µ–º –æ—á–µ–Ω—å –º–Ω–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π —Ç–æ –≤–µ—Ä–æ—è—Ç–Ω–æ —ç—Ç–æ –∑–∞–≤–∏—Å—à–∏–π –æ—Ç–≤–µ—Ç
            # –ø–µ—Ä–µ–¥–∞–µ–º —ç—Å—Ç–∞—Ñ–µ—Ç—É —Å–ª–µ–¥—É—é—â–µ–º—É –ø—Ä–µ—Ç–µ–Ω–¥–µ–Ω—Ç—É
            if len(text) > 2000 and my_transcribe.detect_repetitiveness_with_tail(text):
                text = ''



            # –¥–∂–µ–º–∏–Ω–∏ –æ—Ç–∫–∞–∑–∞–ª–∞—Å—å –æ—Ç–≤–µ—á–∞—Ç—å?
            if 'stop' in text.lower() and len(text) < 10:
                text = ''



            # –¥–∞–ª–µ–µ –ø—Ä–æ–±—É–µ–º gpt4.1 –∏–∑ –≥–∏—Ç—Ö–∞–±–∞
            if not text:
                text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.BIG_GPT_41_MODEL, system=system_message, timeout=timeout)
                if text:
                    WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.BIG_GPT_41_MODEL
                else:
                    text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.DEFAULT_41_MINI_MODEL, system=system_message, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.DEFAULT_41_MINI_MODEL


            # gpt 4o
            if not text:
                text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.BIG_GPT_MODEL, system=system_message, timeout=timeout)
                if text:
                    WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.BIG_GPT_MODEL
                else:
                    text = my_github.img2txt(data, query, temperature=temperature, chat_id=chat_id_full, model=my_github.DEFAULT_MODEL, system=system_message, timeout=timeout)
                    if text:
                        WHO_ANSWERED[chat_id_full] = 'img2txt_' + my_github.DEFAULT_MODEL

            # llama-4-maverick at groq
            if not text:
                text = my_groq.img2txt(data, query, model = 'meta-llama/llama-4-maverick-17b-128e-instruct', temperature=temperature, chat_id=chat_id_full, system=system_message, timeout=timeout)
                if text:
                    WHO_ANSWERED[chat_id_full] = 'img2txt_' + 'meta-llama/llama-4-maverick-17b-128e-instruct'

            # –¥–∞–ª–µ–µ –ø—Ä–æ–±—É–µ–º Cohere command-a-vision
            if not text:
                text = my_cohere.img2txt(
                    image_data=data,
                    prompt=query,
                    temperature=temperature,
                    chat_id=chat_id_full,
                    system=system_message,
                    timeout=timeout
                )
                if text:
                    WHO_ANSWERED[chat_id_full] = 'img2txt_cohere'

        except Exception as img_from_link_error:
            traceback_error = traceback.format_exc()
            my_log.log2(f'my_cmd_img2txt:img2txt1: {img_from_link_error}\n\n{traceback_error}')

        if text:
            # –µ—Å–ª–∏ —Ä–µ–∂–∏–º –Ω–µ –¥–∂–µ–º–∏–Ω–∏ –∏–ª–∏ –æ—Ç–≤–µ—Ç–∏–ª –Ω–µ –¥–∂–µ–º–∏–Ω–∏ –∑–Ω–∞—á–∏—Ç –Ω–∞–¥–æ –¥–æ–±–∞–≤–∏—Ç—å –≤ –ø–∞–º—è—Ç—å –æ—Ç–≤–µ—Ç –≤—Ä—É—á–Ω—É—é
            if 'gemini' not in chat_mode or 'gemini' not in WHO_ANSWERED.get(chat_id_full, ''):
                add_to_bots_mem(tr('User asked about a picture:', lang) + ' ' + original_query, text, chat_id_full)

        if chat_id_full in WHO_ANSWERED:
            if text:
                complete_time = time.time() - time_to_answer_start
                my_log.log3(chat_id_full, complete_time)
                WHO_ANSWERED[chat_id_full] = f'üëá{WHO_ANSWERED[chat_id_full]} {utils.seconds_to_str(complete_time)}üëá'
            else:
                del WHO_ANSWERED[chat_id_full]


        # –¥–æ–±–∞–≤–ª—è–µ–º –≤ UNCAPTIONED_IMAGES[chat_id_full] —ç—Ç—É –∫–∞—Ä—Ç–∏–Ω–∫—É —á—Ç–æ –±—ã –æ–Ω–∞ —Å—Ç–∞–ª–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π
        if images:
            UNCAPTIONED_IMAGES[chat_id_full] = (time.time(), data, images)
        else:
            UNCAPTIONED_IMAGES[chat_id_full] = (time.time(), data, [data])

        # –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
        if utils.edit_image_detect(text, lang, tr):
            if 'gemini' in chat_mode:
                my_gemini3.undo(chat_id_full)

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–≤–µ–∂–∏–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –ø—Ä–∏—à–ª–∏ –≤ —Ñ—É–Ω–∫—Ü–∏—é.
            # –ï—Å–ª–∏ –Ω–µ—Ç ‚Äî –¥–æ—Å—Ç–∞–µ–º –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞.
            if images:
                source_images = images
            else:
                # –î–æ—Å—Ç–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤ –∏–∑ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞.
                # –ò–Ω–¥–µ–∫—Å [2] ‚Äî —ç—Ç–æ —Å–ø–∏—Å–æ–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤.
                source_images = UNCAPTIONED_IMAGES[chat_id_full][2] if chat_id_full in UNCAPTIONED_IMAGES else None

            # –ï—Å–ª–∏ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –≤—Å–µ —Ä–∞–≤–Ω–æ –Ω–µ—Ç, –≤—ã—Ö–æ–¥–∏–º.
            if not source_images:
                my_log.log2(f'my_cmd_img2txt:img2txt2: no source images')
                return

            r = img2img(
                text=source_images,
                lang=lang,
                chat_id_full=chat_id_full,
                query=query__,
                model=model,
                temperature=temperature,
                system_message=system_message,
                timeout=timeout
            )
            if r:
                add_to_bots_mem(tr('User asked to edit image', lang) + f' <prompt>{query[1:]}</prompt>', tr('Changed image successfully.', lang), chat_id_full)
            else:
                add_to_bots_mem(tr('User asked to edit image', lang) + f' <prompt>{query[1:]}</prompt>', tr('Failed to edit image.', lang), chat_id_full)
            return r

        return text
    except Exception as unexpected_error:
        traceback_error = traceback.format_exc()
        my_log.log2(f'my_cmd_img2txt:img2txt2:{unexpected_error}\n\n{traceback_error}')
        return ''
