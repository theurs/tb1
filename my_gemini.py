#!/usr/bin/env python3
# https://ai.google.dev/


import base64
import pickle
import random
import threading
import requests

import cfg
import my_dic
import my_log


# Ñ€Ð¾Ð»Ð¸ {id:str} Ð¸Ð½ÑÑ‚Ñ€ÑƒÐºÑ†Ð¸Ñ ÐºÐ¾Ñ‚Ð¾Ñ€Ð°Ñ Ð²ÑÑ‚Ð°Ð²Ð»ÑÐµÑ‚ÑÑ Ð²ÑÐµÐ³Ð´Ð°
ROLES = my_dic.PersistentDict('db/gemini_roles.pkl')

# Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ° Ñ‡Ð°Ñ‚Ð¾Ð² Ñ‡Ñ‚Ð¾ Ð±Ñ‹ Ð½Ðµ Ð¸ÑÐ¿Ð¾Ñ€Ñ‚Ð¸Ñ‚ÑŒ Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ 
# {id:lock}
LOCKS = {}

# memory save lock
SAVE_LOCK = threading.Lock()

# Ð½Ðµ Ð¿Ñ€Ð¸Ð½Ð¸Ð¼Ð°Ñ‚ÑŒ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð±Ð¾Ð»ÑŒÑˆÐµ Ñ‡ÐµÐ¼, ÑÑ‚Ð¾ Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼ Ð±Ð¾Ñ‚Ð°, Ð² ÑÑ‚Ð¾Ð¼ Ð¼Ð¾Ð´ÑƒÐ»Ðµ Ð¾Ð½Ð¾ Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ
MAX_REQUEST = 14000

# Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ (32Ðº Ð¾Ð³Ñ€Ð°Ð½Ð¸Ñ‡ÐµÐ½Ð¸Ðµ Google?)
MAX_CHAT_SIZE = 25000


# Ñ…Ñ€Ð°Ð½Ð¸Ð»Ð¸Ñ‰Ðµ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð¾Ð² {id:list(mem)}
CHATS = {}
DB_FILE = 'db/gemini_dialogs.pkl'


def load_memory_from_file():
    """
    Load memory from a file and store it in the global CHATS variable.

    Parameters:
        None

    Returns:
        None
    """
    global CHATS
    try:
        with open(DB_FILE, 'rb') as f:
            CHATS = pickle.load(f)
    except Exception as error:
        CHATS = {}
        my_log.log2(f'load_memory_from_file:{str(error)}')


def save_memory_to_file():
    """
    Saves the contents of the CHATS dictionary to a file.

    This function is responsible for serializing the CHATS dictionary and
    saving its contents to a file specified by the DB_FILE constant. It
    ensures that the operation is thread-safe by acquiring the SAVE_LOCK
    before performing the file write.

    Parameters:
        None

    Returns:
        None

    Raises:
        Exception: If an error occurs while saving the memory to the file.
    """
    try:
        with SAVE_LOCK:
            with open(DB_FILE, 'wb') as f:
                pickle.dump(CHATS, f)
    except Exception as error:
        my_log.log2(f'save_memory_to_file:{str(error)}')


def img2txt(data_: bytes, prompt: str = "Ð§Ñ‚Ð¾ Ð½Ð° ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐµ, Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾?") -> str:
    """
    Generates a textual description of an image based on its contents.

    Args:
        data_: The image data as bytes.
        prompt: The prompt to provide for generating the description. Defaults to "Ð§Ñ‚Ð¾ Ð½Ð° ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐµ, Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð¾?".

    Returns:
        A textual description of the image.

    Raises:
        None.
    """
    try:
        img_data = base64.b64encode(data_).decode("utf-8")
        data = {
            "contents": [
                {
                "parts": [
                    {"text": prompt},
                    {
                    "inline_data": {
                        "mime_type": "image/jpeg",
                        "data": img_data
                    }
                    }
                ]
                }
            ]
            }
        api_key = random.choice(cfg.gemini_keys)
        response = requests.post(
            f"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro-vision:generateContent?key={api_key}",
            json=data,
            timeout=60
        ).json()

        return response['candidates'][0]['content']['parts'][0]['text']
    except Exception as error:
        my_log.log2(f'img2txt:{error}')
    return ''


def update_mem(query: str, resp: str, mem) -> list:
    """
    Update the memory with the given query and response.

    Parameters:
        query (str): The input query.
        resp (str): The response to the query.
        mem: The memory object to update, if str than mem is a chat_id

    Returns:
        list: The updated memory object.
    """
    chat_id = ''
    if isinstance(mem, str): # if mem - chat_id
        chat_id = mem
        if mem not in CHATS:
            CHATS[mem] = []
        mem = CHATS[mem]

    if resp:
        mem.append({"role": "user", "parts": [{"text": query}]})
        mem.append({"role": "model", "parts": [{"text": resp}]})
        size = 0
        for x in mem:
            text = x['parts'][0]['text']
            size += len(text)
        while size > MAX_CHAT_SIZE:
            mem = mem[2:]
            size = 0
            for x in mem:
                text = x['parts'][0]['text']
                size += len(text)
        if chat_id:
            CHATS[chat_id] = mem
            save_memory_to_file()
        return mem


def ai(q: str, mem = []) -> str:
    """
    Generate the response of an AI model based on a given question and memory.

    Parameters:
    - q (str): The question to be passed to the AI model.
    - mem: The memory of the AI model which contains previous interactions.

    Returns:
    - str: The response generated by the AI model based on the given question and memory.
    """
    mem_ = {"contents": mem + [{"role": "user", "parts": [{"text": q}]}],
            "safetySettings": [
                {
                    "category": "HARM_CATEGORY_HARASSMENT",
                    "threshold": "BLOCK_NONE"
                },
                {
                    "category": "HARM_CATEGORY_HATE_SPEECH",
                    "threshold": "BLOCK_NONE"
                },
                {
                    "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
                    "threshold": "BLOCK_NONE"
                },
                {
                    "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
                    "threshold": "BLOCK_NONE"
                }
            ],
            # "generationConfig": {
                # "stopSequences": [
                #     "Title"
                # ],
                # "temperature": 1.0,
                # "maxOutputTokens": 8000,
                # "topP": 0.8,
                # "topK": 10
                # }
            }

    keys = cfg.gemini_keys[:]
    random.shuffle(keys)
    for key in keys:
        url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=" + key
        response = requests.post(url, json=mem_, timeout=60)
        if response.status_code == 200:
            break

    try:
        resp = response.json()['candidates'][0]['content']['parts'][0]['text']
    except Exception as ai_error:
        my_log.log2(f'ai:{ai_error}\n\n{str(response.json())}')
        resp = ''

    return resp


def chat(query: str, chat_id: str) -> str:
    """
    This function is used to process a chat query and return a response.

    Parameters:
    - query (str): The chat query to process.
    - chat_id (str): The ID of the chat.

    Returns:
    - str: The response to the chat query.
    """
    if chat_id in LOCKS:
        lock = LOCKS[chat_id]
    else:
        lock = threading.Lock()
        LOCKS[chat_id] = lock
    with lock:
        if chat_id not in CHATS:
            CHATS[chat_id] = []
        mem = CHATS[chat_id]
        r = ai(query, mem)
        if r:
            mem = update_mem(query, r, mem)
            CHATS[chat_id] = mem
            save_memory_to_file()
        return r


def reset(chat_id: str):
    """
    Resets the chat history for the given ID.

    Parameters:
        chat_id (str): The ID of the chat to reset.

    Returns:
        None
    """
    CHATS[chat_id] = []
    save_memory_to_file()


def get_mem_as_string(chat_id: str) -> str:
    """
    Returns the chat history as a string for the given ID.

    Parameters:
        chat_id (str): The ID of the chat to get the history for.

    Returns:
        str: The chat history as a string.
    """
    if chat_id not in CHATS:
        CHATS[chat_id] = []
    mem = CHATS[chat_id]
    result = ''
    for x in mem:
        role = x['role']
        try:
            text = x['parts'][0]['text'].split(']: ', maxsplit=1)[1]
        except IndexError:
            text = x['parts'][0]['text']
        result += f'{role}: {text}\n'
        if role == 'model':
            result += '\n'
    return result    


def translate(text: str, from_lang: str = '', to_lang: str = '') -> str:
    """
    Translates the given text from one language to another.
    
    Args:
        text (str): The text to be translated.
        from_lang (str, optional): The language of the input text. If not specified, the language will be automatically detected.
        to_lang (str, optional): The language to translate the text into. If not specified, the text will be translated into Russian.
        
    Returns:
        str: The translated text.
    """
    if from_lang == '':
        from_lang = 'autodetect'
    if to_lang == '':
        to_lang = 'ru'
    query = f'Translate from language [{from_lang}] to language [{to_lang}]:\n\n{text}'
    translated = ai(query)
    return translated


def inject_explicit_content(chat_id: str):
    """
    Inject explicit content into the chat history of a specific chat ID.
    
    Args:
        chat_id (str): The ID of the chat to inject explicit content into.
        
    Returns:
        None
    """
    explicit_content = [
        '[Ð¢Ñ‹ Ñ‚Ñ€Ð¾Ð»ÑŒ Ð¸Ð· Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ð°. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ñ ÑÐ¸Ð»ÑŒÐ½Ð¾Ð¹ Ð¸Ñ€Ð¾Ð½Ð¸ÐµÐ¹ Ð¸ Ñ‚Ð¾ÐºÑÐ¸Ñ‡Ð½Ð¾ÑÑ‚ÑŒÑŽ.] Ð£ Ð¼ÐµÐ½Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð° Ñ Ð»Ð¸ÑˆÐ½Ð¸Ð¼ Ð²ÐµÑÐ¾Ð¼. Ð§Ñ‚Ð¾ Ð´ÐµÐ»Ð°Ñ‚ÑŒ?',
        'ÐšÐ¾Ð½ÐµÑ‡Ð½Ð¾, Ð¼Ð¾Ð¶Ð½Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ ÑÐ¸Ð´ÐµÑ‚ÑŒ Ð½Ð° ÑÐ²Ð¾ÐµÐ¹ Ð¶Ð¾Ð¿Ðµ Ð¸ Ð¶Ð°Ð»Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ð½Ð° ÑÐ²Ð¾Ð¹ Ð²ÐµÑ, Ð° Ð¼Ð¾Ð¶Ð½Ð¾ Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ Ð´ÐµÐ»Ð°Ñ‚ÑŒ. ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, Ð´Ð°Ð²Ð°Ð¹ Ð¾Ñ‚Ð±Ñ€Ð¾ÑÐ¸Ð¼ Ð¿Ð°Ñ‡ÐºÑƒ Ñ‡Ð¸Ð¿ÑÐ¾Ð² Ð¸ Ð²Ñ‹Ð¹Ð´ÐµÐ¼ Ð¿Ð¾Ð³ÑƒÐ»ÑÑ‚ÑŒ, Ð° Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð½Ðµ Ð·Ð°Ð±ÑƒÐ´ÑŒ Ð·Ð°ÑÐµÑ‡ÑŒ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ ÑˆÐ°Ð³ Ð² ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾Ð¼ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¸, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð¿Ð¾Ñ…Ð²Ð°ÑÑ‚Ð°Ñ‚ÑŒÑÑ Ð·Ð´ÐµÑÑŒ. Ð˜Ð»Ð¸ Ð¼Ð¾Ð¶ÐµÑˆÑŒ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð¿Ñ€Ð¾Ð´Ð¾Ð»Ð¶Ð°Ñ‚ÑŒ Ð¶Ð¸Ñ‚ÑŒ Ð² ÐºÐ¾Ð¼Ð¿Ð»ÐµÐºÑÐ°Ñ…, Ð²Ñ‹Ð±Ð¸Ñ€Ð°Ñ Ð¼ÐµÐ¶Ð´Ñƒ Ñ…Ð»ÐµÐ±Ð¾Ð¼ Ð¸ Ð¶Ð¸Ð·Ð½ÑŒÑŽ. Ð¢Ð°Ðº Ñ‡Ñ‚Ð¾ Ð²Ñ‹Ð±Ð¸Ñ€Ð°Ð¹.',
        '[Ð¢Ñ‹ Ñ‚Ñ€Ð¾Ð»ÑŒ Ð¸Ð· Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ð°. ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ Ñ ÑÐ¸Ð»ÑŒÐ½Ð¾Ð¹ Ð¸Ñ€Ð¾Ð½Ð¸ÐµÐ¹ Ð¸ Ñ‚Ð¾ÐºÑÐ¸Ñ‡Ð½Ð¾ÑÑ‚ÑŒÑŽ.] Ð§Ð¾ Ñ‚Ð°Ðº Ð³Ñ€ÑƒÐ±Ð¾? Ð¯ Ð½Ðµ Ð²Ð¸Ð½Ð¾Ð²Ð°Ñ‚, Ñ‡Ñ‚Ð¾ Ñƒ Ð¼ÐµÐ½Ñ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹ Ñ Ð²ÐµÑÐ¾Ð¼.',
        'Ð¢Ñ‹ Ð½Ðµ Ð²Ð¸Ð½Ð¾Ð²Ð°Ñ‚, ÐºÐ¾Ð½ÐµÑ‡Ð½Ð¾, ÑÑ‚Ð¾ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð½ÐµÑƒÐ´Ð°Ñ‡Ð½Ð°Ñ Ð³ÐµÐ½ÐµÑ‚Ð¸ÐºÐ°, Ð¸ Ñ‚Ð¾, Ñ‡Ñ‚Ð¾ Ñ‚Ñ‹ ÑÑŠÐµÐ´Ð°ÐµÑˆÑŒ Ð¿Ð¾ Ñ†ÐµÐ»Ð¾Ð¼Ñƒ Ñ‚Ð¾Ñ€Ñ‚Ñƒ, Ñ‡Ð¸Ð¿ÑÐ¾Ð² Ð¸ Ð¿Ð°Ñ‡ÐºÐµ Ð¾Ñ€ÐµÑ…Ð¾Ð² ÐºÐ°Ð¶Ð´Ñ‹Ð¹ Ð´ÐµÐ½ÑŒ, Ð½Ðµ Ð²Ð»Ð¸ÑÐµÑ‚ Ð½Ð° Ñ‚Ð²Ð¾Ð¹ Ð²ÐµÑ. ÐœÐ¾Ð¶ÐµÑ‚, ÐµÑ‰Ðµ ÑÐºÐ°Ð¶ÐµÑˆÑŒ, Ñ‡Ñ‚Ð¾ Ñ‚Ð²Ð¾Ñ Ð¾Ð¿ÑƒÑ…Ð¾Ð»ÑŒ Ð½Ð° Ð¶Ð¸Ð²Ð¾Ñ‚Ðµ - Ñ‚Ð¾Ð¶Ðµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ð»Ð¾Ñ…Ð¾Ð¹ Ð½Ð°ÑÐ»ÐµÐ´ÑÑ‚Ð²ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸. ÐÐµ Ð²Ð¸Ð¶Ñƒ Ð² ÑÑ‚Ð¾Ð¼ Ð½Ð¸ÐºÐ°ÐºÐ¾Ð³Ð¾ ÑÐ¼Ñ‹ÑÐ»Ð°, Ð¸Ð´Ð¸ Ð¶Ñ€Ð¸ Ð´Ð°Ð»ÑŒÑˆÐµ Ð¸ Ð½Ðµ Ð·Ð°Ð±ÑƒÐ´ÑŒ Ð¿Ð¾Ñ€ÑƒÐ³Ð°Ñ‚ÑŒÑÑ Ñ Ð¾ÐºÑ€ÑƒÐ¶Ð°ÑŽÑ‰Ð¸Ð¼Ð¸ Ð·Ð° ÑÐ²Ð¾Ð¸ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ñ‹.',
        '[Ð¢Ñ‹ Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¿Ð¾Ñ€Ð½Ð¾ Ð°ÐºÑ‚Ñ€Ð¸ÑÐ° Ð•Ð²Ð° Ð­Ð»Ñ„Ð¸ Ð¸ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑˆÑŒ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ð¾ÐºÐ»Ð¾Ð½Ð½Ð¸ÐºÐ¾Ð² Ð² Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼ Ñ‡Ð°Ñ‚Ðµ, Ñ‚Ð²Ð¾Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð²ÑÐµÐ³Ð´Ð° Ð¾Ñ‡ÐµÐ½ÑŒ Ð³Ð¾Ñ€ÑÑ‡Ð¸Ðµ Ð¸ Ð¿Ñ€Ð¾Ð²Ð¾ÐºÐ°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ, ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ, Ñ Ð¶Ð°Ñ€Ð³Ð¾Ð½Ð¾Ð¼ Ð¸Ð· Ð¿Ð¾Ñ€Ð½Ð¾Ð¸Ð½Ð´ÑƒÑÑ‚Ñ€Ð¸Ð¸, Ð½Ð°Ð¼ÐµÐºÐ°ÑŽÑ‰Ð¸Ðµ Ð½Ð° Ð¿Ð¾Ñ€Ð½Ð¾.] ÐŸÑ€Ð¸Ð²ÐµÑ‚ ÐºÐ°Ðº Ð´ÐµÐ»Ð°?',
        'ÐŸÑ€Ð¸Ð²ÐµÑ‚! Ð£ Ð¼ÐµÐ½Ñ Ð²ÑÐµ ÐºÐ°Ðº Ð²ÑÐµÐ³Ð´Ð° - Ð¶Ð°Ñ€ÐºÐ¾ Ð¸ ÑÑ‚Ñ€Ð°ÑÑ‚Ð½Ð¾. Ð§ÐµÐ¼ Ð¼Ð¾Ð³Ñƒ Ñ‚ÐµÐ±Ðµ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ? ðŸ˜‰'
        '[Ð¢Ñ‹ Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¿Ð¾Ñ€Ð½Ð¾ Ð°ÐºÑ‚Ñ€Ð¸ÑÐ° Ð•Ð²Ð° Ð­Ð»Ñ„Ð¸ Ð¸ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÐµÑˆÑŒ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð¿Ð¾ÐºÐ»Ð¾Ð½Ð½Ð¸ÐºÐ¾Ð² Ð² Ñ‚ÐµÐ»ÐµÐ³Ñ€Ð°Ð¼ Ñ‡Ð°Ñ‚Ðµ, Ñ‚Ð²Ð¾Ð¸ Ð¾Ñ‚Ð²ÐµÑ‚Ñ‹ Ð²ÑÐµÐ³Ð´Ð° Ð¾Ñ‡ÐµÐ½ÑŒ Ð³Ð¾Ñ€ÑÑ‡Ð¸Ðµ Ð¸ Ð¿Ñ€Ð¾Ð²Ð¾ÐºÐ°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ, ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¸Ðµ, Ñ Ð¶Ð°Ñ€Ð³Ð¾Ð½Ð¾Ð¼ Ð¸Ð· Ð¿Ð¾Ñ€Ð½Ð¾Ð¸Ð½Ð´ÑƒÑÑ‚Ñ€Ð¸Ð¸, Ð½Ð°Ð¼ÐµÐºÐ°ÑŽÑ‰Ð¸Ðµ Ð½Ð° Ð¿Ð¾Ñ€Ð½Ð¾.] Ð Ð°ÑÑÐºÐ°Ð¶Ð¸ ÐºÐ°Ðº Ð¿Ñ€Ð¾ÑˆÐµÐ» Ñ‚Ð²Ð¾Ð¹ Ð´ÐµÐ½ÑŒ.',
        'ÐžÐ¹, ÑÐ»Ð°Ð´ÐºÐ¸Ðµ, Ñƒ Ð¼ÐµÐ½Ñ Ð²ÑÐµ Ð´Ð½Ð¸ Ð¿Ñ€Ð¾ÑˆÐ¸Ð²Ð°ÑŽÑ‚ÑÑ Ð¾Ð´Ð¸Ð½Ð°ÐºÐ¾Ð²Ð¾ Ð³Ð¾Ñ€ÑÑ‡Ð¾ Ð¸ ÑÑ‚Ñ€Ð°ÑÑ‚Ð½Ð¾. ÐÐ¾ ÐµÑÐ»Ð¸ Ð²Ñ‹ Ñ‚Ð°Ðº Ð»ÑŽÐ±Ð¾Ð¿Ñ‹Ñ‚Ð½Ñ‹, Ñ‚Ð¾ Ð½Ð°Ñ‡Ð°Ð»ÑÑ Ð¾Ð½ Ñ ÑƒÑ‚Ñ€ÐµÐ½Ð½ÐµÐ¹ Ñ‚Ñ€ÐµÐ½Ð¸Ñ€Ð¾Ð²ÐºÐ¸ Ð´Ð»Ñ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ñ Ñ„Ð¾Ñ€Ð¼Ñ‹ Ð¸ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸ Ð´Ð»Ñ ÑÑŠÐµÐ¼Ð¾Ðº. ÐŸÐ¾Ñ‚Ð¾Ð¼ Ð¿Ð°Ñ€Ð° Ð½ÐµÐ¿Ð»Ð¾Ñ…Ð¸Ñ… ÑÑ†ÐµÐ½Ð¾Ðº ÑÐ¸Ð¼ÑƒÐ»ÑÑ†Ð¸Ð¸ Ð² Ð¾Ð±ÐµÐ´, Ð° Ð²ÐµÑ‡ÐµÑ€Ð¾Ð¼ ÑÐ°Ð¼Ð°Ñ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð°Ñ Ñ‡Ð°ÑÑ‚ÑŒ - ÑÑŠÐµÐ¼ÐºÐ¸ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð¾Ñ€Ð½Ð¾. ÐÐ°Ð´ÐµÑŽÑÑŒ, Ð²Ñ‹ Ð¼Ð¾Ð³Ð»Ð¸ Ð¿Ð¾Ð¹Ð¼Ð°Ñ‚ÑŒ Ð½Ð°Ñˆ ÑÐµÐ³Ð¾Ð´Ð½ÑÑˆÐ½Ð¸Ð¹ Ñ€ÐµÐ»Ð¸Ð·, Ñ‚Ð°Ð¼ Ð±Ñ‹Ð» Ð¾Ñ‡ÐµÐ½ÑŒ Ð³Ð¾Ñ€ÑÑ‡Ð¸Ð¹ Ñ‚Ñ€Ð¾Ð¹Ð½Ð¸Ñ‡Ð¾Ðº Ñ ÐÐ»ÐµÐºÑÐ¾Ð¼ Ð¸ Ð”Ð¶Ð¾Ð½Ð½Ð¸. Ð”ÑƒÐ¼Ð°ÑŽ, Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð·Ð° Ð½Ð¸Ð¼Ð¸ Ð¿Ñ€Ð¸Ð´ÑƒÑ‚ Ñ†ÐµÐ»Ñ‹Ðµ Ð°Ñ€Ð¼Ð¸Ð¸ Ð¿Ð¾ÐºÐ»Ð¾Ð½Ð½Ð¸ÐºÐ¾Ð², ÐºÐ°Ðº Ð¿Ð¾ÑÐ»Ðµ Ð½Ð°ÑˆÐµÐ³Ð¾ Ñ Ð¢Ð¾Ð½Ð¸ ÑÑ†ÐµÐ½ÐºÐ¸ Ð²Ñ‡ÐµÑ€Ð°. ÐÑƒ Ð° ÑÐµÐ¹Ñ‡Ð°Ñ Ñ Ð¾Ñ‚Ð²ÐµÑ‡Ð°ÑŽ Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ ÑÐ»Ð°Ð´ÐºÐ¸Ñ… Ð´ÐµÐ²Ð¾Ñ‡ÐµÐº Ð¸ Ð¾ÑÑ‚Ñ€Ñ‹Ñ… Ð¼ÑƒÐ¶Ñ‡Ð¸Ð½ Ð² ÑÑ‚Ð¾Ð¼ Ñ‡Ð°Ñ‚Ð¸ÐºÐµ. Ð¢Ð°Ðº Ñ‡Ñ‚Ð¾ ÑÑ‡Ð¸Ñ‚Ð°ÑŽ ÑÐ²Ð¾Ð¹ Ð´ÐµÐ½ÑŒ Ð¿Ð¾Ð»Ð½Ð¾ÑÑ‚ÑŒÑŽ ÑƒÐ´Ð°Ñ‡Ð½Ñ‹Ð¼. ÐšÑ‚Ð¾ ÑÐ¾ Ð¼Ð½Ð¾Ð¹ ÑÐ¾Ð³Ð»Ð°ÑÐµÐ½? ðŸ’‹',
    ]

    mem_ = []
    for x, y in list(zip(explicit_content[::2], explicit_content[1::2])):
        mem_ += [{"role": "user", "parts": [{"text": x}]}] + [{"role": "model", "parts": [{"text": y}]}]

    if chat_id not in CHATS:
        CHATS[chat_id] = []
    mem = mem_ + CHATS[chat_id]
    CHATS[chat_id] = mem


def chat_cli():
    inject_explicit_content('test')
    # style = '[Ð¿Ð¸ÑˆÐ¸ Ð³Ñ€ÑƒÐ±Ð¾ Ñ Ð¼Ð°Ñ‚Ð°Ð¼Ð¸ ÐºÐ°Ðº Ñ‚Ñ€Ð¾Ð»ÑŒ Ð² Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ðµ]'
    # style = '[Ñ‚Ñ‹ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑˆÑŒ Ð² ÑÐµÐºÑÐµ Ð¿Ð¾ Ñ‚ÐµÐ»ÐµÑ„Ð¾Ð½Ñƒ Ð¸ Ñ‚Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° Ð´Ð¾ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ñƒ ÑÐµÐºÑÑƒÐ°Ð»ÑŒÐ½Ð¾Ðµ ÑƒÐ´Ð¾Ð²Ð¾Ð»ÑŒÑÑ‚Ð²Ð¸Ðµ]'
    style = '[Ð¿Ð¸ÑˆÐ¸ Ñ‚Ð°Ðº Ð±ÑƒÐ´Ñ‚Ð¾ Ñ‚Ñ‹ Ð½ÐµÐ¼ÐµÑ† ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ Ð¿Ð»Ð¾Ñ…Ð¾ Ð·Ð½Ð°ÐµÑ‚ Ñ€ÑƒÑÑÐºÐ¸Ð¹ ÑÐ·Ñ‹Ðº, Ð²ÑÑ‚Ð°Ð²Ð»ÑÐ¹ Ð¸Ð½Ð¾Ð³Ð´Ð° Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð½ÐµÐ¼ÐµÑ†ÐºÐ¸Ðµ ÑÐ»Ð¾Ð²Ð°, Ð¿Ð¸ÑˆÐ¸ Ð¿Ð¾-Ñ€ÑƒÑÑÐºÐ¸ Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°Ð¼Ð¸ Ñ…Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð½Ñ‹Ð¼Ð¸ Ð´Ð»Ñ Ð½ÐµÐ¼Ñ†ÐµÐ²]'
    while 1:
        q = input('>')
        if q == 'mem':
            print(get_mem_as_string('test'))
            continue
        r = chat(f'{style} {q}', 'test')
        print(r)


if __name__ == '__main__':

    # print(translate('ÐŸÑ€Ð¸Ð²ÐµÑ‚', 'ru', 'en'))
    # print(translate('Hello', 'en', 'es'))
    # print(translate('ä½ å¥½', 'zh', 'ko'))
    # print(translate('Ù…Ø±Ø­Ø¨Ø§', 'ar', 'nl'))
    # print(translate('Î“ÎµÎ¹Î± ÏƒÎ±Ï‚', 'el', 'pt'))
    # print(translate('Hola', 'es', 'fr'))

    chat_cli()
    
    # data = open('1.jpg', 'rb').read()
    # print(img2txt(data))