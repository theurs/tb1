#!/usr/bin/env python3


import base64
import io
import json
import os
import random
import re
import time
import threading
import traceback
from io import BytesIO
from multiprocessing.pool import ThreadPool

import PIL
import requests
from sqlitedict import SqliteDict
from PIL import Image

import bing_img
import cfg
import my_gemini
import my_glm
import my_groq
import my_log
import utils


DEBUG = cfg.DEBUG if hasattr(cfg, 'DEBUG') else False


# –∫–∞–∂–¥—ã–π —é–∑–µ—Ä –¥–∞–µ—Ç —Å–≤–æ–∏ –∫–ª—é—á–∏ –∏ –æ–Ω–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–æ–≤–º–µ—Å—Ç–Ω–æ —Å–æ –≤—Å–µ–º–∏
# {full_chat_id as str: key as str}
# {'[9123456789] [0]': 'key1', ...}
USER_KEYS = SqliteDict('db/huggingface_user_keys.db', autocommit=True)
# list of all users keys
ALL_KEYS = []
USER_KEYS_LOCK = threading.Lock()


# {hash of image:model name, ...}
WHO_AUTOR = {}

# –Ω–µ –¥–∞–≤–∞—Ç—å –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∞—Ä—Ç–∏–Ω–∫–∏ –±–æ–ª—å—à–µ —á–µ–º 1 –∑–∞ —Ä–∞–∑ –¥–ª—è 1 —é–∑–µ—Ä–∞
# {userid:lock}
LOCKS = {}

# –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –≤—ã–∑–æ–≤—ã –±–∏–Ω–≥–∞
BING_LOCK = threading.Lock()


def load_users_keys():
    """
    Load users' keys into memory and update the list of all keys available.
    """
    with USER_KEYS_LOCK:
        global USER_KEYS, ALL_KEYS
        if hasattr(cfg, 'huggin_face_api') and cfg.huggin_face_api:
            ALL_KEYS = cfg.huggin_face_api
        for user in USER_KEYS:
            key = USER_KEYS[user]
            if key not in ALL_KEYS:
                ALL_KEYS.append(key)


def upscale(image_bytes: bytes) -> bytes:
    """
    –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –µ—Å–ª–∏ –µ–≥–æ —à–∏—Ä–∏–Ω–∞ –∏–ª–∏ –≤—ã—Å–æ—Ç–∞ –º–µ–Ω—å—à–µ 1024 –ø–∏–∫—Å–µ–ª–µ–π,
    —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ö–æ—Ä–æ—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞.

    Args:
        image_bytes: –ë–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.

    Returns:
        –ë–∞–π—Ç—ã —É–≤–µ–ª–∏—á–µ–Ω–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ –∏—Å—Ö–æ–¥–Ω—ã–µ –±–∞–π—Ç—ã, –µ—Å–ª–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.
    """
    try:
        image = Image.open(BytesIO(image_bytes))
        width, height = image.size

        if width < 1024 or height < 1024:
            if width > height:
                new_width = 1024
                new_height = int(height * (1024 / width))
            else:
                new_height = 1024
                new_width = int(width * (1024 / height))

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–µ—Å–∞–π–∑–∞ (Lanczos)
            resized_image = image.resize((new_width, new_height), Image.LANCZOS)

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –±–∞–π—Ç—ã
            output_buffer = BytesIO()
            resized_image.save(output_buffer, format=image.format)
            return output_buffer.getvalue()
        else:
            return image_bytes
    except Exception as error:
        error_traceback = traceback.format_exc()
        my_log.log_huggin_face_api(f'my_genimg:upscale: {error}\n\n{error_traceback}')
        return image_bytes


def bing(prompt: str, moderation_flag: bool = False, user_id: str = ''):
    """—Ä–∏—Å—É–µ—Ç 4 –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Å –ø–æ–º–æ—â—å—é –¥–∞–ª–ª–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∫–æ–ª—å–∫–æ —Å–º–æ–≥ –Ω–∞—Ä–∏—Å–æ–≤–∞—Ç—å"""
    # prompt = prompt[:650] # –Ω–µ–ª—å–∑—è –±–æ–ª—å—à–µ 700?
    if moderation_flag or prompt.strip() == '':
        return []
    try:
        # with BING_LOCK:
        #     images = bing_img.gen_images(prompt, user_id)
        images = bing_img.gen_images(prompt, user_id)
        if type(images) == list:
            return list(set(images))
    except Exception as error_bing_img:
        my_log.log_bing_img(f'my_genimg:bing: {error_bing_img}')
    return []


def remove_huggin_face_key(api_key: str):
    '''Remove an API key from the list of valid API keys'''
    try:
        global ALL_KEYS
        ALL_KEYS.remove(api_key)
        user = 'unknown'
        for user in USER_KEYS:
            if USER_KEYS[user] == api_key:
                del USER_KEYS[user]
                break
        my_log.log_keys(f'Invalid key {api_key} removed, user {user}')
    except Exception as error:
        error_traceback = traceback.format_exc()
        my_log.log_huggin_face_api(f'Failed to remove key {api_key}: {error}\n\n{error_traceback}')


def huggin_face_api(prompt: str, negative_prompt: str = "") -> list:
    """
    Calls the Hugging Face API to generate text based on a given prompt.
    
    Args:
        prompt (str): The prompt to generate text from.
    
    Returns:
        bytes: The generated text as bytes.
    """
    if not hasattr(cfg, 'huggin_face_api'):
        return []

    if hasattr(cfg, 'huggin_face_models_urls') and cfg.huggin_face_models_urls:
        API_URL = cfg.huggin_face_models_urls
    else:
        if os.path.exists('huggin_face_models_urls.list'):
            with open('huggin_face_models_urls.list', 'r') as f:
                API_URL = f.read().splitlines()
            API_URL = [x.strip() for x in API_URL if x.strip() and not x.strip().startswith('#')]
        else:
            API_URL = [
            "https://api-inference.huggingface.co/models/ehristoforu/dalle-3-xl-v2",
            "https://api-inference.huggingface.co/models/digiplay/Juggernaut_final",
            "https://api-inference.huggingface.co/models/RunDiffusion/Juggernaut-X-v10",
            "https://api-inference.huggingface.co/models/dataautogpt3/TempestV0.1",
            "https://api-inference.huggingface.co/models/UnfilteredAI/NSFW-gen-v2",

            # new test
            "https://api-inference.huggingface.co/models/Corcelio/mobius",
            "https://api-inference.huggingface.co/models/sd-community/sdxl-flash",
            "https://api-inference.huggingface.co/models/fluently/Fluently-XL-v4",
            "https://api-inference.huggingface.co/models/Corcelio/openvision",

        ]

    payload = json.dumps({"inputs": prompt, "negative_prompt": negative_prompt,})

    def request_img(prompt, url, p):

        n = 1
        result = []
        while n > 0:
            n -= 1

            if hasattr(cfg, 'bing_proxy'):
                proxy = {'http': random.choice(cfg.bing_proxy), 'https': random.choice(cfg.bing_proxy)}
            else:
                proxy = None
            api_key = random.choice(ALL_KEYS)
            headers = {"Authorization": f"Bearer {api_key}"}

            mult_words = [
                '2D', '3D', 'CGI', 'VFX', 'abstract', 'animate', 'animated', 'animatic',
                'animation', 'animation_studio', 'animator', 'anime', 'art', 'asset', 'assets', 'background',
                'blurry', 'bright colors', 'cartoon', 'cartoonish', 'cel', 'celanimation', 'cels', 'character',
                'character_design', 'characters', 'chibi', 'childish', 'claymation', 'comic', 'compositing', 'concept_art',
                'concept_design', 'design', 'digital', 'doujinshi', 'draw', 'drawing', 'dreamlike', 'ecchi',
                'editing', 'effects', 'fanart', 'fantasy', 'film', 'filmmaking', 'frame', 'frames',
                'genre', 'graphicnovel', 'graphics', 'hentai', 'illustrate', 'illustration', 'inbetween', 'kawaii',
                'keyframe', 'lighting', 'lineart', 'loli', 'loop', 'low-contrast', 'low-resolution', 'manga',
                'mecha', 'mocap', 'model', 'modeling', 'models', 'modern', 'motion', 'motion_capture',
                'movie', 'narrative', 'paint', 'painting', 'palette', 'pipeline', 'pixelated', 'post-production',
                'pre-production', 'production', 'program', 'puppet', 'puppets', 'render', 'rendering', 'rigging',
                'rotoscoping', 'scene', 'scenes', 'script', 'scripting', 'sequence', 'sequences', 'shading',
                'short', 'shota', 'simple', 'simplistic', 'sketch', 'software', 'stop_motion', 'stopmotion',
                'story', 'storyboard', 'storyboards', 'style', 'sunny', 'surreal', 'technique', 'texturing',
                'timeline', 'tool', 'tween', 'urban', 'vibrant', 'vibrant colors', 'visual', 'visual_development',
                ]

            try:
                if (any(word in negative_prompt for word in mult_words)
                    and any(word in url for word in ['m3lt', 'midsommarcartoon', 'FLUX.1-dev-LoRA-One-Click-Creative-Template', 'flux-ghibsky-illustration'])):
                    return []

                if (any(word in prompt for word in mult_words)
                    and any(word in url for word in ['flux_film_foto', 'Juggernaut_final', 'NSFW-gen-v2'])):
                    return []

                response = requests.post(url, headers=headers, json=p, timeout=120, proxies=proxy)
            except Exception as error:
                my_log.log_huggin_face_api(f'my_genimg:huggin_face_api: {error}\nPrompt: {prompt}\nAPI key: {api_key}\nProxy: {proxy}\nURL: {url}')
                continue

            if '"error":"Authorization header is correct, but the token seems invalid' in response.text:
                remove_huggin_face_key(api_key)
                api_key = random.choice(ALL_KEYS)
                continue
            resp_text = str(response.content)[:300]
            if 'read timeout=' in resp_text or "SOCKSHTTPSConnectionPool(host='api-inference.huggingface.co', port=443): Max retries exceeded with url" in resp_text: # –∏ —Ç–∞–∫ –¥–æ–ª–≥–æ –∂–¥–∞–ª–∏
                return []
            if response.content and '{"error"' not in resp_text and len(response.content) > 10000:
                # resize small images, upscale
                upscaled = upscale(response.content)
                result.append(upscaled)
                WHO_AUTOR[utils.fast_hash(upscaled)] = url.split('/')[-1]
                return result

            if 'is currently loading","estimated_time":' in str(resp_text) or \
                '"error":"Internal Server Error"' in str(resp_text) or \
                '"CUDA out of memory' in str(resp_text) or \
                '"error":"Service Unavailable"' in str(resp_text):
                if DEBUG:
                    my_log.log_huggin_face_api(f'my_genimg:huggin_face_api: {resp_text} | {proxy} | {url}')
            else: # unknown error
                my_log.log_huggin_face_api(f'my_genimg:huggin_face_api: {resp_text} | {proxy} | {url}')
            time.sleep(10)

        return result

    pool = ThreadPool(processes=len(API_URL))
    async_results = []
    for x in API_URL:
        async_results.append(pool.apply_async(request_img, (prompt, x, payload,)))

    result = []
    for x in async_results:
        result += x.get()

    result = list(set(result))

    return result


def huggin_face_api_one_image(
    url: str,
    positive_prompt: str,
    negative_prompt: str,
    retries: int = 5,
    delay: int = 10,
    timeout: int = 120,
    ) -> bytes:
    """
    –ü–æ–ø—ã—Ç–∫–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Hugging Face API —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º –∏ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –ø—Ä–æ–º–ø—Ç–∞–º–∏.
    –ü—ã—Ç–∞–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –≤ —Å–ª—É—á–∞–µ –Ω–µ—É–¥–∞—á–∏, –∏—Å–ø–æ–ª—å–∑—É—è —Å–ª—É—á–∞–π–Ω—ã–µ –∫–ª—é—á–∏ API.

    Args:
        url (str): URL API Hugging Face.
        positive_prompt (str): –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç.
        negative_prompt (str): –û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç.
        retries (int): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫.
        delay (int): –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö).

    Returns:
        bytes: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –±–∞–π—Ç–∞—Ö.
    """
    if not ALL_KEYS:
        # raise Exception("–ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∫–ª—é—á–µ–π –¥–ª—è Hugging Face API")
        return []

    payload = json.dumps({
        "inputs": positive_prompt, 
        "negative_prompt": negative_prompt,
    })

    start_time = time.time()
    for attempt in range(retries):
        api_key = random.choice(ALL_KEYS)  # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –∫–ª—é—á
        headers = {"Authorization": f"Bearer {api_key}"}

        try:
            response = requests.post(url, headers=headers, data=payload, timeout=timeout)

            if response.status_code == 200 and len(response.content) > 100:
                # my_log.log_huggin_face_api(f"–£—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}")
                return response.content


            # –õ–æ–≥–∏—Ä—É–µ–º –æ—à–∏–±–∫—É —Å—Ç–∞—Ç—É—Å–∞
            # my_log.log_huggin_face_api(f"huggin_face_api_one_image: –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1} –Ω–µ —É–¥–∞–ª–∞—Å—å: —Å—Ç–∞—Ç—É—Å {response.status_code}, –æ—Ç–≤–µ—Ç: {response.text[:300]}")

        except Exception as e:
            error_traceback = traceback.format_exc()
            my_log.log_huggin_face_api(f"huggin_face_api_one_image: {str(e)}\n–¢—Ä–∞—Å—Å–∏—Ä–æ–≤–∫–∞: {error_traceback}")

        end_time = time.time()
        if end_time - start_time > timeout:
            return b''

        time.sleep(delay)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –Ω–æ–≤–æ–π –ø–æ–ø—ã—Ç–∫–æ–π

    # raise Exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ–ø—ã—Ç–æ–∫")
    return b''


def size_of_image(data: bytes):
    """
    Calculate the size of an image from the given byte data.

    Args:
        data (bytes): The byte data of the image.

    Returns:
        tuple: A tuple containing the width and height of the image.
    """
    img = PIL.Image.open(io.BytesIO(data))
    return img.size


def glm(prompt: str, width: int = 1024, height: int = 1024, num: int = 1, negative_prompt: str = ""):
    """
    Generates images based on a prompt using the bigmodel.cn API.

    Args:
        prompt (str): The prompt for generating the images.
        width (int, optional): The width of the images. Defaults to 1024.
        height (int, optional): The height of the images. Defaults to 1024.
        num (int, optional): The number of images to generate. Defaults to 1.

    Returns:
        list: A list of generated images in bytes format.
    """
    try:
        if hasattr(cfg, 'GLM_IMAGES') and cfg.GLM_IMAGES:
            images = my_glm.txt2img(prompt, user_id='-')
            results = []
            if images:
                for image in images:
                    data = utils.download_image_as_bytes(image)
                    WHO_AUTOR[utils.fast_hash(data)] = 'bigmodel.cn cogView-3-plus'
                    results.append(data)
                return results

    except Exception as error:
        error_traceback = traceback.format_exc()
        my_log.log_huggin_face_api(f'glm: {error}\n\n{error_traceback}')

    return []


def kandinski(prompt: str, width: int = 1024, height: int = 1024, num: int = 1, negative_prompt: str = ""):
    """
    Generates images based on a prompt using the KANDINSKI_API.

    Args:
        prompt (str): The prompt for generating the images.
        width (int, optional): The width of the images. Defaults to 1024.
        height (int, optional): The height of the images. Defaults to 1024.
        num (int, optional): The number of images to generate. Defaults to 1.

    Returns:
        list: A list of generated images in bytes format.
    """
    try:
        if not hasattr(cfg, 'KANDINSKI_API') or not cfg.KANDINSKI_API:
            return []
        keys = cfg.KANDINSKI_API[:]
        key = random.choice(keys)
        AUTH_HEADERS = {
            'X-Key': f'Key {key[0]}',
            'X-Secret': f'Secret {key[1]}',
        }
        params = {
            "type": "GENERATE",
            "numImages": num,
            "width": width,
            "height": height,
            "generateParams": {
            "query": f"{prompt}"
		    }
	    }
        def get_model():
            response = requests.get('https://api-key.fusionbrain.ai/key/api/v1/models', headers=AUTH_HEADERS)
            data = response.json()
            return data[0]['id']

        data = {
            'model_id': (None, get_model()),
            'params': (None, json.dumps(params), 'application/json')
        }
        response = requests.post('https://api-key.fusionbrain.ai/key/api/v1/text2image/run', headers=AUTH_HEADERS, files=data, timeout=120)
        data = response.json()
        try:
            uuid = data['uuid']
        except KeyError:
            return []

        def check_generation(request_id, attempts=10, delay=10):
            while attempts > 0:
                response = requests.get('https://api-key.fusionbrain.ai/key/api/v1/text2image/status/' + request_id, headers=AUTH_HEADERS)
                data = response.json()
                if  data['censored']:
                    return []
                if data['status'] == 'DONE':
                    return data['images']
                attempts -= 1
                time.sleep(delay)

        images = check_generation(uuid)
        if images:
            results = []
            for image in images:
                data = base64.b64decode(image)
                WHO_AUTOR[utils.fast_hash(data)] = 'fusionbrain.ai'
                results.append(data)
            return results
        else:
            return []

    except Exception as error:
        error_traceback = traceback.format_exc()
        my_log.log_huggin_face_api(f'my_genimg:kandinski: {error}\n\n{error_traceback}')

    return []


def get_reprompt(prompt: str, conversation_history: str = '', chat_id: str = '') -> tuple[str, str] | None:
    """
    Function to get a reprompt for image generation based on user's prompt and conversation history.
    Parameters:
    - prompt: a string containing the user's prompt
    - conversation_history: a string containing the conversation history
    Returns:
    - a string representing the reprompt for image generation
    """
    try:
        conversation_history = conversation_history.replace('ùêîùêíùêÑùêë:', 'user:')
        conversation_history = conversation_history.replace('ùêÅùêéùêì:', 'bot:')

        prompt = prompt.strip()
        dont_translate = prompt.startswith('!')
        prompt = re.sub(r'^!+', '', prompt).strip()

        query = f'''
User want to create image with text to image generator.
Repromt user's PROMPT for image generation.
Generate a good detailed prompt in english language, image generator accept only english so translate if needed.
Answer as a professional image prompt engineer, answer completely grammatically correct and future rich, add details if it was short.
A negative prompt in image generation lets you specify what you DON'T want to see in the picture. It helps exclude unwanted objects, styles, colors, or other characteristics, giving you more control over the result and speeding up the generation process.

Example:

Prompt: "Cat in a wizard hat"

Negative prompt: "sad, angry, blurry, cartoon"

Result: The AI will generate an image of a cat in a wizard hat that looks realistic, rather joyful or neutral, not sad or angry, and the image will be sharp, not blurry.

Start your prompt with word Generate.


User's PROMPT: {prompt}

Dialog history: {conversation_history}

Using this JSON schema:
  reprompt = {{"was_translated": str, "lang_from": str, "reprompt": str, "negative_reprompt": str, "moderation_sexual": bool, "moderation_hate": bool}}
Return a `reprompt`
'''

        negative = ''
        reprompt = ''
        r = ''

        if not r:
            r = my_gemini.get_reprompt_for_image(query, chat_id)
        if r:
            reprompt, negative, moderation_sex, moderation_hate = r
            if moderation_sex or moderation_hate:
                return 'MODERATION', None
        if not reprompt:
            r = my_groq.get_reprompt_for_image(query, chat_id)
            if r:
                reprompt, negative, moderation_sex, moderation_hate = r
                if moderation_sex or moderation_hate:
                    return 'MODERATION', None

    except Exception as error:
        error_traceback = traceback.format_exc()
        my_log.log_huggin_face_api(f'my_genimg:get_reprompt: {error}\n\nPrompt: {prompt}\n\n{error_traceback}')
    if dont_translate:
        my_log.log_reprompts(f'get_reprompt:\n\n{prompt}\n\n{prompt}\n\nNegative: {negative}')
    else:
        my_log.log_reprompts(f'get_reprompt:\n\n{prompt}\n\n{reprompt}\n\nNegative: {negative}')

    if dont_translate:
        return prompt, negative

    return reprompt, negative




@utils.async_run
def bing_get_one_round(reprompt: str, user_id: str, container):
    '''fill containers with results (0-4 images)'''
    r = bing(reprompt, user_id=user_id)
    if r:
        container += r
    else:
        container += ['none',]


def count_running_bing_threads() -> list[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—É—â–µ–Ω–Ω—ã—Ö –ø–æ—Ç–æ–∫–æ–≤ bing."""
    thread_list = threading.enumerate()
    thread_names = [thread.name for thread in thread_list if 'bing_get_one_round' in thread.name]
    return len(thread_names)


def gen_images_bing_only(prompt: str, user_id: str = '', conversation_history: str ='', iterations: int = 1) -> list:
    if iterations == 0:
        iterations = 1

    if prompt.strip() == '':
        return []

    reprompt, _ = get_reprompt(prompt, conversation_history)
    if reprompt == 'MODERATION':
        if hasattr(cfg, 'ALLOW_PASS_NSFW_FILTER') and utils.extract_user_id(user_id) in cfg.ALLOW_PASS_NSFW_FILTER:
            prompt = re.sub(r'^!+', '', prompt).strip()
            reprompt = prompt
        else:
            return ['moderation',]

    if reprompt:
        prompt = re.sub(r'^!+', '', prompt).strip()
        result = []

        max_threads = len([x for x in bing_img.COOKIE.keys()])
        if max_threads > 4:
            max_threads = max_threads - 2 # leave 2 threads for other tasks
        else:
            max_threads = 1

        containers = {}

        for i in range(iterations):
            containers[i] = []
            bing_get_one_round(reprompt, user_id, containers[i])
            while count_running_bing_threads() >= max_threads:
                time.sleep(1)

        while True:
            time.sleep(1)
            ready_containers = sum(1 for value_list in containers.values() if value_list)
            if ready_containers == iterations:
                break

        result = [s for value_list in containers.values() for s in value_list if s != 'none']

        return result
    return []




def gen_images(prompt: str, moderation_flag: bool = False,
               user_id: str = '',
               conversation_history: str = '',
               use_bing: bool = True) -> list:
    """—Ä–∏—Å—É–µ—Ç –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –≤—Å–µ–º–∏ –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ —Å–ø–æ—Å–æ–±–∞–º–∏"""

    if not user_id:
        user_id = 'test'

    if user_id in LOCKS:
        lock = LOCKS[user_id]
    else:
        lock = threading.Lock()
        LOCKS[user_id] = lock

    with lock:
        if prompt.strip() == '':
            return []

        negative = ''

        reprompt = ''
        if use_bing:
            reprompt, negative = get_reprompt(prompt, conversation_history, user_id)
            if reprompt == 'MODERATION':
                return ['moderation',]

        if reprompt:
            prompt = reprompt
        else:
            return []

        pool = ThreadPool(processes=9)

        async_result1 = pool.apply_async(bing, (prompt, moderation_flag, user_id))

        async_result2 = pool.apply_async(kandinski, (prompt, 1024, 1024, 1, negative))
        async_result3 = pool.apply_async(kandinski, (prompt, 1024, 1024, 1, negative))

        async_result4 = pool.apply_async(huggin_face_api, (prompt, negative))

        async_result9 = pool.apply_async(glm, (prompt, negative))

        result = (async_result1.get() or []) + \
                 (async_result2.get() or []) + \
                 (async_result3.get() or []) + \
                 (async_result4.get() or []) + \
                 (async_result9.get() or [])

        return result


def test_hkey(key: str):
    '''test huggingface key'''
    API_URL = [
        "https://api-inference.huggingface.co/models/ehristoforu/dalle-3-xl-v2",
        "https://api-inference.huggingface.co/models/digiplay/Juggernaut_final",
        "https://api-inference.huggingface.co/models/RunDiffusion/Juggernaut-X-v10",
        "https://api-inference.huggingface.co/models/dataautogpt3/TempestV0.1",
        "https://api-inference.huggingface.co/models/UnfilteredAI/NSFW-gen-v2",
    ]

    payload = json.dumps({"inputs": 'golden apple', "negative_prompt": 'big',})

    n = 1
    while n > 0:
        n -= 1

        if hasattr(cfg, 'bing_proxy'):
            proxy = {'http': random.choice(cfg.bing_proxy), 'https': random.choice(cfg.bing_proxy)}
        else:
            proxy = None
        api_key = key
        headers = {"Authorization": f"Bearer {api_key}"}

        try:
            response = requests.post(API_URL[0], headers=headers, json=payload, timeout=10, proxies=proxy)
        except Exception as error:
            # print(error)
            my_log.log_keys(f'hf key test error: {api_key}\n\n{str(error)}')
            continue

        try:
            resp_text = response.text
        except:
            return True
        # print(resp_text)
        if 'Authorization header is correct, but the token seems invalid' in resp_text:
            my_log.log_keys(f'hf key test error: {resp_text}\n{api_key}\n\n{str(response)}')
            return False

    return True


def guess_hf_url(url: str) -> str:
    if url.startswith('http'):
        return url
    else:
        if '/' in url:
            url = 'https://api-inference.huggingface.co/models/' + url
        else:
            try:
                if os.path.exists('huggin_face_models_urls.list'):
                    with open('huggin_face_models_urls.list', 'r') as f:
                        API_URL = f.read().splitlines()
                    API_URL = [x.strip() for x in API_URL if x.strip() and not x.strip().startswith('#')]
                    for x in API_URL:
                        if url in x:
                            url = x
                            break
                    if not url.startswith('http'):
                        return ''
            except:
                return ''
    return url


def gen_one_image(prompt: str,
               user_id: str = '',
               url: str = '',
               ) -> bytes:
    """—Ä–∏—Å—É–µ—Ç —É–∫–∞–∑–∞–Ω–Ω–æ–π –≤ —É—Ä–ª–µ –º–æ–¥–µ–ª—å–∫–æ–π —Ö–∞–≥–≥–∏–Ω–≥ —Ñ–µ–π—Å–∞"""

    url = guess_hf_url(url)
    if not url or not url.startswith('https://api-inference.huggingface.co/models/'):
        return None

    if not user_id:
        user_id = 'test'

    if prompt.strip() == '':
        return None

    negative = ''

    reprompt = ''

    reprompt, negative = get_reprompt(prompt, '', user_id)
    if reprompt == 'MODERATION':
        return None

    if reprompt:
        prompt = reprompt
    else:
        return None

    result = huggin_face_api_one_image(
        url,
        prompt,
        negative
        )

    return result


if __name__ == '__main__':
    load_users_keys()
    my_groq.load_users_keys()

    # print(get_reprompt('–ü–æ—Ç—Ä—è—Å–∞—é—â–∞—è –±–ª–æ–Ω–¥–∏–Ω–∫–∞ —Å –¥–ª–∏–Ω–Ω—ã–º–∏ —Ä–∞—Å–ø—É—â–µ–Ω–Ω—ã–º–∏ –≤–æ–ª–æ—Å–∞–º–∏ —Å–∏–¥–∏—Ç –Ω–∞ –¥–µ—Ä–µ–≤—è–Ω–Ω–æ–π –ª–µ—Å—Ç–Ω–∏—Ü–µ. –ù–∞ –Ω–µ–π –º–∏–Ω–∏–º—É–º –æ–¥–µ–∂–¥—ã, –µ–µ —Ç–µ–ª–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤–∏–¥–Ω–æ —Å –∞–∫—Ü–µ–Ω—Ç–æ–º –Ω–∞ –≤—É–ª—å–≤—É, –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É—è –µ–µ –≥–ª–∞–¥–∫—É—é, –±–µ–∑—É–ø—Ä–µ—á–Ω—É—é –∫–æ–∂—É –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—É—é –∫—Ä–∞—Å–æ—Ç—É. –û—Å–≤–µ—â–µ–Ω–∏–µ –º—è–≥–∫–æ–µ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ, –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞—é—â–µ–µ –µ–µ –∏–∑–≥–∏–±—ã –∏ —Ç–µ–∫—Å—Ç—É—Ä—É –∫–æ–∂–∏. –í—ã—Å–æ–∫–∞—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è, —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ 8K, —Ñ–æ—Ç–æ—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è, –æ—Ç–º–µ—á–µ–Ω–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞–º–∏.'))

    print(gen_images_bing_only('golden apple', iterations=2))
