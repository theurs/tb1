#!/usr/bin/env python3

import cachetools.func
import concurrent.futures
import datetime
import functools
import hashlib
import io
import json
import html
import os
import pathlib
import pickle
import pysrt
import pytz
import random
import re
import regex
import requests
import shutil
import string
import subprocess
import tempfile
import threading
import time
import traceback
import platform as platform_module
from typing import Any, Union, List, Tuple

import json_repair
import markdownify
import PIL
import telebot
from bs4 import BeautifulSoup

from pylatexenc.latex2text import LatexNodes2Text
from pillow_heif import register_heif_opener
from prettytable import PrettyTable
from textwrap import wrap

import cfg
import my_log


register_heif_opener()


LOCK_TRANSCODE = threading.Lock()


def async_run(func):
    '''–î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Ñ—É–Ω–∫—Ü–∏–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ, –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ'''
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        thread = threading.Thread(target=func, args=args, kwargs=kwargs)
        thread.start()
    return wrapper


def async_run_with_limit(max_threads: int):
    """
    Decorator to run a function in a separate thread asynchronously,
    with a limit on the number of concurrent threads.

    Args:
        max_threads: The maximum number of threads allowed to run concurrently.
    """
    semaphore = threading.Semaphore(max_threads)

    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            def task():
                try:
                    func(*args, **kwargs)
                finally:
                    semaphore.release()

            semaphore.acquire()
            thread = threading.Thread(target=task)
            thread.start()
            return thread  # Optionally return the thread object
        return wrapper
    return decorator


def get_file_ext(fname: str) -> str:
    '''return extension of file using pathlib'''
    try:
        p = pathlib.Path(fname)
        return p.suffix
    except Exception as error:
        my_log.log2(f'utils:get_file_ext {error}\n{fname}')
        return ''


def split_text(text: str, chunk_limit: int = 1500):
    """ Splits one string into multiple strings, with a maximum amount of chars_per_string
        characters per string. This is very useful for splitting one giant message into multiples.
        If chars_per_string > 4096: chars_per_string = 4096. Splits by '\n', '. ' or ' ' in exactly
        this priority.

        :param text: The text to split
        :type text: str

        :param chars_per_string: The number of maximum characters per part the text is split to.
        :type chars_per_string: int

        :return: The splitted text as a list of strings.
        :rtype: list of str
    """
    return telebot.util.smart_split(text, chunk_limit)


def split_text_my(text: str, chunk_limit: int = 1500):
    """—Ä–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ –∑–∞–¥–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã –Ω–µ —Ä–∞–∑—Ä—ã–≤–∞—è —Å–ª–æ–≤–∞,
    –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∫—É—Å–∫–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ —á–µ–º –∑–∞–¥–∞–Ω–æ, –µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –ø—Ä–æ–±–µ–ª–æ–≤ —Ç–æ –Ω–∞–º–Ω–æ–≥–æ –±–æ–ª—å—à–µ –ñ)"""
    # —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —á–∞—Å—Ç–µ–π —Ç–µ–∫—Å—Ç–∞
    chunks = []
    # —Å–æ–∑–¥–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–π –ø–æ–∑–∏—Ü–∏–∏ –≤ —Ç–µ–∫—Å—Ç–µ
    position = 0
    # –ø–æ–∫–∞ –ø–æ–∑–∏—Ü–∏—è –º–µ–Ω—å—à–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
    while position < len(text):
        # –Ω–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å –ø—Ä–æ–±–µ–ª–∞ –ø–æ—Å–ª–µ –ª–∏–º–∏—Ç–∞
        space_index = text.find(" ", position + chunk_limit)
        # –µ—Å–ª–∏ –ø—Ä–æ–±–µ–ª –Ω–µ –Ω–∞–π–¥–µ–Ω, —Ç–æ –±–µ—Ä–µ–º –≤–µ—Å—å –æ—Å—Ç–∞–≤—à–∏–π—Å—è —Ç–µ–∫—Å—Ç
        if space_index == -1:
            space_index = len(text)
        # –¥–æ–±–∞–≤–ª—è–µ–º —á–∞—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ –æ—Ç —Ç–µ–∫—É—â–µ–π –ø–æ–∑–∏—Ü–∏–∏ –¥–æ –ø—Ä–æ–±–µ–ª–∞ –≤ —Å–ø–∏—Å–æ–∫
        chunks.append(text[position:space_index])
        # –æ–±–Ω–æ–≤–ª—è–µ–º —Ç–µ–∫—É—â—É—é –ø–æ–∑–∏—Ü–∏—é –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π —Å–∏–º–≤–æ–ª –ø–æ—Å–ª–µ –ø—Ä–æ–±–µ–ª–∞
        position = space_index + 1
    # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫ —á–∞—Å—Ç–µ–π —Ç–µ–∫—Å—Ç–∞
    return chunks


def platform() -> str:
    """
    Return the platform information.
    """
    return platform_module.platform()


def bot_markdown_to_tts(text: str) -> str:
    """–º–µ–Ω—è–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –±–æ—Ç–æ–≤ —Ç–∞–∫ —á—Ç–æ –±—ã –º–æ–∂–Ω–æ –±—ã–ª–æ –∑–∞—á–∏—Ç–∞—Ç—å —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ TTS"""
    
    # –ø–µ—Ä–µ–¥–µ–ª—ã–≤–∞–µ–º —Å–ø–∏—Å–∫–∏ –Ω–∞ –±–æ–ª–µ–µ –∫—Ä–∞—Å–∏–≤—ã–µ
    new_text = ''
    for i in text.split('\n'):
        ii = i.strip()
        if ii.startswith('* '):
            i = i.replace('* ', '‚Ä¢ ', 1)
        if ii.startswith('- '):
            i = i.replace('- ', '‚Ä¢ ', 1)
        new_text += i + '\n'
    text = new_text.strip()

    # 1 –∏–ª–∏ 2 * –≤ 0 –∑–≤–µ–∑–¥–æ—á–µ–∫ *bum* -> bum
    text = re.sub('\*\*?(.*?)\*\*?', '\\1', text)

    # tex –≤ unicode
    matches = re.findall(r"(?:\$\$?|\\\[|\\\(|\\\[)(.*?)(?:\$\$?|\\\]|\\\)|\\\])", text, flags=re.DOTALL)
    for match in matches:
        new_match = LatexNodes2Text().latex_to_text(match.replace('\\\\', '\\'))
        text = text.replace(f'$${match}$$', new_match)
        text = text.replace(f'${match}$', new_match)
        text = text.replace(f'\[{match}\]', new_match)
        text = text.replace(f'\({match}\)', new_match)

    # –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤, –∫—Ä–æ–º–µ –±—É–∫–≤, —Ü–∏—Ñ—Ä –∏ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    pattern = regex.compile(r'[^\p{L}\p{N}\p{P} ]', re.UNICODE)
    # –ó–∞–º–µ–Ω–∞ –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
    text = pattern.sub('', text)

    return text


# –≥—Ä–µ–±–∞–Ω—ã–π –º–∞—Ä–∫–¥–∞—É–Ω ###################################################################

def replace_math_byte_sequences(text: str) -> str:
    """
    Replaces byte sequences like <0xXX><0xYY><0xZZ> with their corresponding Unicode characters.

    Args:
        text: The input string containing the byte sequences.

    Returns:
        The string with the byte sequences replaced by Unicode characters.
    """
    def replace(match: re.Match) -> str:
        hex_byte1 = match.group(1)
        hex_byte2 = match.group(2)
        hex_byte3 = match.group(3)
        byte_values = [int(hex_byte1, 16), int(hex_byte2, 16), int(hex_byte3, 16)]
        try:
            return bytes(byte_values).decode('utf-8')
        except UnicodeDecodeError:
            return match.group(0)

    pattern = r'<0x([0-9a-fA-F]{2})><0x([0-9a-fA-F]{2})><0x([0-9a-fA-F]{2})>'
    replaced_text = re.sub(pattern, replace, text)
    return replaced_text


def bot_markdown_to_html(text: str) -> str:
    # –ø–µ—Ä–µ–¥–µ–ª—ã–≤–∞–µ—Ç –º–∞—Ä–∫–¥–∞—É–Ω –æ—Ç —á–∞—Ç–±–æ—Ç–æ–≤ –≤ —Ö—Ç–º–ª –¥–ª—è —Ç–µ–ª–µ–≥—Ä–∞–º–∞
    # —Å–Ω–∞—á–∞–ª–∞ –¥–µ–ª–∞–µ—Ç—Å—è –ø–æ–ª–Ω–æ–µ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
    # –∑–∞—Ç–µ–º –º–µ–Ω—è—é—Ç—Å—è –º–∞—Ä–∫–¥–∞—É–Ω —Ç–µ–≥–∏ –∏ –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏–µ –Ω–∞ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–µ –≤ —Ö—Ç–º–ª
    # –ø—Ä–∏ —ç—Ç–æ–º –Ω–µ –∑–∞—Ç—Ä–∞–≥–∏–≤–∞–µ—Ç—Å—è —Ç–æ —á—Ç–æ –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–æ–≤ –∫–æ–¥, —Ç–∞–º —Ç–æ–ª—å–∫–æ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
    # –ª–∞—Ç–µ–∫—Å –∫–æ–¥ –≤ —Ç–µ–≥–∞—Ö $ –∏ $$ –º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ —é–Ω–∏–∫–æ–¥ —Ç–µ–∫—Å—Ç


    # –°–ª–æ–≤–∞—Ä—å –ø–æ–¥—Å—Ç—Ä–æ—á–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
    subscript_map = {
        '0': '‚ÇÄ', '1': '‚ÇÅ', '2': '‚ÇÇ', '3': '‚ÇÉ', '4': '‚ÇÑ', '5': '‚ÇÖ',
        '6': '‚ÇÜ', '7': '‚Çá', '8': '‚Çà', '9': '‚Çâ',
        '+': '‚Çä', '-': '‚Çã', '=': '‚Çå', '(': '‚Çç', ')': '‚Çé',
        'a': '‚Çê',
        # 'b': '‚ô≠', 
        'c': 'ÍúÄ',
        # 'd': '·ëØ',
        'e': '‚Çë',
        # 'f': '‚®ç',
        'g': '‚Çâ',
        'h': '‚Çï',
        'i': '·µ¢',
        'j': '‚±º',
        'k': '‚Çñ',
        'l': '‚Çó',
        'm': '‚Çò',
        'n': '‚Çô',
        'o': '‚Çí',
        'p': '‚Çö',
        # 'q': '‡´ß',
        'r': '·µ£',
        's': '‚Çõ',
        't': '‚Çú',
        'u': '·µ§',
        'v': '·µ•',
        # 'w': 'w',
        'x': '‚Çì',
        'y': '·µß',
        'z': '‚ÇÇ'
    }

    # –°–ª–æ–≤–∞—Ä—å –Ω–∞–¥—Å—Ç—Ä–æ—á–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
    superscript_map = {
        '0': '‚Å∞', '1': '¬π', '2': '¬≤', '3': '¬≥', '4': '‚Å¥', '5': '‚Åµ',
        '6': '‚Å∂', '7': '‚Å∑', '8': '‚Å∏', '9': '‚Åπ',
        '+': '‚Å∫', '-': '‚Åª', '=': '‚Åº', '(': '‚ÅΩ', ')': '‚Åæ',
        'a': '·µÉ',
        'b': '·µá',
        'c': '·∂ú',
        'd': '·µà',
        'e': '·µâ',
        'f': '·∂†',
        'g': '·µç',
        'h': ' ∞',
        'i': '‚Å±',
        'j': ' ≤',
        'k': '·µè',
        'l': 'À°',
        'm': '·µê',
        'n': '‚Åø',
        'o': '·µí',
        'p': '·µñ',
        'q': 'êû•', 
        'r': ' ≥',
        's': 'À¢',
        't': '·µó',
        'u': '·µò',
        'v': '·µõ',
        'w': ' ∑',
        'x': 'À£',
        'y': ' ∏',
        'z': '·∂ª'
    }

    # –º–µ–Ω—è–µ–º —Ç—Ä–µ—Ö–±–∞–π—Ç–æ–≤—ã–µ —É—Ç—Ñ8 —Å–∏–º–≤–æ–ª—ã –¥–ª—è –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ –±–æ—Ç –∏–Ω–æ–≥–¥–∞ –≤—Å—Ç–∞–≤–ª—è–µ—Ç –≤–º–µ—Å—Ç–æ —Å–∞–º–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
    text = replace_math_byte_sequences(text)

    # —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –¥–ª—è html, –ø–æ—Ç–æ–º –Ω–∞–¥–æ –±—É–¥–µ—Ç –≤–µ—Ä–Ω—É—Ç—å —Ç–µ–≥–∏ <u>
    text = html.escape(text)

    # –Ω–∞–¥–æ –∑–∞—Ä–∞–Ω–µ–µ –Ω–∞–π—Ç–∏ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö –±–ª–æ–∫–∏ –∫–æ–¥–∞ (–æ–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω–æ–≥–æ `–∫–æ–¥–∞`) –∏ –∑–∞–º–µ–Ω–∏—Ç—å ` –Ω–∞ –ø—Ä–æ–±–µ–ª—ã
    text = clear_tables(text)

    # –∑–∞–º–µ–Ω—è–µ–º —Å—Ç—Ä–∞–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è –∫–æ–¥–∞ –∫–æ–≥–¥–∞ –∏–¥–µ—Ç 0-6 –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –Ω–∞—á–∞–ª–µ –ø–æ—Ç–æ–º ` –∏–ª–∏ `` –∏–ª–∏ ``` –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —è–∑—ã–∫–∞
    pattern = r"^ {0,6}`{1,3}(\w+)\n(.*?)\n  {0,6}`{1,3}$"
    # replacement = r"```\1\n\2\n```"
    replacement = lambda match: f"```{match.group(1)}\n{re.sub(r'^ {1,6}', '', match.group(2), flags=re.MULTILINE)}\n```"
    text = re.sub(pattern, replacement, text, flags=re.MULTILINE | re.DOTALL)


    # –Ω–∞–π—Ç–∏ –≤—Å–µ –∫—É—Å–∫–∏ –∫–æ–¥–∞ –º–µ–∂–¥—É ``` –∏ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Ö–µ—à–∏
    # —Å–ø—Ä—è—Ç–∞—Ç—å –∫–æ–¥ –Ω–∞ –≤—Ä–µ–º—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
    matches = re.findall('```(.*?)```\n', text, flags=re.DOTALL)
    list_of_code_blocks = []
    for match in matches:
        random_string = str(hash(match))
        list_of_code_blocks.append([match, random_string])
        text = text.replace(f'```{match}```', random_string)

    matches = re.findall('```(.*?)```', text, flags=re.DOTALL)
    for match in matches:
        random_string = str(hash(match))
        list_of_code_blocks.append([match, random_string])
        text = text.replace(f'```{match}```', random_string)

    # –∑–∞–º–µ–Ω–∞ —Ç–µ–≥–æ–≤ <sub> <sup> –Ω–∞ –ø–æ–¥—Å—Ç—Ä–æ—á–Ω—ã–µ –∏ –Ω–∞–¥—Å—Ç—Ä–æ—á–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    text = re.sub(r'&lt;sup&gt;(.*?)&lt;/sup&gt;', lambda m: ''.join(superscript_map.get(c, c) for c in m.group(1)), text)
    text = re.sub(r'&lt;sub&gt;(.*?)&lt;/sub&gt;', lambda m: ''.join(subscript_map.get(c, c) for c in m.group(1)), text)

    # —Ç—É—Ç –º–æ–≥—É—Ç –±—ã—Ç—å –æ–¥–∏–Ω–æ—á–Ω—ã–µ –ø–æ–≤–æ—Ä—è—é—â–∏–µ—Å—è `, –º–µ–Ω—è–µ–º –∏—Ö –Ω–∞ '
    text = text.replace('```', "'''")

    matches = re.findall('`(.*?)`', text)
    list_of_code_blocks2 = []
    for match in matches:
        random_string = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(16))
        list_of_code_blocks2.append([match, random_string])
        text = text.replace(f'`{match}`', random_string)

    # –º–µ–Ω—è–µ–º –ª–∞—Ç–µ–∫—Å –≤—ã—Ä–∞–∂–µ–Ω–∏—è
    text = replace_latex(text)

    # —Å–æ—Ö—Ä–∞–Ω—è–µ–º 3 –∑–≤–µ–∑–¥—ã —á—Ç–æ –±—ã –∏—Ö –Ω–µ –∏—Å–ø–æ—Ä—Ç–∏–ª –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä —Å–ø–∏—Å–∫–æ–≤
    def replace_3_stars(match):
        indent = match.group(0).split('*')[0] # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ
        return indent + '‚Ä¢ ‚Ä¢ ‚Ä¢'
    text = re.sub(r"^\s*\*\s*\*\s*\*\s*$", replace_3_stars, text, flags=re.MULTILINE)

    # –ø–µ—Ä–µ–¥–µ–ª—ã–≤–∞–µ–º —Å–ø–∏—Å–∫–∏ –Ω–∞ –±–æ–ª–µ–µ –∫—Ä–∞—Å–∏–≤—ã–µ
    text = re.sub(r"^(\s*)\*\s", r"\1‚Ä¢ ", text, flags=re.MULTILINE)
    # text = re.sub(r"^(\s*)-\s", r"\1‚Äì ", text, flags=re.MULTILINE)

    # 1,2,3,4 # –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏ –º–µ–Ω—è–µ–º –≤—Å—é —Å—Ç—Ä–æ–∫—É –Ω–∞ –∂–∏—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç
    text = re.sub(r"^(?:\.\s)?#(?:#{0,})\s(.*)$", r"<b>\1</b>", text, flags=re.MULTILINE)  # 1+ hashes

    # —Ü–∏—Ç–∞—Ç—ã –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å &gt; –∏—Ö –Ω–∞–¥–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ <blockquote></blockquote>
    # &gt; –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ª–∏–±–æ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏, –ª–∏–±–æ —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±–µ–ª—ã –ø–æ—Ç–æ–º &gt;
    # –µ—Å–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ä—è–¥ —Å—Ç—Ä–æ–∫ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å &gt; —Ç–æ –∏—Ö –≤—Å–µ—Ö –Ω–∞–¥–æ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤ –æ–¥–∏–Ω –±–ª–æ–∫ <blockquote>
    def process_quotes(text):
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏
        lines = text.split('\n')
        result = []
        quote_lines = []
        
        for line in lines:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ —Ü–∏—Ç–∞—Ç–æ–π (—Å —É—á–µ—Ç–æ–º –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –Ω–∞—á–∞–ª–µ)
            if re.match('^\s*&gt;\s*(.*)$', line):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ &gt;
                quote_content = re.sub('^\s*&gt;\s*(.*)$', '\\1', line)
                quote_lines.append(quote_content)
            else:
                # –ï—Å–ª–∏ –Ω–∞–∫–æ–ø–∏–ª–∏—Å—å —Ü–∏—Ç–∞—Ç—ã, –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                if quote_lines:
                    quote_text = '\n'.join(quote_lines)
                    result.append(f'<blockquote>{quote_text}</blockquote>')
                    quote_lines = []
                result.append(line)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Ü–∏—Ç–∞—Ç—ã –≤ –∫–æ–Ω—Ü–µ —Ç–µ–∫—Å—Ç–∞
        if quote_lines:
            quote_text = '\n'.join(quote_lines)
            result.append(f'<blockquote>{quote_text}</blockquote>')
        
        return '\n'.join(result)

    text = process_quotes(text)

    # –∑–∞–º–µ–Ω–∏—Ç—å –¥–≤–æ–π–Ω—ã–µ –∏ —Ç—Ä–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –≤ —Ç–µ–∫—Å—Ç–µ (—Ç–æ–ª—å–∫–æ —Ç–µ —á—Ç–æ –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏ –∏ –∑–Ω–∞–∫–∞–º–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è)
    text = re.sub(r"(?<=\S) {2,}(?=\S)", " ", text)

    # –∑–∞–º–µ–Ω–∏—Ç—å –∑–∞–ø–∏—Å–∏ —Ç–∏–ø–∞ \boxed{1.7} –Ω–∞ „Äê1.7„Äë
    text = re.sub(r"\\boxed\{([^}]*)\}", r"„Äê\1„Äë", text)

    # —É–¥–∞–ª–∏—Ç—å —Å—Ç—Ä–∞–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏ –≤–∏–¥–∞ <binary data, 1 bytes>
    text = text.replace('&lt;binary data, 1 bytes&gt;', '')

    # First handle _*text*_ pattern (italic-bold combined)
    text = re.sub(r"(?<!\w)_\*([^\n\s].*?[^\n\s])\*_(?!\w)", r"<i><b>\1</b></i>", text)

    # Handle **_text_** pattern (bold-italic combined)
    text = re.sub(r"\*\*_(.+?)_\*\*", r"<b><i>\1</i></b>", text)

    # Handle _**text**_ pattern (italic-bold combined)
    text = re.sub(r"_\*\*(.+?)\*\*_", r"<i><b>\1</b></i>", text)

    # Handle *_text_* pattern (bold-italic combined)
    text = re.sub(r"\*_(.+?)_\*", r"<i><b>\1</b></i>", text)

    # Handle standalone bold (**text**)
    text = re.sub(r'\*\*([^*]+?)\*\*', r'<b>\1</b>', text)
    text = re.sub(r'^\*\*(.*?)\*\*$', r'<b>\1</b>', text, flags=re.MULTILINE | re.DOTALL)

    # Handle standalone italics (_text_ or *text*)
    text = re.sub(r"(?<!\w)_([^\n\s_*][^\n*_]*[^\n\s_*])_(?!\w)", r"<i>\1</i>", text)
    text = re.sub(r"(?<!\w)\*(?!\s)([^\n*]+?)(?<!\s)\*(?!\w)", r"<i>\1</i>", text)



    # 2 _ –≤ <i></i>
    text = re.sub('\_\_(.+?)\_\_', '<i>\\1</i>', text)
    text = re.sub(r'^\_\_(.*?)\_\_$', r'<i>\1</i>', text, flags=re.MULTILINE | re.DOTALL)

    # –ó–∞–º–µ–Ω–∞ _*—Ç–µ–∫—Å—Ç*_ –Ω–∞ <i>—Ç–µ–∫—Å—Ç</i>
    text = re.sub(r"(?<!\w)_\*([^\n\s].*?[^\n\s])\*_(?!\w)", r"<i>\1</i>", text)

    # –ó–∞–º–µ–Ω–∞ ~~—Ç–µ–∫—Å—Ç~~ –Ω–∞ <s>—Ç–µ–∫—Å—Ç</s>
    text = re.sub(r"(?<!\w)~~(?!\s)([^\n*]+?)(?<!\s)~~(?!\w)", r"<s>\1</s>", text)

    # –ó–∞–º–µ–Ω–∞ ||—Ç–µ–∫—Å—Ç|| –Ω–∞ <tg-spoiler>—Ç–µ–∫—Å—Ç</tg-spoiler>
    text = re.sub(r"(?<!\w)\|\|(?!\s)([^\n*]+?)(?<!\s)\|\|(?!\w)", r"<tg-spoiler>\1</tg-spoiler>", text)

    # –∑–∞–º–µ–Ω–∞ <b><i> ... </b></i> –Ω–∞ <b><i> ... </i></b>
    text = re.sub(r"<b><i>(.+?)</b></i>", r"<b><i>\1</i></b>", text)
    text = re.sub(r"<i><b>(.+?)</i></b>", r"<i><b>\1</b></i>", text)

    # –£–¥–∞–ª–µ–Ω–∏–µ –ø–∞—Ä–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤ $ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    text = re.sub(r'\$(\S[^\$\n]*?\S)\$', r'\1', text)

    # –º–µ–Ω—è–µ–º –º–∞—Ä–∫–¥–∞—É–Ω —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ö—Ç–º–ª
    text = re.sub('''\[(.*?)\]\((https?://\S+)\)''', r'<a href="\2">\1</a>', text)

    # –º–µ–Ω—è–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Å—ã–ª–∫–∏ –≤ —Ö—Ç–º–ª —Ç–µ–≥–µ –∫—Ä–æ–º–µ —Ç–µ—Ö –∫—Ç–æ —É–∂–µ —Ç–∞–∫ –æ—Ñ–æ—Ä–º–ª–µ–Ω
    # –∞ –∑–∞—á–µ–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ? text = re.sub(r'(?<!<a href=")(https?://\S+)(?!">[^<]*</a>)', r'<a href="\1">\1</a>', text)

    # —Ö–∑ –æ—Ç–∫—É–¥–∞ —ç—Ç–æ
    text = text.replace('&#x27;', "'")
    text = text.replace('   #x27;', "'")
    text = text.replace('#x27;', "'")


    # –º–µ–Ω—è–µ–º —Ç–µ–≥–∏ &lt;u&gt;  &lt;/u&gt; –Ω–∞ <u></u>
    text = re.sub(r'&lt;u&gt;(.+?)&lt;/u&gt;', r'<u>\1</u>', text)

    # –º–µ–Ω—è–µ–º —Ç–∞–±–ª–∏—Ü—ã –¥–æ –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏—è –∫–æ–¥–∞
    text = replace_tables(text)

    # –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 3 –∑–≤–µ–∑–¥—ã
    def replace_3_stars2(match):
        indent = match.group(0).split('‚Ä¢')[0] # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ
        return indent + '* * *'
    text = re.sub(r"^\s*‚Ä¢\s*‚Ä¢\s*‚Ä¢\s*$", replace_3_stars2, text, flags=re.MULTILINE)


    def replace_asterisk_with_digits(text: str) -> str:
        """
        –ó–∞–º–µ–Ω—è–µ—Ç —Å–∏–º–≤–æ–ª \* –Ω–∞ * –≤ —Å—Ç—Ä–æ–∫–∞—Ö, –≥–¥–µ –µ—Å—Ç—å —Ü–∏—Ñ—Ä—ã.

        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç.

        Returns:
            –¢–µ–∫—Å—Ç —Å –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–º–∏ –∑–∞–º–µ–Ω–∞–º–∏.
        """
        lines = text.split('\n')
        modified_lines = []
        for line in lines:
            # if any(char.isdigit() for char in line):
            #     modified_line = re.sub(r'\\\*', '*', line)
            #     modified_line = re.sub(r'\\\[', '[', modified_line)
            #     modified_line = re.sub(r'\\\(', '(', modified_line)
            # else:
            #     modified_line = line
            # –ó–∞–º–µ–Ω—è–µ–º —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∏–º–≤–æ–ª '_' –µ—Å–ª–∏ –ø—Ä–∏–ª–µ–≥–∞–µ—Ç –∫ –±—É–∫–≤–∞–º
            # modified_line = re.sub(r"(?<=\w)\\_|\\_(?=\w)|(?<=\w)\\_(?=\w)", "_", modified_line)
            modified_line = re.sub(r'\\\*', '*', line)
            modified_line = re.sub(r'\\\[', '[', modified_line)
            modified_line = re.sub(r'\\\(', '(', modified_line)
            modified_line = re.sub(r'\\\)', ')', modified_line)
            modified_line = re.sub(r'\\\_', '_', modified_line)
            modified_lines.append(modified_line)
        return '\n'.join(modified_lines)

    text = replace_asterisk_with_digits(text)


    # –º–µ–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ —Ö–µ—à–∏ –Ω–∞ –±–ª–æ–∫–∏ –∫–æ–¥–∞
    for match, random_string in list_of_code_blocks2:
        # new_match = html.escape(match)
        new_match = match
        text = text.replace(random_string, f'<code>{new_match}</code>')

    # –º–µ–Ω—è–µ–º –æ–±—Ä–∞—Ç–Ω–æ —Ö–µ—à–∏ –Ω–∞ –±–ª–æ–∫–∏ –∫–æ–¥–∞
    for match, random_string in list_of_code_blocks:
        new_match = match
        text = text.replace(random_string, f'<code>{new_match}</code>')

    text = replace_code_lang(text)

    text = text.replace('<pre><code class="language-plaintext">\n<pre><code>', '<pre><code class="language-plaintext">')

    # —É–±—Ä–∞—Ç—å 3 –∏ –±–æ–ª–µ–µ –ø—É—Å—Ç—ã–µ —Å—Ä–æ–∫–∏ –ø–æ–¥—Ä—è–¥ (—Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –±–ª–æ–∫–æ–≤ –∫–æ–¥–∞ –∏–ª–∏ –ª—é–±—ã—Ö —Ç–µ–≥–æ–≤)
    def replace_newlines(match):
        return '\n\n'
    text = re.sub(r"(?<!<pre>)(?<!<code>)\n{3,}(?!</code>)(?!</pre>)", replace_newlines, text, flags=re.DOTALL)
    text = re.sub(r"pre>\n{2,}", "pre>\n", text)

    text = text.replace('\n</code></pre>\n</code>', '\n</code></pre>')

    return text.strip()


def clear_tables(text: str) -> str:
    '''–Ω–∞–¥–æ –Ω–∞–π—Ç–∏ –≤ –º–∞—Ä–∫–¥–∞—É–Ω —Ç–∞–±–ª–∏—Ü–∞—Ö –±–ª–æ–∫–∏ –∫–æ–¥–∞ (–æ–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω–æ–≥–æ `–∫–æ–¥–∞`) –∏ –∑–∞–º–µ–Ω–∏—Ç—å ` –Ω–∞ –ø—Ä–æ–±–µ–ª—ã
    –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç–∞–±–ª–∏—Ü—ã - 2 –∏ –±–æ–ª–µ–µ –∏–¥—É—â–∏—Ö –ø–æ–¥—Ä—è–¥ —Å—Ç—Ä–æ–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è –∏ –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—Ç—Å—è –Ω–∞ | –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ | –≤ –Ω–∏—Ö —Å–æ–≤–ø–∞–¥–∞–µ—Ç
    '''
    lines = text.splitlines()
    in_table = False
    table_lines = []
    result = []

    for line in lines:
        if line.startswith("|") and line.endswith("|") and line.count("|") > 1:
            if not in_table:
                table_lines = []  # Start a new table
                in_table = True
            table_lines.append(line)

        else:
            if in_table:
                # Process the table lines
                processed_table_lines = []
                for table_line in table_lines:
                    processed_table_lines.append(table_line.replace("`", " "))
                result.extend(processed_table_lines)
                table_lines = []
                in_table = False

            result.append(line)

    if in_table:  # If the text ends inside a table block
      processed_table_lines = []
      for table_line in table_lines:
          processed_table_lines.append(table_line.replace("`", " "))
      result.extend(processed_table_lines)

    return "\n".join(result)


def replace_latex(text: str) -> str:
    def is_valid_latex(text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –≤–∞–ª–∏–¥–Ω—ã–º LaTeX –≤—ã—Ä–∞–∂–µ–Ω–∏–µ–º
        """
        # –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ LaTeX –∫–æ–º–∞–Ω–¥ –∏–ª–∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
        latex_indicators = [
            '\\', '_', '^', '{', '}', '=',  # –±–∞–∑–æ–≤—ã–µ LaTeX –∫–æ–º–∞–Ω–¥—ã
            '\\frac', '\\sqrt', '\\sum', '\\int',  # –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ç–æ—Ä—ã
            '\\alpha', '\\beta', '\\gamma',  # –≥—Ä–µ—á–µ—Å–∫–∏–µ –±—É–∫–≤—ã
            '\\mathbf', '\\mathrm', '\\text'  # —Ñ–æ—Ä–º
        ]
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ LaTeX
        return any(indicator in text for indicator in latex_indicators)


    # –û–±—Ä–∞–±–æ—Ç–∫–∞ LaTeX –≤—ã—Ä–∞–∂–µ–Ω–∏–π
    # 1. –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤—ã—Ä–∞–∂–µ–Ω–∏—è –≤ $$ ... $$
    matches = re.findall(r'\$\$(.*?)\$\$', text, flags=re.DOTALL)
    for match in matches:
        if is_valid_latex(match):  # –¥–æ–±–∞–≤–∏–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å LaTeX
            try:
                new_match = LatexNodes2Text().latex_to_text(match.replace('\\\\', '\\'))
                new_match = html.escape(new_match)
                text = text.replace(f'$${match}$$', new_match)
            except:
                # –ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                continue

    # 2. –ó–∞—Ç–µ–º –∏—â–µ–º –≤—ã—Ä–∞–∂–µ–Ω–∏—è –≤ $ ... $
    # matches = re.findall(r'(?<!\$)\$(?!\$)(.*?)(?<!\$)\$(?!\$)', text, flags=re.DOTALL)
    matches = re.findall(r'(?<!\$)\$(?!$)(.*?)(?<!\$)\$(?!$)', text, flags=re.DOTALL)
    for match in matches:
        if is_valid_latex(match):
            try:
                new_match = LatexNodes2Text().latex_to_text(match.replace('\\\\', '\\'))
                new_match = html.escape(new_match)
                text = text.replace(f'${match}$', new_match)
            except:
                continue

    # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ \[ ... \] –∏ \( ... \)
    matches = re.findall(r'\\\[(.*?)\\\]|\\\((.*?)\\\)', text, flags=re.DOTALL)
    for match_tuple in matches:
        match = match_tuple[0] if match_tuple[0] else match_tuple[1]
        if is_valid_latex(match):
            try:
                new_match = LatexNodes2Text().latex_to_text(match.replace('\\\\', '\\'))
                new_match = html.escape(new_match)
                if match_tuple[0]:
                    text = text.replace(f'\\[{match}\\]', new_match)
                else:
                    text = text.replace(f'\\({match}\\)', new_match)
            except:
                continue

    def latex_to_text(latex_formula):
        # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è LaTeX –≤ —Ç–µ–∫—Å—Ç
        # –í –¥–∞–Ω–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ñ–æ—Ä–º—É–ª—É –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
        r = LatexNodes2Text().latex_to_text(latex_formula).strip()
        rr = html.escape(r)
        return rr

    def replace_function_lt1(match):
        latex_code = match.group(2) if match.group(2) is not None else match.group(3) if match.group(3) is not None else match.group(4)
        return latex_to_text(latex_code)

    pattern = r"\\begin\{(.*?)\}(.*?)\\end\{\1\}|\\\[(.*?)\\\]|\\begin(.*?)\\end"
    text = re.sub(pattern, replace_function_lt1, text, flags=re.DOTALL)

    return text


def replace_code_lang(t: str) -> str:
    """
    Replaces the code language in the given string with appropriate HTML tags.
    Adds "language-plaintext" class if no language is specified but <code> tags are present.
    Does not add language class for single-line code snippets.
    Parameters:
        t (str): The input string containing code snippets.
    Returns:
        str: The modified string with code snippets wrapped in HTML tags.
    """
    result = ''
    code_content = ''
    state = 0
    lines = t.split('\n')
    i = 0
    while i < len(lines):
        line = lines[i]
        if state == 0 and line.startswith('<code>'):
            # –ù–∞—á–∞–ª–æ –±–ª–æ–∫–∞ –∫–æ–¥–∞
            if '</code>' in line:
                # –û–¥–Ω–æ—Å—Ç—Ä–æ—á–Ω—ã–π –∫–æ–¥
                result += line + '\n'  # –û—Å—Ç–∞–≤–ª—è–µ–º –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
            else:
                lang = line[6:].strip().lower()
                if lang == 'c++':
                    lang = 'cpp'
                elif not lang:
                    lang = 'plaintext'
                result += f'<pre><code class="language-{lang}">'
                state = 1
                code_content = ''  # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ —Ç–µ–≥
        elif state == 1:
            if '</code>' in line:
                # –ö–æ–Ω–µ—Ü –±–ª–æ–∫–∞ –∫–æ–¥–∞
                code_content += line[:line.index('</code>')]
                result += code_content + '</code></pre>\n'
                state = 0
            else:
                code_content += line + '\n'
        else:
            result += line + '\n'
        i += 1
    result = re.sub(r"\n{2,}</code>", "\n</code>", result)
    return result


def replace_tables(text: str, max_width: int = 80, max_cell_width: int = 20, ) -> str:
    """
    –ó–∞–º–µ–Ω—è–µ—Ç markdown —Ç–∞–±–ª–∏—Ü—ã –Ω–∞ –∏—Ö prettytable –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ.
    –£–ª—É—á—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ç–∞–±–ª–∏—Ü, –≤–∫–ª—é—á–∞—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —à–∏—Ä–∏–Ω—ã –∏ –æ–±—Ä–µ–∑–∞–Ω–∏–µ –¥–ª–∏–Ω–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤.
    
    :param text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç —Å markdown —Ç–∞–±–ª–∏—Ü–∞–º–∏
    :param max_width: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ —Ç–∞–±–ª–∏—Ü—ã –≤ —Å–∏–º–≤–æ–ª–∞—Ö
    :param max_cell_width: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —à–∏—Ä–∏–Ω–∞ —è—á–µ–π–∫–∏ –≤ —Å–∏–º–≤–æ–ª–∞—Ö
    :return: –¢–µ–∫—Å—Ç —Å –∑–∞–º–µ–Ω–µ–Ω–Ω—ã–º–∏ —Ç–∞–±–ª–∏—Ü–∞–º–∏
    """
    original_text = text
    try:
        text += '\n'

        def is_valid_separator(line: str) -> bool:
            if not line or not line.strip('| '):
                return False
            parts = line.strip().strip('|').split('|')
            return all(part.strip().replace('-', '').replace(':', '') == '' for part in parts)

        def is_valid_table_row(line: str) -> bool:
            return line.strip().startswith('|') and line.strip().endswith('|')

        def strip_tags(text: str) -> str:
            text = text.replace('&lt;', '<')
            text = text.replace('&gt;', '>')
            text = text.replace('&quot;', '"')
            text = text.replace('&#x27;', "'")
            text = text.replace('<b>', '   ')
            text = text.replace('<i>', '   ')
            text = text.replace('</b>', '    ')
            text = text.replace('</i>', '    ')
            text = text.replace('<br>', '    ')
            text = text.replace('<code>',  '      ')
            text = text.replace('</code>', '       ')
            return text

        def truncate_text(text: str, max_width: int) -> str:
            text = strip_tags(text)
            if len(text) <= max_width:
                return text
            return text[:max_width-3] + '...'

        def wrap_long_text(text: str, max_width: int) -> str:
            text = strip_tags(text)
            if len(text) <= max_width:
                return text
            return '\n'.join(wrap(text, max_width))

        def process_table(table_text: str) -> str:
            lines = table_text.strip().split('\n')
            x = PrettyTable()
            x.header = True
            x.hrules = 1

            # –ù–∞—Ö–æ–¥–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
            header_index = next((i for i, line in enumerate(lines) if is_valid_table_row(line)), None)
            if header_index is None:
                return table_text

            separator_index = next((i for i in range(header_index + 1, len(lines)) if is_valid_separator(lines[i])), None)
            if separator_index is None:
                return table_text

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            header = [truncate_text(cell.strip(), max_cell_width) for cell in lines[header_index].strip('|').split('|') if cell.strip()]

            def make_strings_unique(strings):
                """
                –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –¥–µ–ª–∞–µ—Ç –∏—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏.

                Args:
                    strings: –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫.

                Returns:
                    –°–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –±–µ–∑ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤.
                """
                seen = set()
                result = []
                for s in strings:
                    original_s = s
                    count = 1
                    while s in seen:
                        s = original_s + f"_{count}"
                        count += 1
                    seen.add(s)
                    result.append(s)
                return result

            x.field_names = make_strings_unique(header)

            # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è
            alignments = []
            for cell in lines[separator_index].strip('|').split('|'):
                cell = cell.strip()
                if cell.startswith(':') and cell.endswith(':'):
                    alignments.append('c')
                elif cell.endswith(':'):
                    alignments.append('r')
                else:
                    alignments.append('l')
            
            for i, align in enumerate(alignments):
                x.align[x.field_names[i]] = align

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            seen_rows = set()
            for line in lines[separator_index + 1:]:
                if is_valid_table_row(line) and not is_valid_separator(line):
                    row = [wrap_long_text(cell.strip(), max_cell_width) for cell in line.strip('|').split('|') if cell.strip()]
                    row += [''] * (len(header) - len(row))
                    row = tuple(row[:len(header)])
                    if row not in seen_rows:
                        seen_rows.add(row)
                        x.add_row(row)

            # –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —à–∏—Ä–∏–Ω—ã —Ç–∞–±–ª–∏—Ü—ã
            x.max_width = max_width

            # return f'\n\n<pre><code>{x.get_string()}\n</code></pre>'
            return f'\n\n<code>{x.get_string()}\n</code>'

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã –≤ —Ç–µ–∫—Å—Ç–µ
        table_pattern = re.compile(r'(\n|^)\s*\|.*\|.*\n\s*\|[-:\s|]+\|\s*\n(\s*\|.*\|.*\n)*', re.MULTILINE)

        # –ó–∞–º–µ–Ω—è–µ–º –∫–∞–∂–¥—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        text = table_pattern.sub(lambda m: process_table(m.group(0)), text)


        # —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –∫—Ä–æ–º–µ —Ö—Ç–º–ª —Ç–µ–≥–æ–≤
        TAG_MAP = {
            "<b>": "40bd001563085fc35165329ea1ff5c5ecbdbbeef",
            "</b>": "c591326762260728871710537179fabf75973234",
            "<strong>": "ef0b585e265b5287aa6d26a6860e0cd846623679",
            "</strong>": "e882cf5c82a930662f17c188c70ade885c55c607",
            "<i>": "497603a6c32112169ae39a79072c07e863ae3f7a",
            "</i>": "0784921025d4c05de5069cc93610c754a4088015",
            "<em>": "d1a25e1cb6b3d667b567323119f126f845c971df",
            "</em>": "851e149d4a4313c6016e73f719c269076790ab23",
            "<code>": "c1166919418e7c62a16b86662710541583068278",
            "</code>": "b7e364fd74d46f698c0f164988c382957c220c7c",
            "<s>": "03c7c0ace395d80182db07ae2c30f0341a739b1b",
            "</s>": "86029812940d86d63c5899ee5227cf94639408a7",
            "<strike>": "f0e25c74b67881c84327dc916c8c919f062c9003",
            "</strike>": "935f70051f605261d9f93948a5c3382f3a843596",
            "<del>": "8527a891e224136950ff32ca212b45bc93f69972",
            "</del>": "a992a007a4e77704231c285601a97cca4a70b768",
            "<pre>": "932162e70462a0f5d1a7599592ed51c41c4f8eb7",
            "</pre>": "e9e6f7c1fe77261334b414ae017288814903b225",
            "<u>": "764689e6705f61c6e7494bfa62688414325d8155",
            "</u>": "8a048b284925205d3187f8b04625a702150a936f",
        }

        REVERSE_TAG_MAP = {
            "40bd001563085fc35165329ea1ff5c5ecbdbbeef": "<b>",
            "c591326762260728871710537179fabf75973234": "</b>",
            "ef0b585e265b5287aa6d26a6860e0cd846623679": "<strong>",
            "e882cf5c82a930662f17c188c70ade885c55c607": "</strong>",
            "497603a6c32112169ae39a79072c07e863ae3f7a": "<i>",
            "0784921025d4c05de5069cc93610c754a4088015": "</i>",
            "d1a25e1cb6b3d667b567323119f126f845c971df": "<em>",
            "851e149d4a4313c6016e73f719c269076790ab23": "</em>",
            "c1166919418e7c62a16b86662710541583068278": "<code>",
            "b7e364fd74d46f698c0f164988c382957c220c7c": "</code>",
            "03c7c0ace395d80182db07ae2c30f0341a739b1b": "<s>",
            "86029812940d86d63c5899ee5227cf94639408a7": "</s>",
            "f0e25c74b67881c84327dc916c8c919f062c9003": "<strike>",
            "935f70051f605261d9f93948a5c3382f3a843596": "</strike>",
            "8527a891e224136950ff32ca212b45bc93f69972": "<del>",
            "a992a007a4e77704231c285601a97cca4a70b768": "</del>",
            "932162e70462a0f5d1a7599592ed51c41c4f8eb7": "<pre>",
            "e9e6f7c1fe77261334b414ae017288814903b225": "</pre>",
            "764689e6705f61c6e7494bfa62688414325d8155": "<u>",
            "8a048b284925205d3187f8b04625a702150a936f": "</u>",
        }

        def replace_tags_with_hashes(text):
            for tag, tag_hash in TAG_MAP.items():
                text = text.replace(tag, tag_hash)
            return text

        def replace_hashes_with_tags(text):
            for tag_hash, tag in REVERSE_TAG_MAP.items():
                text = text.replace(tag_hash, tag)
            return text

        text = replace_tags_with_hashes(text)
        text = re.sub(r'(?<=\|)(.*?)(?=\|)', lambda match: match.group(1).replace('<', '&lt;').replace('>', '&gt;').replace('"', '&quot;').replace("'", '&#x27;'), text)
        text = replace_hashes_with_tags(text)

        return text
    except Exception as unknown:
        traceback_error = traceback.format_exc()
        # my_log.log2(f'utils:replace_tables {unknown}\n\n{traceback_error}\n\n{original_text}')
        return original_text


def split_html(text: str, max_length: int = 1500) -> list:
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç HTML-–ø–æ–¥–æ–±–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏, –Ω–µ –ø—Ä–µ–≤—ã—à–∞—é—â–∏–µ max_length —Å–∏–º–≤–æ–ª–æ–≤.

    –£—á–∏—Ç—ã–≤–∞–µ—Ç –≤–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å —Ç–µ–≥–æ–≤ –∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç –∏—Ö –º–µ–∂–¥—É —á–∞—Å—Ç—è–º–∏.
    """

    tags = {
        "b": "</b>",
        "i": "</i>",
        "code": "</code>",
        "pre": "</pre>",
        "blockquote": "</blockquote>",
        "blockquote expandable": "</blockquote>",
    }
    opening_tags = {f"<{tag}>" for tag in tags}
    closing_tags = {tag for tag in tags.values()}

    result = []
    current_chunk = ""
    open_tags_stack = []

    lines = text.splitlines(keepends=True)
    for line in lines:
        line_stripped = line.strip()

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏—Ö —Ç–µ–≥–æ–≤
        for tag in opening_tags:
            if line_stripped.startswith(tag):
                tag_name = tag[1:-1]

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–∫—Ä—ã—Ç –ª–∏ —Ç–µ–≥ –≤ —ç—Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–µ
                if tags[tag_name] not in line:
                    open_tags_stack.append(tag_name)

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª—É—á–∞—è <pre><code class="">
                if tag_name == "pre" and '<code class="' in line:
                    open_tags_stack.append("code")

                break

        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏—Ö —Ç–µ–≥–æ–≤
        for closing_tag in closing_tags:
            if closing_tag in line:
                tag_name = closing_tag[2:-1]

                remove_index = -1
                for i in reversed(range(len(open_tags_stack))):
                    if open_tags_stack[i] == tag_name:
                        remove_index = i
                        break
                if remove_index != -1:
                    open_tags_stack.pop(remove_index)

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –∫ —Ç–µ–∫—É—â–µ–º—É —á–∞–Ω–∫—É
        if len(current_chunk) + len(line) > max_length:
            # –ß–∞–Ω–∫ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω, –Ω—É–∂–Ω–æ –µ–≥–æ –∑–∞–≤–µ—Ä—à–∏—Ç—å –∏ –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π

            # 1. –ó–∞–∫—Ä—ã–≤–∞–µ–º —Ç–µ–≥–∏ –≤ —Ç–µ–∫—É—â–µ–º —á–∞–Ω–∫–µ
            for tag_name in reversed(open_tags_stack):
                current_chunk += tags[tag_name]

            # 2. –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if len(current_chunk) > max_length:
                for x in split_text(current_chunk, max_length):
                    result.append(x)
            else:
                result.append(current_chunk)

            # 3. –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π —á–∞–Ω–∫
            current_chunk = ""

            # 4. –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ç–µ–≥–∏ –≤ –Ω–æ–≤–æ–º —á–∞–Ω–∫–µ
            for tag_name in open_tags_stack:
                current_chunk += f"<{tag_name}>"

        current_chunk += line

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —á–∞–Ω–∫–∞
    if current_chunk:
        if len(current_chunk) > max_length:
            for x in split_text(current_chunk, max_length):
                result.append(x)
        result.append(current_chunk)

    result2 = post_process_split_html(result)

    return result2


def post_process_split_html(chunks: list) -> list:
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫—É —Å–ø–∏—Å–∫–∞ —á–∞–Ω–∫–æ–≤, –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ –∏–∑ split_html.
    –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –ø–æ–ª–æ–º–∞–Ω–Ω—ã–µ —Ç–µ–≥–∏, –∏ —É–±–∏—Ä–∞–µ—Ç –ø—É—Å—Ç—ã —á–∞–Ω–∫–∏
    """

    def fix_html_tags(text: str) -> str:
        """
        Fixes HTML tag errors in the text using BeautifulSoup.

        Args:
            text: The input text containing HTML tags.

        Returns:
            The text with fixed HTML tags.
        """
        soup = BeautifulSoup(text, 'html.parser')
        return str(soup)

    processed_chunks = []
    for chunk in chunks:
        processed_chunks.append(fix_html_tags(chunk))

    # —É–¥–∞–ª–∏—Ç—å –ø—É—Å—Ç—ã–µ —á–∞–Ω–∫–∏
    processed_chunks = [chunk for chunk in processed_chunks if chunk.strip() and chunk.strip() != '</code>']

    return processed_chunks


def html_to_markdown(html: str) -> str:
    """
    Converts HTML to Markdown.

    Args:
        html (str): HTML code.

    Returns:
        str: Markdown code.
    """
    try:
        markdown_text = markdownify.markdownify(html)
        return markdown_text
    except Exception as error:
        traceback_error = traceback.format_exc()
        my_log.log2(f'utils:html_to_markdown {error}\n\n{traceback_error}\n\n{html}')
        return html

#######################################################################################


def get_tmp_fname() -> str:
    """
    Generate a temporary file name.

    Returns:
        str: The name of the temporary file.
    """
    with tempfile.NamedTemporaryFile(delete=True) as temp_file:
        return temp_file.name


def is_image_link(url: str) -> bool:
  """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ URL-–∞–¥—Ä–µ—Å —Å—Å—ã–ª–∫–æ–π –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫—É.

  Args:
    url: URL-–∞–¥—Ä–µ—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.

  Returns:
    True, –µ—Å–ª–∏ URL-–∞–¥—Ä–µ—Å —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫—É, –∏–Ω–∞—á–µ False.
  """

  try:
    # response = requests.get(url, timeout=2, stream=True)
    content = b''
    response = requests.get(url, stream=True, timeout=10)
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
    for chunk in response.iter_content(chunk_size=1024):
        content += chunk
        if len(content) > 50000:
            break
    content_type = response.headers['Content-Type']
    return content_type.startswith('image/')
  except:
    return False


## ytb #####################################################################################

def convert_to_mp3(input_file: str) -> str | None:
    """
    Converts an audio file to MP3 format using ffmpeg with the highest quality settings.

    Args:
        input_file: Path to the input audio file.

    Returns:
        Path to the converted MP3 file, or None if an error occurred.
    """
    with LOCK_TRANSCODE:
        try:
            output_file = get_tmp_fname() + '.mp3'

            # LAME Bitrate Overview
            # lame option | Average kbit/s | Bitrate range kbit/s      | ffmpeg option
            # ----------- | --------------- | ----------------------- | -------------
            # -b 320      | 320             | 320 CBR (non VBR) example | -b:a 320k (NB this is 32KB/s, or its max)
            # -V 0        | 245             | 220-260                 | -q:a 0 (NB this is VBR from 220 to 260 KB/s)
            # -V 1        | 225             | 190-250                 | -q:a 1
            # -V 2        | 190             | 170-210                 | -q:a 2
            # -V 3        | 175             | 150-195                 | -q:a 3
            # -V 4        | 165             | 140-185                 | -q:a 4
            # -V 5        | 130             | 120-150                 | -q:a 5
            # -V 6        | 115             | 100-130                 | -q:a 6
            # -V 7        | 100             | 80-120                  | -q:a 7
            # -V 8        | 85              | 70-105                  | -q:a 8
            # -V 9        | 65              | 45-85                   | -q:a 9

            subprocess.run([
                'ffmpeg',
                '-i',
                input_file,
                '-vn',  # Disable video processing
                '-acodec',
                'libmp3lame',  # Use libmp3lame for MP3 encoding
                '-q:a',
                '3',  # Use -q:a for VBR (Variable Bit Rate)
                # 0 is the highest quality, 9 is the lowest
                '-loglevel',
                'error',
                output_file
            ], check=True)

            return output_file

        except subprocess.CalledProcessError as error:
            my_log.log2(f'utils:convert_to_mp3: error: {error}\n\n{traceback.format_exc()}')
            return None


@cachetools.func.ttl_cache(maxsize=10, ttl=10 * 60)
def get_title_and_poster(url: str) -> Tuple[str, str, str, int]:
    """
    Gets the title, thumbnail URL, description, and size of a YouTube video using yt-dlp.

    Args:
        url: The URL of the YouTube video.

    Returns:
        A tuple containing the title, thumbnail URL, description, and size (duration in seconds) of the video.
        If an error occurs, returns a tuple of four empty strings or 0 for size.
    """
    try:
        # Use yt-dlp to extract video information
        if hasattr(cfg, 'YTB_PROXY2') and cfg.YTB_PROXY2:
            proxy = random.choice(cfg.YTB_PROXY2)
            process = subprocess.run([
                'yt-dlp',
                '--dump-json',
                '--proxy', proxy,
                url
            ], capture_output=True, text=True, check=True)
        else:
            process = subprocess.run([
                'yt-dlp',
                '--dump-json',
                url
            ], capture_output=True, text=True, check=True)

        # Parse the JSON output
        video_info = json.loads(process.stdout)

        # Extract the required information
        title = video_info.get('title', '')
        thumbnail_url = video_info.get('thumbnail', '')
        description = video_info.get('description', '')
        size = video_info.get('duration', 0)

        return title, thumbnail_url, description, size

    except (subprocess.CalledProcessError, json.JSONDecodeError) as error:
        my_log.log2(f'my_ytb:get_title_and_poster {url} {error}')
        return '', '', '', 0


def download_audio(url: str, limit_duration: int = 4 * 60 * 60) -> str | None:
    """
    Downloads audio file using yt-dlp to a temporary folder
    with audio quality 128k or lower. If small file them download best quality.

    Args:
        url: Link to the audio file.
        limit_duration: Maximum duration of the audio file in seconds. Default is 4 hours.

    Returns:
        Path to the downloaded file in the temporary folder, or None if download failed.
    """
    output_template = get_tmp_fname()

    try:
        duration = get_title_and_poster(url)[3]

        if duration > limit_duration:
            return None

        if duration < 10*60:
            quality = 'bestaudio'
        else:
            quality = 'bestaudio[abr<=128]/bestaudio'
        if hasattr(cfg, 'YTB_PROXY2') and cfg.YTB_PROXY2:
            proxy = random.choice(cfg.YTB_PROXY2)
            subprocess.run([
                'yt-dlp',
                '-f', quality,
                '--proxy', proxy,
                '-o', output_template,
                url
            ], check=True)
        else:
            subprocess.run([
                'yt-dlp',
                '-f', quality,
                '-o', output_template,
                url
            ], check=True)
    except subprocess.CalledProcessError:
        return None

    r = output_template
    if quality == 'bestaudio':
        r2 = convert_to_mp3(r)
        if r2:
            remove_file(r)
            return r2
        else:
            return None
    return r


@cachetools.func.ttl_cache(maxsize=10, ttl=10 * 60)
def valid_youtube_url(url: str) -> str:
    """
    Checks if the URL is a valid YouTube URL using yt-dlp, with proxy support.

    Supports various YouTube URL formats:
    - youtu.be/
    - youtube.com/watch?v=
    - m.youtube.com/watch?v=
    - youtube-nocookie.com/embed/

    Args:
        url: The URL string to check.

    Returns:
        The YouTube video ID if the URL is valid, otherwise an empty string.
    """
    try:
        url = url.strip()
        if not url.lower().startswith('http'):
            return ''

        # Check if a proxy is configured
        if hasattr(cfg, 'YTB_PROXY2') and cfg.YTB_PROXY2:
            # Use a random proxy from the list
            proxy = random.choice(cfg.YTB_PROXY2)
            process = subprocess.run([
                'yt-dlp',
                '--print', '%(id)s',
                '--skip-download',  # Skip downloading the video
                '--proxy', proxy,
                url
            ], capture_output=True, text=True, check=True)
        else:
            # No proxy configured, use yt-dlp directly
            process = subprocess.run([
                'yt-dlp',
                '--print', '%(id)s',
                '--skip-download',  # Skip downloading the video
                url
            ], capture_output=True, text=True, check=True)

        # Extract the video ID from the output
        video_id = process.stdout.strip()

        # Check if the extracted ID is not empty
        if video_id:
            return video_id
        else:
            my_log.log2(f'my_ytb:valid_youtube_url1: Invalid YouTube URL: {url}')
            return ''

    except subprocess.CalledProcessError as error:
        error_traceback = traceback.format_exc()
        my_log.log2(f'my_ytb:valid_youtube_url2: {url} {error}\n\n{error_traceback}')
        return ''

## ytb #####################################################################################


def download_audio_file_as_bytes(url: str,  limit_size: int = 200) -> bytes:
    """
    Downloads a file from the given URL and returns it as bytes.
    Does not download more than limit_size (200 MB) to avoid downloading excessively large files.
    Includes timeouts for requests and data reading to handle large files efficiently.

    Args:
        url (str): The URL of the file.
        limit_size (int, optional): The maximum size of the file to download. Defaults to 200 MB.

    Returns:
        bytes: The file as bytes.
    """
    if valid_youtube_url(url):
        p = download_audio(url)
        if p:
            with open(p, 'rb') as f:
                data = f.read()
            remove_file(p)
            return data
        else:
            return None
            

    max_size = limit_size * 1024 * 1024
    chunk_size = 100 * 1024
    timeout = 30  # Timeout for requests in seconds
    read_timeout = 300  # Timeout for reading data in seconds

    try:
        response = requests.get(url, stream=True, timeout=timeout)
        response.raise_for_status()

        # Get the content length from the headers, if available
        content_length = response.headers.get('Content-Length')
        if content_length is not None:
            content_length = int(content_length)
            if content_length > max_size:
                raise ValueError(f"File is too large: {content_length} bytes. Maximum size: {max_size} bytes.")

        downloaded_size = 0
        audio_data = b''
        start_time = time.time()

        # Download the file in chunks to avoid loading large files into memory
        for chunk in response.iter_content(chunk_size=chunk_size):
            if time.time() - start_time > read_timeout:
                raise TimeoutError("Reading data timed out.")

            if downloaded_size + len(chunk) > max_size:
                raise ValueError(f"Exceeded maximum file size: {max_size} bytes.")

            audio_data += chunk
            downloaded_size += len(chunk)

            # Log the progress
            my_log.log2(f'utils:download_audio_file_as_bytes: Downloaded {downloaded_size} bytes out of {content_length if content_length else "unknown"} bytes.')

        return audio_data

    except Exception as error:
        traceback_error = traceback.format_exc()
        my_log.log2(f'utils:download_audio_file_as_bytes: Error in download_audio_file_as_bytes: {url}\n{error}\n\n{traceback_error}')

    return b''


def get_filename_from_url(url: str) -> str:
    return os.path.basename(url)


def download_image_as_bytes(url_or_urls: str) -> bytes:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ(—è) –ø–æ URL-–∞–¥—Ä–µ—Å—É(–∞–º) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ(–∏—Ö) –≤ –≤–∏–¥–µ –±–∞–π—Ç–æ–≤.

    Args:
        url_or_urls: URL-–∞–¥—Ä–µ—Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–ª–∏ —Å–ø–∏—Å–æ–∫ URL-–∞–¥—Ä–µ—Å–æ–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

    Returns:
        –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –≤–∏–¥–µ –±–∞–π—Ç–æ–≤ –∏–ª–∏ —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ –≤–∏–¥–µ –±–∞–π—Ç–æ–≤.
    """

    if isinstance(url_or_urls, str):
        try:
            response = requests.get(url_or_urls, timeout=30)
        except Exception as error:
            return b''
        return response.content

    elif isinstance(url_or_urls, list):
        with concurrent.futures.ThreadPoolExecutor() as executor:
            results = list(executor.map(lambda url: requests.get(url, timeout=30).content if requests.get(url, timeout=30).status_code == 200 else None, url_or_urls))
        return results

    else:
        return b''


def download_image_for_thumb(url: str) -> bytes:
    """
    Downloads an image from the given URL, converts it to JPG format if necessary,
    resizes it to a maximum size of 200KB, and ensures its dimensions do not exceed 320x320 pixels.

    Args:
        url: The URL of the image.

    Returns:
        The image data as bytes in JPG format, or empty bytes if an error occurred.
    """
    try:
        # Download the image using requests
        response = requests.get(url, stream=True)
        response.raise_for_status()  # Raise an exception for bad status codes

        # Read the image data into a BytesIO object
        image_data = io.BytesIO(response.content)

        # Open the image using PIL
        image = PIL.Image.open(image_data)

        # Convert the image to RGB mode if it's not
        if image.mode != 'RGB':
            image = image.convert('RGB')

        # Resize the image if necessary, maintaining aspect ratio
        if image.width > 320 or image.height > 320:
            width, height = image.size
            if width > height:
                new_width = 320
                new_height = int(height * (320 / width))
            else:
                new_height = 320
                new_width = int(width * (320 / height))
            image = image.resize((new_width, new_height), PIL.Image.LANCZOS)

        output_data = io.BytesIO()
        quality = 75
        image.save(output_data, format='JPEG', quality=quality)

        return output_data.getvalue()

    except Exception as error:
        my_log.log2(f'download_image_as_bytes_as_jpg: error: {error}\n\n{traceback.format_exc()}')
        return b''


def fast_hash(data: Any) -> str:
    """
    Calculates the SHA256 hash of any Python data.

    This function efficiently handles various data types, including bytes, strings, lists, dictionaries, etc.
    For byte data, it directly calculates the hash. For other data types, it first serializes the data using pickle
    and then calculates the hash.

    Args:
        data: The data to hash. Can be of any type.

    Returns:
        The hexadecimal representation of the SHA256 hash.
    """
    if isinstance(data, bytes):
        hashed = hashlib.sha256(data).hexdigest()
    else:
        pickled_data = pickle.dumps(data)
        hashed = hashlib.sha256(pickled_data).hexdigest()
    return hashed


def nice_hash(s: str, l: int = 12) -> str:
    """
    Generate a nice hash of the given string.

    Parameters:
        s (str): The string to hash.

    Returns:
        str: The nice hash of the string.
    """
    hash_object = hashlib.sha224(s.encode())
    return f'{hash_object.hexdigest()[:l]}'


def get_full_time() -> str:
    """
    Get the current time with a GMT time offset.

    Returns:
        str: A string representing the current time in the format "YYYY-MM-DD HH:MM:SS TZ".
    """
    now = datetime.datetime.now(pytz.timezone('Europe/Moscow'))
    time_string = now.strftime("%Y-%m-%d %H:%M:%S %Z")
    return time_string


def seconds_to_str(seconds: float) -> str:
    """
    Convert seconds to a string in the format "HH:MM:SS".

    Parameters:
        seconds (float): The number of seconds to convert.

    Returns:
        str: A string representing the time in the format "HH:MM:SS".
    """
    seconds = int(seconds)
    hours = seconds // 3600
    minutes = (seconds % 3600) // 60
    seconds = seconds % 60
    return f'{hours:02}:{minutes:02}:{seconds:02}'


def get_username_for_log(message) -> str:
    """
    Returns the username for logging purposes based on the given message.

    Args:
        message: The message object to extract the username from.
                 My be a group of messages (list).

    Returns:
        str: The username for logging.
    """
    if isinstance(message, list):
        message = message[0]

    if message.chat.type == 'private':
        return message.from_user.full_name or message.from_user.username or 'noname'
    else:
        if message.is_topic_message:
            return f'[{message.chat.title or message.chat.username or message.chat.first_name or "nonamechat"}] [{message.message_thread_id}]'
        else:
            return message.chat.title or message.chat.username or message.chat.first_name or 'nonamechat'


def safe_fname(s: str) -> str:
    """Return a safe filename for the given string, truncated to 250 bytes in UTF-8 encoding."""
    
    # Replace invalid characters
    s = re.sub(r'[\\/*?:"<>|]', '_', s)
    
    # Encode to UTF-8 and check length
    encoded_s = s.encode('utf-8')
    if len(encoded_s) <= 250:
        return s
    
    # Shorten filename if longer than 250 bytes
    while len(encoded_s) > 247:
        s = s[:len(s)//2-3] + '___' + s[len(s)//2+3:]
        encoded_s = s.encode('utf-8')
    return s


def remove_file(fname: str):
    '''–£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª –ø–æ –∏–º–µ–Ω–∏'''
    try:
        os.unlink(fname)
        return True
    except Exception as error:
        # my_log.log2(f'utils:remove_file: {fname}\n\n{error}')
        return False


def remove_dir(fname: str):
    '''–£–¥–∞–ª—è–µ—Ç –ø–∞–ø–∫—É —Ä–µ–∫—É—Ä—Å–∏–≤–Ω–æ'''
    try:
        if os.path.isdir(fname):
            shutil.rmtree(fname)
        elif os.path.isfile(fname):
            os.unlink(fname)
        else:
            # my_log.log2(f'utils:remove_dir: {fname} not found or not a directory or file')
            return False
        return True
    except Exception as error:
        # my_log.log2(f'utils:remove_file: {fname}\n\n{error}')
        return False


def mime_from_buffer(data: bytes) -> str:
    """
    Get the MIME type of the given buffer.

    Parameters:
        data (bytes): The buffer to get the MIME type of.

    Returns:
        str: The MIME type of the buffer.
    """
    pdf_signature = b'%PDF-1.'

    if data.startswith(pdf_signature):
        return 'application/pdf'
    return 'plain'


def get_codepage():
    if 'windows' in platform().lower():
        result = subprocess.getoutput("chcp")
        return f'cp{result.split()[-1]}'
    else:
        result = subprocess.getoutput("locale charmap")
        return result.lower()


def make_collage(images: list) -> bytes:
    """–°–æ–∑–¥–∞–µ—Ç –∫–æ–ª–ª–∞–∂ –∏–∑ —Å–ø–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, —Ä–∞—Å–ø–æ–ª–∞–≥–∞—è –∏—Ö –ø–æ 2 –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤ —Ä—è–¥.
    –£—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞–∑–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–∞—Ä—Ç–∏–Ω–æ–∫, –ø—Ä–∏–≤–æ–¥—è –∏—Ö –∫ –æ–¥–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É –ø–µ—Ä–µ–¥ —Å–∫–ª–µ–π–∫–æ–π,
    —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏. –§–æ–Ω –∫–æ–ª–ª–∞–∂–∞ –±–µ–ª—ã–π.

    Args:
        images (list): –°–ø–∏—Å–æ–∫ –±–∞–π—Ç–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—â–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.

    Returns:
        bytes: –ë–∞–π—Ç–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞, –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—â–∞—è –∏—Ç–æ–≥–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–æ–ª–ª–∞–∂–∞.
    """

    images = [PIL.Image.open(io.BytesIO(img)) for img in images]

    # –ù–∞—Ö–æ–¥–∏–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é —à–∏—Ä–∏–Ω—É –∏ –≤—ã—Å–æ—Ç—É —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –∫–∞—Ä—Ç–∏–Ω–æ–∫
    max_width = max(img.width for img in images)
    max_height = max(img.height for img in images)

    # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –≤—Å–µ—Ö –∫–∞—Ä—Ç–∏–Ω–æ–∫ –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
    resized_images = []
    for img in images:
        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
        scale_factor = min(max_width / img.width, max_height / img.height)

        # –í—ã—á–∏—Å–ª—è–µ–º –Ω–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
        new_width = int(img.width * scale_factor)
        new_height = int(img.height * scale_factor)

        # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –∫–∞—Ä—Ç–∏–Ω–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–µ—Ç–æ–¥–∞ LANCZOS
        resized_img = img.resize((new_width, new_height), PIL.Image.LANCZOS)

        # –ï—Å–ª–∏ –∫–∞—Ä—Ç–∏–Ω–∫–∞ –Ω–µ –∏–º–µ–µ—Ç –∞–ª—å—Ñ–∞-–∫–∞–Ω–∞–ª–∞, –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ
        if resized_img.mode != 'RGBA':
            resized_img = resized_img.convert('RGBA')

        resized_images.append(resized_img)

    # –°–æ–∑–¥–∞–µ–º –∫–æ–ª–ª–∞–∂ –∏–∑ –∫–∞—Ä—Ç–∏–Ω–æ–∫ –æ–¥–∏–Ω–∞–∫–æ–≤–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —Å –±–µ–ª—ã–º —Ñ–æ–Ω–æ–º
    collage_width = max_width * 2  # –®–∏—Ä–∏–Ω–∞ –∫–æ–ª–ª–∞–∂–∞ - 2 –∫–∞—Ä—Ç–∏–Ω–∫–∏ –≤ —Ä—è–¥
    collage_height = max_height * (len(images) // 2 + len(images) % 2)  # –í—ã—Å–æ—Ç–∞ –∫–æ–ª–ª–∞–∂–∞ - –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä—è–¥–æ–≤ * –≤—ã—Å–æ—Ç–∞ –∫–∞—Ä—Ç–∏–Ω–∫–∏

    collage = PIL.Image.new('RGB', (collage_width, collage_height), (255, 255, 255))  # –ë–µ–ª—ã–π —Ñ–æ–Ω

    x_offset = 0
    y_offset = 0
    for i, img in enumerate(resized_images):
        collage.paste(img, (x_offset, y_offset)) # –í—Å—Ç–∞–≤–ª—è–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É
        if (i + 1) % 2 == 0:
            y_offset += max_height
            x_offset = 0
        else:
            x_offset += max_width

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –±—É—Ñ–µ—Ä
    result_image_as_bytes = io.BytesIO()
    collage.save(result_image_as_bytes, format='JPEG', quality=95, optimize=True, subsampling=0)
    result_image_as_bytes.seek(0)
    return result_image_as_bytes.read()


def get_image_size(data: bytes) -> tuple[int, int]:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞–∑–º–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –±–∞–π—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

    Args:
        data: –ë–∞–π—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.

    Returns:
        –ö–æ—Ä—Ç–µ–∂ (—à–∏—Ä–∏–Ω–∞, –≤—ã—Å–æ—Ç–∞) –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. 
        –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (0, 0).
    """
    try:
        image = PIL.Image.open(io.BytesIO(data))
        width, height = image.size
        return width, height
    except Exception as error:
        my_log.log2(f'utils:get_image_size: {error}')
        return 0, 0


def string_to_dict(input_string: str):
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ —Å–ª–æ–≤–∞—Ä—å.

    Args:
        input_string: –°—Ç—Ä–æ–∫–∞, –∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≤ —Å–ª–æ–≤–∞—Ä—å.

    Returns:
        –°–ª–æ–≤–∞—Ä—å, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –∏–∑ —Å—Ç—Ä–æ–∫–∏, –∏–ª–∏ None, –µ—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∏ –æ—à–∏–±–∫–∏.
    """
    try:
        decoded_object = json_repair.loads(input_string)
        if decoded_object:
            return decoded_object
    except Exception as error:
        my_log.log2(f'utils:string_to_dict: {error}')
    if input_string:
        my_log.log2(f'utils:string_to_dict: {input_string}')
    return None


def resize_and_convert_to_jpg(image_data: Union[bytes, str], max_size: int = 2000, jpg_quality: int = 60) -> bytes:
    """
    Resizes an image to a maximum size in either dimension,
    converts it to JPG format (if it's not already), and compresses it.
    If the image is already JPG and within the size limits, it returns the original data.

    Args:
        image_data: The image data as bytes or a file path to the image.
        max_size: The maximum size (in pixels) for the width or height of the image. Defaults to 2000.
        jpg_quality: The quality of the JPG compression (0-100). Defaults to 60.

    Returns:
        The processed JPG image data as bytes, or the original data if no changes were needed.
    """
    try:
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –µ—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–ª–∏ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É, —Ç–æ —á–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        if isinstance(image_data, str):
            with open(image_data, 'rb') as f:
                image_data = f.read()

        print(len(image_data))

        # –û—Ç–∫—Ä—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ –±–∞–π—Ç–æ–≤
        img = PIL.Image.open(io.BytesIO(image_data))

        # –ü–æ–ª—É—á–∞–µ–º —à–∏—Ä–∏–Ω—É –∏ –≤—ã—Å–æ—Ç—É
        width, height = img.size

        # –ï—Å–ª–∏ —Ä–∞–∑–º–µ—Ä—ã –º–µ–Ω—å—à–µ max_size –∏ —Ñ–æ—Ä–º–∞—Ç JPG, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if width <= max_size and height <= max_size and img.format == 'JPEG':
            return image_data

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∏–∑–º–µ–Ω—è—Ç—å —Ä–∞–∑–º–µ—Ä
        if width > max_size or height > max_size:
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è
            if width > height:
                scale = max_size / width
            else:
                scale = max_size / height

            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –Ω–æ–≤—ã–µ —Ä–∞–∑–º–µ—Ä—ã
            new_width = int(width * scale)
            new_height = int(height * scale)

            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            img = img.resize((new_width, new_height))

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ JPG –∏ —Å–∂–∏–º–∞–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
        with io.BytesIO() as output:
            img = img.convert('RGB')  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
            img.save(output, format='JPEG', quality=jpg_quality, optimize=True)
            jpg_data = output.getvalue()

        print(len(jpg_data))

        return jpg_data

    except Exception as e:
        my_log.log2(f'utils:resize_and_convert_to_jpg: {e}')
        return b''  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ –±–∞–π—Ç—ã –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏


def heic2jpg(data: Union[bytes, str]) -> bytes:
    """Converts HEIC/HEIF image data (bytes or filepath) to JPEG bytes.

    Args:
        data: The image data as bytes or a string representing the filepath.

    Returns:
        The JPEG image data as bytes if the image was HEIC/HEIF,
        or the original data if it's not HEIC/HEIF,
        or an empty bytes object if conversion fails.
    """

    try:
        if isinstance(data, str):
            with open(data, 'rb') as f:
                data = f.read()

        if data[4:12] == b'ftypheic' or data[4:12] == b'ftypmif1':
            with PIL.Image.open(io.BytesIO(data)) as image:
                with io.BytesIO() as output:
                    image.save(output, format="JPEG", quality=80, optimize=True, progressive=True, subsampling="4:4:4")
                    contents = output.getvalue()
                    return contents
        else:
            return data

    except Exception as error:
        my_log.log2(f'utils:heic2jpg {error}')
        return b''


def compress_png_bytes(image_bytes: bytes) -> bytes:
    """Compresses a PNG image provided as bytes as much as possible.

    Args:
        image_bytes: The PNG image data as bytes.

    Returns:
        The compressed PNG image bytes, or the original 
        image_bytes if compression fails. Returns source if input is invalid.
    """
    try:
        # Open image from bytes
        img = PIL.Image.open(io.BytesIO(image_bytes))

        # Ensure the image is in PNG format
        if img.format != "PNG":
            return image_bytes  # Return original bytes if it's not a PNG

        # Convert image to RGB for color counting, if necessary
        if img.mode != "RGB":
            img = img.convert("RGB")

        # Count the number of unique colors
        unique_colors = len(img.getcolors(maxcolors=2**24))  # maxcolors to handle large images

        # If there are more than 256 unique colors, quantize the image
        if unique_colors < 256:
            img = img.quantize(colors=256)

        # Save with maximum compression and optimization
        with io.BytesIO() as compressed_buf:
            img.save(compressed_buf, "PNG", compress_level=9, optimize=True)
            compressed_image_bytes = compressed_buf.getvalue()

        return compressed_image_bytes

    except Exception as e:
        my_log.log2(f"utils:compress_png_bytes: Compression error: {e}")
        return image_bytes  # Return original bytes on error


def resize_image(image_bytes: bytes, max_size: int = 10 * 1024 * 1024) -> bytes:
    """
    Resizes the image to a maximum size in bytes, specifically for Telegram.
    Converts the image to JPEG regardless of the original format to ensure compatibility and reduce size.

    Args:
        image_bytes: Image bytes.
        max_size: Maximum size in bytes (default is 10MB).

    Returns:
        Resized image bytes in JPEG format.
        Returns original bytes if any error occurs or if image is already smaller than max_size.
    """
    if len(image_bytes) <= max_size:
        return image_bytes # Already small enough

    try:
        img = PIL.Image.open(io.BytesIO(image_bytes)).convert("RGB")
    except Exception:
        return image_bytes  # Return original bytes if open fails

    quality = 75

    while True:
        output = io.BytesIO()
        try:
            img.save(output, format="JPEG", quality=quality, optimize=True, subsampling=0) # optimize and preserve text
        except Exception:
            return image_bytes # Return original bytes if save fails

        size = output.tell()

        if size <= max_size:
            return output.getvalue()

        if quality <= 10:  # Minimum quality
            return output.getvalue()

        quality -= 10


def resize_image_dimention(image_bytes: bytes) -> bytes:
    """
    Resizes an image to fit within Telegram's dimension limits (width + height <= 10000),
    while preserving the aspect ratio and format.

    Args:
        image_bytes: The image data as bytes.

    Returns:
        The resized image data as bytes, or the original image data if no resizing was needed.
    """
    try:
        img = PIL.Image.open(io.BytesIO(image_bytes)) # Open the image from bytes
        original_format = img.format  # Store original format

        if img.width + img.height > 10000:
            # Calculate the scaling factor to maintain aspect ratio
            # while keeping within Telegram's size limit.
            scale_factor = 10000 / (img.width + img.height)
            new_width = int(img.width * scale_factor)
            new_height = int(img.height * scale_factor)

            # Resize the image using the calculated dimensions
            img = img.resize((new_width, new_height), PIL.Image.LANCZOS)
        else:
            return image_bytes

        # Save the image to a BytesIO object, preserving the original format
        output_bytes = io.BytesIO()
        img.save(output_bytes, format=original_format, optimize=True)
        return output_bytes.getvalue()

    except Exception as e:
        my_log.log2(f"utils:resize_image_dimention: {e}")
        return image_bytes


def truncate_text(text: str, max_lines: int = 10, max_chars: int = 300) -> str:
    try:
        text = html.escape(text)
        if len(text) < max_chars and text.count('\n') < max_lines:
            return text
        text = '<blockquote expandable>' + text[:3500] + '</blockquote>'
        return text
    except Exception as error:
        traceback_error = traceback.format_exc()
        my_log.log2(f'utils:truncate_text {error}\n{text}\n{max_lines} {max_chars}\n\n{traceback_error}')
        return text


def extract_user_id(user_id_string: str) -> int:
    """
    Extracts the user ID (the first number) from a string like 'user_id = '[2534346] [0]'' using regular expressions.

    Args:
        user_id_string: The input string containing the user ID.

    Returns:
        The extracted user ID as an integer.
        Returns 0 if the input string is not in the expected format or does not contain a valid number.
    """
    match = re.search(r'\[(-?\d+)\]', user_id_string)
    if match:
        try:
            return int(match.group(1))
        except ValueError:
            return 0
    return 0


def format_timestamp(timestamp: float) -> str:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç timestamp –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç,
    –≥–¥–µ –º–µ—Å—è—Ü –Ω–∞–ø–∏—Å–∞–Ω —Å–ª–æ–≤–∞–º–∏.

    Args:
        timestamp: Timestamp (—á–∏—Å–ª–æ —Å–µ–∫—É–Ω–¥ —Å –Ω–∞—á–∞–ª–∞ —ç–ø–æ—Ö–∏).

    Returns:
        –°—Ç—Ä–æ–∫–∞ —Å –¥–∞—Ç–æ–π –∏ –≤—Ä–µ–º–µ–Ω–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ '–î–µ–Ω—å –ú–µ—Å—è—Ü –ì–æ–¥ –ß–∞—Å:–ú–∏–Ω—É—Ç–∞:–°–µ–∫—É–Ω–¥–∞'.
    """
    datetime_object = datetime.datetime.fromtimestamp(timestamp)
    month_name = datetime_object.strftime('%B')
    day = datetime_object.strftime('%d')
    year = datetime_object.strftime('%Y')
    time_str = datetime_object.strftime('%H:%M:%S')
    
    return f"{day} {month_name} {year} {time_str}"


def extract_large_ids(text: str, min_digits: int = 5) -> List[str]:
    """
    Extracts IDs (large numbers with a minimum number of digits) from a text string,
    including negative numbers.

    Args:
        text: The input text containing IDs.
        min_digits: Minimum number of digits for a number to be considered as an ID

    Returns:
        A list of extracted IDs as strings, including the square brackets and [0] part.
    """
    pattern = r'(\D|^)(-?\d{' + str(min_digits) + r',})(\D|$)'
    matches = re.findall(pattern, text)
    return [f'[{match[1]}] [0]' for match in matches]


def extract_retry_seconds(text: str) -> int:
    """
    Extracts the number of seconds after the "retry after" phrase from a text.

    Args:
        text: The input text containing the "retry after" phrase.

    Returns:
        The number of seconds as an integer, or None if not found.
    """
    pattern = r"retry after (\d+)"
    match = re.search(pattern, text)
    if match:
        return int(match.group(1))
    return 0


def shorten_all_repeats(text: str, min_repetitions: int = 200, max_keep: int = 10) -> str:
    """
    Detects and shortens all sequences of repeating characters throughout the text.

    Args:
        text: The input string.
        min_repetitions: The minimum number of repetitions to consider for shortening.
        max_keep: The maximum number of repetitions to keep.

    Returns:
        The string with all repeated character sequences shortened.
    """
    def replace_repeat(match):
        repeated_unit: str = match.group(1)
        return repeated_unit * max_keep

    pattern: str = r"(.+?)\1{" + str(min_repetitions - 1) + ",}"
    return re.sub(pattern, replace_repeat, text, flags=re.DOTALL)


def get_ytb_proxy(url: str = None) -> str:
    '''return insert line with proxy if any else Empty string'''

    # # no proxy for vimeo
    # if url and 'vimeo' in url:
    #     return ''

    if hasattr(cfg, 'YTB_PROXY') and cfg.YTB_PROXY:
        proxy = random.choice(cfg.YTB_PROXY)
        result = f' --proxy "{proxy}" '
    else:
        result = ''

    return result


def audio_duration(audio_file: Union[str, bytes]) -> int:
    """
    Get the duration of an audio file.

    Args:
        audio_file: The path to the audio file (str) or the audio file content as bytes.

    Returns:
        int: The duration of the audio file in seconds.
    """
    tmpfname = ''
    if isinstance(audio_file, bytes):
        # Create a temporary file to pass to ffprobe
        tmpfname = get_tmp_fname()
        with open(tmpfname, 'wb') as f:
            f.write(audio_file)
        audio_file = tmpfname

    duration_seconds = 0
    try:
        # Execute ffprobe to get the duration
        result = subprocess.run(
            ['ffprobe', '-v', 'error', '-show_entries', 'format=duration', '-of', 'default=noprint_wrappers=1:nokey=1', audio_file],
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            check=True  # Raise CalledProcessError for non-zero return codes
        )
        if result.stdout:
            try:
                # Convert the output to float and then to integer
                duration_seconds = int(float(result.stdout.decode('utf-8').strip()))
            except ValueError:
                my_log.log2(f'utils:audio_duration Could not convert ffprobe output to float: {result.stdout}')
    except subprocess.CalledProcessError as error:
        my_log.log2(f'utils:audio_duration ffprobe failed for {audio_file}\n{error}')
    except FileNotFoundError as error:
        my_log.log2(f'utils:audio_duration ffprobe not found\n{error}')
    except Exception as error:
        my_log.log2(f'utils:audio_duration {audio_file}\n{error}')
    finally:
        # Clean up the temporary file if it was created
        if tmpfname:
            remove_file(tmpfname)

    return duration_seconds


def srt_to_text(cap_srt: str) -> str:
    """Converts an SRT subtitle string to plain text.

    Args:
        cap_srt: A string containing subtitles in SRT format.

    Returns:
        A string with the extracted text from the subtitles.
        Returns an empty string ('') if an error occurs during processing.
    """
    try:
        subs = pysrt.from_string(cap_srt)
        text = subs.text
        return text
    except pysrt.Error:
        return ''


if __name__ == '__main__':
    pass

    # with open('C:/Users/user/Downloads/1.srt', 'r', encoding='utf8') as f:
    #     srt_text = f.read()
    # text = srt_to_text(srt_text)
    # print(text)

    # print(get_filename_from_url('https://youtu.be/1234567890.ogg'))


    # with open('C:/Users/user/Downloads/test.md', 'r', encoding='utf8') as f:
    #     text = f.read()
    #     html = bot_markdown_to_html(text)
    #     print(html)

    with open(r'c:\Users\user\Downloads\–±–æ–ª—å—à–∞—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è (–ø–µ—Ä–µ–∂–∞—Ç–æ).jpg', 'wb') as f:
        f.write(resize_and_convert_to_jpg(r'c:\Users\user\Downloads\samples for ai\–±–æ–ª—å—à–∞—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è.jpg'))
